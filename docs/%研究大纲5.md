# ==Part I　背景与统一形式化==

## 第1章　引言与贡献概览

### 1.1 问题背景与动机

量子 Born 机（QCBM）以纯态 $|\psi_\theta\rangle$ 的**计算基测量**所诱导的概率分布

$$
p_\theta(x)=|\psi_\theta(x)|^2,\qquad x\in\Sigma^T
$$

作为生成模型。与经典深度生成模型不同，QCBM 的“参数—函数”映射天然带有**相位—振幅**耦合与**多体纠缠**结构。若将 $|\psi_\theta\rangle$ 顺序化为 MPS（矩阵乘积态），其**键维/纠缠维** $D$ 是复杂度的核心指标，但如何把 $D$ 与**可学习性**（样本复杂度、稳定性、泛化）建立可操作的桥梁仍欠系统化。

本工作给出一个统一视角：以**Hankel 矩阵**作为序列可学习性的“坐标系”，通过

$$
\psi_\theta(x)=\alpha^\top\!\Big(\prod_{t=1}^T A_t(x_t)\Big)\beta
\quad\Longrightarrow\quad
H_a(u,v)=\psi_\theta(uv),\ \ H_p(u,v)=|H_a(u,v)|^2,
$$

揭示

$$
\operatorname{rank}(H_a)\le D,\qquad \operatorname{rank}(H_p)\le D^2,
$$

并在截断/噪声等情形下给出**近秩、条件数与稳健性**的系统理论；进而把 QCBM 的可学性落回\*\*线性代数 + 有限自动机（WFA）\*\*的范式：$H_p$ 的秩/条件数 $\leftrightarrow$ 有限维线性表示的可辨识性与统计效率。

### 1.2 主要贡献（结构定理、统计界、算法框架、选集设计）

* **结构理论（Born–Hankel–自动机统一）**：给出**转移算子**

  $$
  T=\sum_{\sigma\in\Sigma}A(\sigma)\otimes\overline{A(\sigma)}
  $$

  的核心角色：它连接 MPS 的规范化与概率‑Hankel 的线性化；在左/右规范形下刻画 $T$ 的谱半径与不动点，从而控制长度依赖与稳态行为。

* **秩—纠缠与近秩稳定**：证明 $\operatorname{rank}(H_p)\le D^2$，并在逐割截断下给出
  $\|H_p-\tilde H_p\|_2$ 的上界与**几何放大因子** $G_L(\kappa_p)$（由 $\|A(\sigma)\|_2$ 控制）。并证明 $\Omega(D^2)$ 的近紧性与“高纠缠/随机电路近满秩”的对照结果。

* **可辨识性与最小实现**：以可观测/可控制子空间刻画**最小实现秩**与 Hankel 秩等价，给出 Gram 判据的 $\sigma_{\min}$ 下界；清晰分离**gauge 等价类**与**可识别不变量**。

* **统计学习理论**：对 one‑shot 与滑窗采样建立矩阵 Bernstein/鞅集中；在核范/有效秩假设下给出泛化界；端到端误差由 $\| \widehat H - H\|_2$ 传递到点态误差，长度依赖由 $G_L(\kappa_B)$ 或在可收缩锥内降为 $O(L)$。

### 1.3 方法路线图与读者导航

* **Part II（结构理论）**：从秩—纠缠与截断稳健出发，建立转移算子与规范化框架，给出可辨识与下界。
* **Part III（统计学习理论）**：从 Hankel 频数估计出发，推导集中—泛化—端到端误差与样本复杂度。
* **Part IV（扩展）**：混态/POVM、平稳极限与其他观测。

---

## 第2章　记号、模型与预备知识

### 2.1 字母表、字符串、Hankel 与基本线性代数

* **字母表**：有限集合 $\Sigma$，$|\Sigma|=d$。
* **字符串**：$\Sigma^t$ 为长度 $t$ 的串集，$\Sigma^{\le L}=\bigcup_{t=0}^L\Sigma^t$，空串 $\epsilon$。
* **拼接**：$uv$ 表示串连接。
* **长度‑$L$ Hankel**：对函数 $f:\Sigma^L\to\mathbb C$ 或 $\mathbb R_{\ge0}$，

  $$
  H_f^{(L)}(u,v)=f(uv)\quad\text{仅当 }|u|+|v|=L,
  $$

  并记子矩阵 $H_f^{(L)}(P,S)$（默认 $P\subseteq\Sigma^{t_\star},\ S\subseteq\Sigma^{L-t_\star}$ 含 $\epsilon$，且只索引满足 $|u|+|v|=L$ 的对）。
* **线性代数**：$\mathrm{vec}(\cdot)$ 为列优先向量化；$\overline{\cdot}$ 复共轭；$(\cdot)^\dagger$ 共轭转置；$\otimes$ Kronecker。谱范数 $\|\cdot\|_2$、核范 $\|\cdot\|_*$、Frobenius 范数 $\|\cdot\|_F$。奇异值 $\sigma_1\ge\cdots$，条件数 $\kappa(M)=\sigma_1/\sigma_{\min}$。
  基本恒等式（常用）：

  $$
  \|X\otimes Y\|_2=\|X\|_2\,\|Y\|_2,\quad (X\otimes Y)^\top=X^\top\otimes Y^\top,\quad \mathrm{vec}(AXB)=(B^\top\!\otimes A)\,\mathrm{vec}(X).
  $$

### 2.2 Born 机与 MPS 顺序化（规范形与 gauge）

* **Born 机（one‑shot）**：希尔伯特空间 $\mathcal H=(\mathbb C^d)^{\otimes T}$；计算基 $\{|x\rangle:x\in\Sigma^T\}$。态与分布

  $$
  |\psi_\theta\rangle=\sum_{x}\psi_\theta(x)|x\rangle,\qquad p_\theta(x)=|\psi_\theta(x)|^2,\ \sum_x p_\theta(x)=1.
  $$
* **MPS 顺序化（时间从左到右）**：存在 $\alpha,\beta\in\mathbb C^D$，$A_t(\sigma)\in\mathbb C^{D\times D}$ 使

  $$
  \psi_\theta(x_{1:T})=\alpha^\top\!\Big(\prod_{t=1}^T A_t(x_t)\Big)\beta .
  $$

  若 $A_t\equiv A$ 与 $t$ 无关则称平移不变；本文默认长度‑$L$ 分析时用 $A(\cdot)$ 记法。
* **gauge（相似变换）**：对任意可逆 $S\in\mathbb C^{D\times D}$，
$$
  A'(\sigma)=S^{-1}A(\sigma)S,\quad \alpha'=S^\top \alpha,\quad \beta'=S^{-1}\beta,
$$

则 $\alpha'^\top A'(x)\beta'=\alpha^\top A(x)\beta$；故 $p_\theta$ 对 gauge 不变。
* **规范形（MPS canonical forms）**：常见左/右规范：
  左规范：$\sum_\sigma A(\sigma)A(\sigma)^\dagger=I$；
  右规范：$\sum_\sigma A(\sigma)^\dagger A(\sigma)=I$。
  在左规范下，转移超算子 $E(X)=\sum_\sigma A(\sigma)XA(\sigma)^\dagger$ 满足 $E(I)=I$（单位不动点）；右规范类似。实际中可在某个割点采用**混合规范**（orthogonality center）。

### 2.3 振幅‑Hankel、概率‑Hankel 与 Kronecker 嵌入

> 约定：对长度‑$L$ 的 Hankel，仅索引满足 $|u|+|v|=L$ 的 $(u,v)$。

**振幅 Hankel（rank ≤ $D$）**
令

$$
\psi(x_{1:L})=\alpha^\top\!\Big(\prod_{t=1}^{L}A(x_t)\Big)\beta,\quad
H_a(u,v)=\psi(uv).
$$

定义前缀/后缀嵌入

$$
\ell(u)=\Big(\prod_{t=1}^{|u|}A(u_t)\Big)^\top\!\alpha,\qquad
r(v)=\Big(\prod_{t=1}^{|v|}A(v_t)\Big)\beta,
$$

则

$$
H_a(u,v)=\ell(u)^\top r(v),\qquad \operatorname{rank} H_a\le D .
$$

**概率 Hankel（rank ≤ $D^2$）**
作 Kronecker 嵌入

$$
\ell_p(u)=\ell(u)\otimes\overline{\ell(u)},\qquad
r_p(v)=r(v)\otimes\overline{r(v)},
$$

则

$$
H_p(u,v)=|H_a(u,v)|^2=\ell_p(u)^\top r_p(v),\qquad
\operatorname{rank} H_p\le D^2 .
$$

**字母作用与线性更新**
记

$$
B_\sigma:=A(\sigma)\otimes\overline{A(\sigma)}\in\mathbb C^{D^2\times D^2},
$$

则对任意 $\sigma\in\Sigma$,

$$
\ell_p(u\sigma)^\top=\ell_p(u)^\top B_\sigma,\qquad
r_p(\sigma v)=B_\sigma\,r_p(v),
$$

初值

$$
\ell_p(\epsilon)=\alpha\otimes\overline{\alpha},\qquad
r_p(\epsilon)=\beta\otimes\overline{\beta}.
$$

> 以上定义彼此一致：$H_p=\ell_p^\top r_p$ 给出概率‑Hankel 的双线性分解，且更新律与初值无需任何规范形假设即可成立。

### 2.4 误差度量与采样（one‑shot、滑窗、量子访问选读）

* **误差度量**：

  $$
  \mathrm{TV}(p,q)=\tfrac12\sum_{x\in\Sigma^L}|p(x)-q(x)|,\quad
  \mathrm{MMD}^2_k=\mathbb E k-2\mathbb E k+\mathbb E k,\quad
  \mathrm{NLL}(\hat p;\mathcal D)=-\tfrac1N\sum_{i}\log\hat p(x^{(i)}).
  $$
* **采样模型**：
  one‑shot：独立采样 $x^{(i)}\sim p_\theta$（长度 $L$）。
  滑窗：当观测长串 $T>L$，从每条样本串提取所有长度 $L$ 的窗口，形成 $N_L$ 个窗口计数（注意**相关性**）。
* **经验 Hankel**：固定切分 $t_\star$，对 $x=uv$ 唯一分解，

  $$
  \widehat H_p(u,v)=\frac{1}{N_L}\sum_{i=1}^{N}\sum_{w\in\mathcal W_L(x^{(i)})}\mathbf 1\{w=uv\}.
  $$
* **量子访问（选读）**：若可用幅度估计（QAE）或影子等技术，频数估计的方差可进一步缩小；本文主结果不依赖这些访问，仅作理论对照。

---

## 第3章　Born‑Hankel–自动机的统一视角

本章把 QCBM 的概率结构与**有理级数/加权有限自动机（WFA）**完全对齐。核心对象是**转移（transfer）算子**

$$
T=\sum_{\sigma\in\Sigma}B_\sigma=\sum_{\sigma\in\Sigma}A(\sigma)\otimes\overline{A(\sigma)}\in\mathbb C^{D^2\times D^2}.
$$

### 3.1　转移算子与 Liouville 表示

> **向量化约定**：列优先 `vec`，并始终使用$\displaystyle \mathrm{vec}(A X B)=(B^\top\!\otimes A)\,\mathrm{vec}(X)$.

##### 定义 3.1（Liouville 超算子与两种等价矩阵实现）

给定

$$
E(X)=\sum_{\sigma\in\Sigma}A(\sigma)\,X\,A(\sigma)^\dagger .
$$

其 **Liouville 矩阵** 为

$$
\boxed{\ \ \mathcal L\ :=\ \sum_{\sigma}\overline{A(\sigma)}\otimes A(\sigma)\ \ }
\quad\Rightarrow\quad
\mathrm{vec}\!\big(E(X)\big)=\mathcal L\,\mathrm{vec}(X).
$$

为与后续 Kronecker‑嵌入的传播律统一，同时记

$$
B_\sigma:=A(\sigma)\otimes \overline{A(\sigma)},\qquad
T:=\sum_{\sigma}B_\sigma .
$$

两者满足**相似等价**：$\mathcal L=K\,T\,K^{-1}$并且$K^{-1}=K=K^\top$，其中 $K$ 为换位矩阵（$\,K\,\mathrm{vec}(X)=\mathrm{vec}(X^\top),\ K^2=I$）。因此 $\mathcal L$ 与 $T$ **谱相同**。

##### 引理 3.2（规范形与谱性质版）

1. **左规范 $\Leftrightarrow$ 不动点；单位特征值存在。**

$$
\sum_{\sigma}A(\sigma)A(\sigma)^\dagger=I\quad\Longleftrightarrow\quad E(I)=I .
$$

因此 $\mathcal L\,\mathrm{vec}(I)=\mathrm{vec}(I)$。又因 $\mathcal L=K T K^{-1}$ 且 $K\,\mathrm{vec}(I)=\mathrm{vec}(I)$，故 $T\,\mathrm{vec}(I)=\mathrm{vec}(I)$。从而

$$
1\in \mathrm{spec}(\mathcal L)=\mathrm{spec}(T).
$$

2. **谱半径与外围谱（unital‑CP；primitive）。** 在左规范下，$E$ 为 **unital** 的完全正映射（CP）。对由 $\|\cdot\|_\infty$ 诱导的算子范数

$$
\|E\|_{\infty\to\infty}=\sup_{X\neq 0}\frac{\|E(X)\|_\infty}{\|X\|_\infty},
$$

由 Russo–Dye/Kadison 可知 $\|E\|_{\infty\to\infty}=1$。故

$$
\rho(\mathcal L)\le \|E\|_{\infty\to\infty}=1,
$$

联同 (1) 得 $\rho(\mathcal L)=1$。另外，$E(I)=I$ 蕴含对偶映射 $E^*$ **迹保持**：

$$
\mathrm{Tr}\!\big(E^*(\rho)\big)=\mathrm{Tr}\!\big(\rho\,E(I)\big)=\mathrm{Tr}\rho,
$$

因此 $E^*$ 为 **CPTP**。若进一步 $E$ **primitive**（Heisenberg 图像下存在 $n$ 使 $E^n(X)\succ 0$ 对所有 $0\neq X\succeq 0$；**等价地**，其对偶 CPTP 通道 $E^*$ 在薛定谔图像下亦 primitive），则**外围谱**仅含**简单**（代数重数 1）的特征值 $1$，其余特征值满足 $|\lambda|<1$。由于 $\mathcal L$ 与 $T$ 相似，上述结论同样适用于 $T$。

##### 命题 3.3（前缀/后缀特征的线性传播与 Hankel 分解）

为统一传播律，取

$$
\ell(u)=\Big(\prod_{t=1}^{|u|}A(u_t)\Big)^\top\!\alpha,\qquad
r(v)=\Big(\prod_{t=1}^{|v|}A(v_t)\Big)\beta,
$$

并定义

$$
\ell_p(u)=\ell(u)\otimes\overline{\ell(u)},\quad
r_p(v)=r(v)\otimes\overline{r(v)},\quad
B_\sigma:=A(\sigma)\otimes\overline{A(\sigma)}\in\mathbb C^{D^2\times D^2}.
$$

则对任意 $\sigma\in\Sigma$，有**线性传播**：

$$
\ell_p(u\sigma)^\top=\ell_p(u)^\top B_\sigma,\qquad
r_p(\sigma v)=B_\sigma\,r_p(v),
$$

初值为 $\ell_p(\epsilon)=\alpha\otimes\overline{\alpha}$、$r_p(\epsilon)=\beta\otimes\overline{\beta}$。

记 $H_p(u,v)=|\ell(u)^\top r(v)|^2$。取 $O_P[u,:]=\ell_p(u)^\top$、$C_S[:,v]=r_p(v)$，则

$$
\boxed{\,H_p(P,S)=O_P\,C_S\,},\qquad
\operatorname{rank}H_p(P,S)\le \min\{\operatorname{rank}O_P,\operatorname{rank}C_S\}\le D^2.
$$

> 注：$T:=\sum_{\sigma}B_\sigma$ 给出一步“平均传播”，其谱与 Liouville 矩阵谱等价，可用于长度依赖与稳态分析。

### 3.2 与有理级数/WFA 的对齐：可观测 / 可控制子空间

**定义 3.4（线性表示 / WFA）**
称三元组 $(i,\{B_\sigma\}_{\sigma\in\Sigma},f)$ 为 **线性表示**，若对任意词 $x=x_{1:L}\in\Sigma^L$,
$$
p(x)=i^\top B_{x_1}\cdots B_{x_L} f,\qquad B_{u}:=B_{u_1}\cdots B_{u_{|u|}} .
$$

在 QCBM–Hankel 情形，可取

$$
i=\alpha\otimes\overline{\alpha},\quad f=\beta\otimes\overline{\beta},\quad
B_\sigma=A(\sigma)\otimes\overline{A(\sigma)},
$$

于是

$$
p(x)=\big|\alpha^\top A(x)\beta\big|^2=i^\top B_{x_1}\cdots B_{x_L} f .
$$

**定义 3.5（可观测 / 可控制子空间）**
给定表示 $(i,B,f)$，定义
$$
\mathcal O^{(\le L)}:=\operatorname{span}\{\,i^\top B_u:\ u\in\Sigma^{\le L}\,\}\subset\mathbb C^{1\times D^2},\qquad
\mathcal C^{(\le L)}:=\operatorname{span}\{\,B_v f:\ v\in\Sigma^{\le L}\,\}\subset\mathbb C^{D^2\times 1}.
$$

当 $L$ 足够大时，简记 $\mathcal O,\mathcal C$。

**命题 3.6（Hankel 分解与秩界）**
令长度 $L$ 的概率‑Hankel 子矩阵 $H_p(P,S)$ 以满足 $|u|+|v|=L$ 的 $(u,v)$ 为索引。设
$$
O_P[u,:]=i^\top B_u,\qquad C_S[:,v]=B_v f.
$$

则

$$
H_p(P,S)=O_P\,C_S,\quad
\operatorname{rowspan}(O_P)\subseteq \mathcal O^{(\le L)},\ 
\operatorname{colspan}(C_S)\subseteq \mathcal C^{(\le L)},
$$

从而

$$
\operatorname{rank} H_p(P,S)\ \le\ \min\{\dim\mathcal O^{(\le L)},\ \dim\mathcal C^{(\le L)}\}\ \le\ D^2,
$$

且当 $P,S$ 充分张成上述子空间时取等。

**定理 3.7（最小实现与 Hankel 秩等价）**
为避免记号冲突，用 $h:\Sigma^*\!\to\mathbb F$（$\mathbb F=\mathbb R$ 或 $\mathbb C$）表示目标函数，其 Hankel 矩阵 $H_h(u,v)=h(uv)$。

* **(A) 无限长度版.** 若 $\operatorname{rank}H_h=r<\infty$，则存在维度为 $r$ 的线性表示 $(i,\{B_\sigma\},f)$ 使

  $$
  \forall w\in\Sigma^*:\ h(w)=i^\top B_w f,
  $$

  且任意线性表示的维度 $\ge r$。因此**最小表示维数**恰为 $\operatorname{rank}H_h$。

* **(B) 有限长度（受限）版——须用块‑Hankel.** 给定 $L\ge0$，定义块‑Hankel

  $$
  H_h^{(\le L)}(u,v)=h(uv),\qquad |u|,|v|\ge0,\ |u|+|v|\le L.
  $$

  设 $r_L=\operatorname{rank}H_h^{(\le L)}$。则存在维度为 $r_L$ 的线性表示 $(i,\{B_\sigma\},f)$，用**同一组** $\{B_\sigma\}$ 同时满足

  $$
  \forall w\in\Sigma^*,\ |w|\le L:\ h(w)=i^\top B_w f,
  $$

  且任一能在所有 $|w|\le L$ 上再现 $h$ 的线性表示，其维度至少为 $r_L$。
  *备注：仅用单层 Hankel $H_h^{(L)}$（索引 $|u|+|v|=L$）只能保证该层的低秩分解，**不足以**保证存在对所有 $|w|\le L$ 递推一致的 $\{B_\sigma\}$。*

##### 推论 3.8（可辨识性）

设目标函数（或分布）$h$ 的**最小线性表示维度**为 $r_\star$（无限长度情形按 §3.7(A)；有限长度情形按 §3.7(B) 以块‑Hankel $H_h^{(\le L)}$ 的秩为准）。令长度 $L$ 的概率‑Hankel 子矩阵 $H_p(P,S)$ 满足 $\operatorname{rank} H_p(P,S)=r_\star$。对任一线性表示 $(i,\{B_\sigma\},f)$，记

$$
O_P[u,:]=i^\top B_u,\qquad C_S[:,v]=B_v f .
$$

若 $\operatorname{rank} O_P=\operatorname{rank} C_S=r_\star$（等价地，所选 $P,S$ 在秩‑$r_\star$ 子空间上限制‑Gram 非奇异），则有：

**（结构可辨识）**
对任何另一组也能再现同一 $h$ 的表示 $(i',\{B'_\sigma\},f')$，**存在且仅存在**可逆矩阵 $Q\in \mathrm{GL}(r_\star)$ 使

$$
O'_P=O_P\,Q,\qquad C'_S=Q^{-1}C_S,\qquad B'_\sigma=Q^{-1}B_\sigma Q\ \ (\forall\sigma\in\Sigma),
$$

等价地，$i'^\top=i^\top Q,\ f'=Q^{-1}f$。因此，最小实现在秩‑$r_\star$ 子空间上**唯一到相似变换**。

> 说明：本推论给出**结构层面的唯一性**。关于在 $\widehat H$ 接近 $H$ 时的**稳定恢复**与定量误差上界，见 §11 的扰动—恢复结果。

### 3.3　规范化与 gauge‑不变量（可辨识性的等价类）

**两层等价.**

* **MPS‑gauge（维度 $D$）**：$A'(\sigma)=S^{-1}A(\sigma)S$、$\alpha'=S^\top\alpha$、$\beta'=S^{-1}\beta$。
* **WFA‑相似变换（维度 $D^2$）**：$B'_\sigma=Q^{-1}B_\sigma Q$、$i'=Q^\top i$、$f'=Q^{-1}f$。
  二者由 $Q=S\otimes\overline S$ 关联；故任意 MPS‑gauge 在 WFA 层均为相似变换，且

$$
i^\top B_{x_1}\cdots B_{x_L}f
=i'^\top B'_{x_1}\cdots B'_{x_L}f'.
$$

##### 命题 3.9（gauge‑不变量与可调量）

* **不变量：** 生成函数 $p(x)$；（无限）Hankel 秩 $\operatorname{rank}H_p$；转移算子 $T=\sum_\sigma B_\sigma$ 的特征值多重集（相似不变）；可观测/可控制子空间的维数。
* **可调量：** $\|B_\sigma\|_2$、$\kappa(H_p(P,S))$ 等依赖坐标与 $(P,S)$ 的量。
* **规范化选择：**

  1. **MPS 左/右规范：** $\sum_\sigma A(\sigma)A(\sigma)^\dagger=I$（或对偶）使 $E(X)=\sum_\sigma A X A^\dagger$ 成为 **unital‑CP**，从而 $\rho(T)=1$ 且 $T\,\mathrm{vec}(I)=\mathrm{vec}(I)$ **显式可见**；
  2. **WFA 白化/平衡化：** 在秩‑$r$ 子空间取可逆 $W_L,W_R$ 使 $W_L H_p W_R=I_r$（见下述“恒等校准”），并因此得到 $\sum_\sigma \widehat B_\sigma=I_r$。

##### 引理 3.10（Kronecker‑更新与相似变换兼容性）

对适形 $B,a$ 与可逆 $S$，

$$
(B^\top a)\!\otimes\!\overline{(B^\top a)}
=(B\!\otimes\!\overline B)^\top(a\!\otimes\!\overline a),\qquad
(S^{-1}BS)\!\otimes\!\overline{(S^{-1}BS)}
=(S^{-1}\!\otimes\!\overline{S^{-1}})(B\!\otimes\!\overline B)(S\!\otimes\!\overline S).
$$

*证明略：由 Kronecker 与转置/共轭的分配性。*

##### 定理 3.11（限制‑Gram 判据与规范化协同）

**设定**：令 $H=H_p(P,S)=O_P\,C_S\in\mathbb C^{m\times n}$，$\mathrm{rank}(H)=r\ge1$。记 $k:=\mathrm{rank}(C_S)\ge r$。取 $U\in\mathbb C^{D^2\times k}$ 使 $U^\dagger U=I_k$ 且 $\operatorname{col}(C_S)=\operatorname{span}(U)$。定义
$$
\mathcal O_P:=U^\dagger O_P^\dagger O_P\,U,\qquad
\mathcal C_S:=U^\dagger C_S C_S^\dagger U\quad(\in\mathbb C^{k\times k}).
$$

##### (A) 限制‑Gram 下界

$$
\boxed{\quad
\sigma_r(H)\ \ge\ \sqrt{\lambda_{\min}(\mathcal O_P)}\ \sqrt{\lambda_{r}(\mathcal C_S)}\ .
\quad}
$$

其中 $\lambda_r(\cdot)$ 为第 $r$ 大特征值。**特例**：若 $\mathrm{rank}(C_S)=r$，则

$$
\sigma_r(H)\ \ge\ \sqrt{\lambda_{\min}(\mathcal O_P)}\ \sqrt{\lambda_{\min}(\mathcal C_S)} .
$$

（对偶式可由交换行/列并用 $\widetilde U$ 张成 $\operatorname{row}(O_P)$ 得到。）

##### (B) 恒等校准（白化）

设 $H=U_r\Sigma_r V_r^\dagger$ 为秩‑$r$ SVD（$\Sigma_r\succ0$）。给定 $\lambda\ge0$ 定义

$$
W'_L=(\Sigma_r+\lambda I)^{-1/2}U_r^\dagger,\quad
W'_R=V_r(\Sigma_r+\lambda I)^{-1/2},\quad
\widehat S:=W'_LHW'_R\succ0,
$$

$$
W_L=\widehat S^{-1/2}W'_L,\qquad W_R=W'_R\,\widehat S^{-1/2}.
$$

则有**精确恒等**：

$$
\boxed{\quad W_LHW_R=I_r,\qquad
\widehat B_\sigma:=W_LH_\sigma W_R\ \Rightarrow\ \sum_{\sigma\in\Sigma}\widehat B_\sigma=I_r.\quad}
$$

（当 $\lambda=0$ 时可直接取 $W_L=\Sigma_r^{-1/2}U_r^\dagger,\ W_R=V_r\Sigma_r^{-1/2}$ 而无需 $\widehat S$ 这一步。）

##### 备注 3.12（“$\sum_\sigma B_\sigma=I$”的两种语义）

* **MPS 左规范**：仅有 $E(I)=I$（或对偶），等价于 $T\,\mathrm{vec}(I)=\mathrm{vec}(I)$ 与 $\rho(T)=1$；这并不意味着 $T=I$。
* **WFA‑白化‑恒等校准**：在**数据驱动的秩‑$r$ 子空间**上经上式白化/平衡化得到
  $\sum_\sigma \widehat B_\sigma=I_r$，其含义是“字母转移的**平均效应**在该最小实现子空间上被规约为恒等”；与原始 $T$ 是否等于 $I$ 无关。

---

# ==Part II　结构理论==

## 第4章　秩—纠缠理论与有效维

> **长度‑$L$ Hankel 约定：** 仅索引满足 $|u|+|v|=L$ 的 $(u,v)$。

### 4.1　Rank–Entanglement：$\operatorname{rank}(H_a)\le D$、$\operatorname{rank}(H_p)\le D^2$

**设定.** 令（平移不变门列）

$$
\psi(x_{1:L})=\alpha^\top\!\Big(\prod_{t=1}^{L} A(x_t)\Big)\beta,\qquad
H_a(u,v)=\psi(uv),\qquad
H_p(u,v)=|H_a(u,v)|^2 .
$$

**前/后缀嵌入与 Kronecker 嵌入（与 §2.3 一致）**

$$
\ell(u)=\Big(\prod_{t=1}^{|u|}A(u_t)\Big)^\top\!\alpha,\qquad
r(v)=\Big(\prod_{t=1}^{|v|}A(v_t)\Big)\beta,
$$

$$
\ell_p(u)=\ell(u)\otimes \overline{\ell(u)},\qquad
r_p(v)=r(v)\otimes \overline{r(v)},\qquad
B_\sigma:=A(\sigma)\otimes\overline{A(\sigma)}.
$$

> **一致性说明**：这里的 $r(v)$ 采用**正向乘积**，从而
> $H_a(u,v)=\ell(u)^\top r(v)=\psi(uv)$ 严格成立；且与 §2.3 的传播律完全对齐。

##### 定理 4.1（振幅/概率 Hankel 的秩上界）

对任意 $P\subseteq\Sigma^{t_\star}$、$S\subseteq\Sigma^{L-t_\star}$，

$$
\operatorname{rank} H_a(P,S)\le D,\qquad
\operatorname{rank} H_p(P,S)\le D^2 .
$$

**证明（简）**：令 $O_P[u,:]=\ell(u)^\top\in\mathbb C^{1\times D}$、$C_S[:,v]=r(v)\in\mathbb C^{D\times 1}$，则$H_a(P,S)=O_P C_S$，故$\operatorname{rank}H_a\le D$。又由 $|\ell^\top r|^2=(\ell\otimes\overline\ell)^\top(r\otimes\overline r)$，取 $O^{(p)}_P[u,:]=\ell_p(u)^\top\in\mathbb C^{1\times D^2}$、$C^{(p)}_S[:,v]=r_p(v)\in\mathbb C^{D^2\times 1}$，得 $H_p(P,S)=O^{(p)}_P C^{(p)}_S$，故 $\operatorname{rank}H_p\le D^2$。□

##### 命题 4.2（前缀/后缀的线性传播）

初值

$$
\ell_p(\epsilon)=\alpha\otimes\overline\alpha,\qquad
r_p(\epsilon)=\beta\otimes\overline\beta .
$$

对任意 $\sigma\in\Sigma$,

$$
\ell_p(u\sigma)^\top=\ell_p(u)^\top B_\sigma,\qquad
r_p(\sigma v)=B_\sigma\,r_p(v).
$$

**证明（简）**：$\ell(u\sigma)=A(\sigma)^\top\ell(u)\Rightarrow
\ell_p(u\sigma)=(A(\sigma)\!\otimes\!\overline{A(\sigma)})^\top\ell_p(u)$，
取转置得左式。右式由 $r(\sigma v)=A(\sigma)r(v)$ 与 Kronecker 乘法分配性直接得出。□

> **注**（时变门列）：若 $A_t(\sigma)$ 随 $t$ 变化，则上述 $B_\sigma$ 改为位置相关的
> $B_{t,\sigma}:=A_t(\sigma)\otimes\overline{A_t(\sigma)}$，相应传播指数随位置移动；详见第 5 章。

### 4.2　近秩与有效秩：$\operatorname{rank}_\varepsilon(H_p)$ 与 $D_{\rm eff}$

**逐割 Schmidt 截断与误差累积.** 设每个割点的 Schmidt 奇异值为 $(s_{t,i})_{i\ge1}$。对某 $D_{\rm eff}\le D$ 在各割点做最优秩‑$D_{\rm eff}$ 截断，记
$$
\epsilon_t^2=\sum_{i>D_{\rm eff}} s_{t,i}^2,\qquad
\tau:=\sum_{t=1}^{L-1}\epsilon_t .
$$

用 “$\tilde{\cdot}$” 表示截断后的对象（$\tilde\psi,\tilde H_p$ 等）。

##### 引理 4.3（逐割截断的全局 $\ell_2$ 误差）

在标准 MPS 规范形并采用逐割最优截断（TT/MPS rounding）时，

$$
\boxed{\ \ \|\psi-\tilde\psi\|_2\ \le\ \Big(\sum_{t=1}^{L-1}\epsilon_t^2\Big)^{\!1/2}\ .\ }
$$

（保守但始终成立的版本：$\ \|\psi-\tilde\psi\|_2\le 2\sum_t \epsilon_t=2\tau$。）

##### 定理 4.4（由振幅误差到概率‑Hankel 误差）

固定切分点 $t_\star$，令 $H_p(P,S)$ 仅索引满足 $|u|+|v|=L$ 的 $(u,v)$（当 $P=\Sigma^{t_\star},S=\Sigma^{L-t_\star}$ 完全枚举该层时，下式中的“$\le$”变为“$=$”）。对归一化态 $\|\psi\|_2=\|\tilde\psi\|_2=1$ 有

$$
\|H_p-\tilde H_p\|_2\ \le\ \|H_p-\tilde H_p\|_F
\ \le\ \||\psi|^2-|\tilde\psi|^2\|_2
\ \le\ 2\,\|\psi-\tilde\psi\|_2 .
$$

由引理 4.3 立得

$$
\boxed{\ \ \|H_p-\tilde H_p\|_2\ \le\ 2\Big(\sum_{t=1}^{L-1}\epsilon_t^2\Big)^{\!1/2}\ \le\ 4\tau\ .\ }
$$

为后续记号方便，设

$$
\Delta_H\ :=\ 2\Big(\sum_{t=1}^{L-1}\epsilon_t^2\Big)^{\!1/2}\ \ \ (\le 4\tau).
$$

##### 定义 4.5（有效秩）

令 $\operatorname{rank}_\varepsilon(\cdot)$ 表示**谱范**容差‑$\varepsilon$ 的有效秩。由 $\operatorname{rank}(\tilde H_p)\le D_{\rm eff}^2$ 与 $\|H_p-\tilde H_p\|_2\le \Delta_H$ 知：

$$
\boxed{\ \ \forall\,\varepsilon\ge \Delta_H\ \ (\text{尤其 }\varepsilon\ge 4\tau),\qquad
\operatorname{rank}_\varepsilon(H_p)\ \le\ D_{\rm eff}^2\ .\ }
$$

记

$$
r_{\rm eff}(\varepsilon):=\operatorname{rank}_\varepsilon(H_p),\qquad
\text{并在下文取 }r_{\rm eff}:=r_{\rm eff}(4\tau)\ \le\ D_{\rm eff}^2
\ (\text{用 }\varepsilon=\Delta_H\text{亦可}).
$$

> 注：若把所有切分层（$t=0,\dots,L$）**同时**并入一个“联合 Hankel”，则上式需额外乘以 $\sqrt{L+1}$ 的因子；本节均假设固定切分 $t_\star$。

### 4.3　$\Omega(D^2)$ 的近紧性与“典型满秩”构造

##### 定理 4.6（近紧性）

给定键维 $D$、长度 $L$、切分 $t_\star$ 与任意集合 $P\subseteq\Sigma^{t_\star}$、$S\subseteq\Sigma^{L-t_\star}$。则**存在**参数 $(\alpha,\beta,\{A(\sigma)\})$ 使

$$
\operatorname{rank} H_p(P,S)\;=\;\min\{D^2,\ |P|,\ |S|\}.
$$

更强地，满足上式的参数集合是**非空的 Zariski 开集**；因此只要参数分布对 Lebesgue/Haar **绝对连续**（例如一般位置的连续随机化），上述等式便以**概率 1** 成立。特别地，当 $|P|\ge D^2$ 且 $|S|\ge D^2$ 时，$\operatorname{rank} H_p(P,S)=D^2$。

*证明要点（略）：* 由 $H_p(P,S)=O_PC_S$ 且 $O_P[u,:]=\ell(u)\otimes\overline{\ell(u)}$、$C_S[:,v]=r(v)\otimes\overline{r(v)}$（见 §4.1），“满秩”等价于某个 $D^2\times D^2$ 主子式的行列式**非零**。该行列式是参数的多项式；一旦举例验证其在某参数点非零，则其非零集是 Zariski 开，因而在绝对连续随机化下以概率 1 发生。□

##### 备注 4.7（典型满秩；精确表述）

若生成态的分布对 Haar 测度**绝对连续**（如 Haar 随机态，或具有连续参数且处于一般位置的随机电路族），则对任意固定 $P,S$ 有

$$
\operatorname{rank} H_p(P,S)\;=\;\min\{D^2,\ |P|,\ |S|\}\quad\text{几乎必然（概率 1）}.
$$

需要强调：“**近 2‑design**”本身**并不**保证绝对连续（典型反例：Clifford 族是离散的精确 2‑design），因此**不能**仅凭“近 2‑design”就断言“概率 1 满秩”。由此可见，**低秩‑Hankel** 反映的是低纠缠/收缩等**结构性**假设，而非总体上的典型性质。

---

## 第5章　截断与稳定：逐割理论与长度依赖

### 5.1　规范形下逐割截断误差：$\|\psi-\tilde\psi\|_2 \to \|H_p-\tilde H_p\|_2$

**设定**：长度 $L$、固定切分点 $t_\star$。在标准 MPS 规范形下对每个割点作最优秩截断，尾能量 $\epsilon_t$，记 $\tau=\sum_t \epsilon_t$。两态归一化：$\|\psi\|_2=\|\tilde\psi\|_2=1$。

##### 命题 5.1（主界；规范形 + 最优截断）

$$
\boxed{\;
\|H_p-\tilde H_p\|_2\ \le\ 2\Big(\sum_t \epsilon_t^2\Big)^{1/2}.
\;}
$$

若再用保守版 $\|\psi-\tilde\psi\|_2\le 2\tau$，则得到始终有效的松界

$$
\boxed{\;\|H_p-\tilde H_p\|_2\ \le\ 4\tau.\;}
$$

而仅用 $\big(\sum_t\epsilon_t^2\big)^{1/2}\le\tau$ 则给出更紧的
$\ \|H_p-\tilde H_p\|_2\le 2\tau$。

**证明要点（一步式）**：

$$
\|H_p-\tilde H_p\|_2\ \le\ \underbrace{\|H_p-\tilde H_p\|_F}_{\displaystyle
=\ \||\psi|^2-|\tilde\psi|^2\|_2\ \text{（当完整枚举该层时为等号）}}
\ \le\ 2\,\|\psi-\tilde\psi\|_2,
$$

再用 $\|\psi-\tilde\psi\|_2\le(\sum_t\epsilon_t^2)^{1/2}$（最优逐割截断）即得。

> **等号位置说明**：当 $P,S$ **完整枚举**长度‑$L$ 层时，上式中 **第二个**“$\le$”为“$=$”。首个“$\le$”一般严格。

##### 命题 5.2（备用界；非规范形，算子扰动与传播常数）

**设定与记号.** 固定一次向量范数诱导的算子范数（默认谱范数 $\|\cdot\|_2$）。对每层与字母

$$
M_{t,\sigma}:=A_t(\sigma)\otimes \overline{A_t(\sigma)},\qquad 
\widetilde M_{t,\sigma}:=\widetilde A_t(\sigma)\otimes \overline{\widetilde A_t(\sigma)} .
$$

定义**逐层传播常数**

$$
\boxed{\quad \kappa_{p,t}\ :=\ \max_{\sigma}\big\{\,\|M_{t,\sigma}\|,\ \|\widetilde M_{t,\sigma}\|\,\big\},\qquad 
\kappa_p\ :=\ \max_{1\le t\le L}\kappa_{p,t}\ .\quad}
$$

（这样任何出现 $\kappa_p$ 的界都**自动**兼顾真模型与扰动模型。）

令扰动 $E_t(\sigma)=\widetilde A_t(\sigma)-A_t(\sigma)$、$\varepsilon_t:=\max_\sigma\|E_t(\sigma)\|$。记

$$
\Delta_{t,\sigma}
:=E_t(\sigma)\!\otimes\!\overline{A_t(\sigma)}\ +\ A_t(\sigma)\!\otimes\!\overline{E_t(\sigma)}\ +\ E_t(\sigma)\!\otimes\!\overline{E_t(\sigma)}.
$$

边界向量取 $i=\alpha\otimes\overline{\alpha},\ f=\beta\otimes\overline{\beta}$，故 $\|i\|=\|\alpha\|^2,\ \|f\|=\|\beta\|^2$（此处为 2‑范数；若更换算子范数，应相应使用其对偶向量范数）。

##### (i) 单步扰动界（Kronecker 乘法性）

$$
\boxed{\ \ \|\Delta_{t,\sigma}\|\ \le\ 2\,\kappa\,\varepsilon_t\ +\ \varepsilon_t^{\,2},\qquad 
\kappa:=\max_{t,\sigma}\|A_t(\sigma)\|\ .\ }
$$

> 说明：由 $\|X\otimes Y\|=\|X\|\,\|Y\|$ 与三角不等式直接得出。

##### (ii) 逐条目一致上界（望远镜展开）

对任意 $x=uv$（$|u|+|v|=L$）及其逐位字母 $x_s$：

$$
\prod_{t=1}^L \widetilde M_{t,x_t}-\prod_{t=1}^L M_{t,x_t}
=\sum_{s=1}^L\Big(\prod_{t=s+1}^L \widetilde M_{t,x_t}\Big)\,\Delta_{s,x_s}\,\Big(\prod_{t=1}^{s-1} M_{t,x_t}\Big),
$$

从而

$$
\boxed{\ 
\begin{aligned}
|H_p(u,v)-\widetilde H_p(u,v)|
&\le \|i\|\,\|f\|\sum_{s=1}^L
\Big(\prod_{t=s+1}^L \kappa_{p,t}\Big)\,\|\Delta_{s,x_s}\|\,\Big(\prod_{t=1}^{s-1} \kappa_{p,t}\Big)\\
&\le \ \|\alpha\|^2\,\|\beta\|^2
\sum_{t=1}^L\Big(2\kappa\,\varepsilon_t+\varepsilon_t^{\,2}\Big)\,
\Big(\prod_{j\neq t}\kappa_{p,j}\Big).
\end{aligned}\ }
$$

**均匀上界（$\kappa_{p,t}\le \kappa_p$）**：

$$
\boxed{\ 
|H_p(u,v)-\widetilde H_p(u,v)|
\ \le\ \|\alpha\|^2\,\|\beta\|^2\ \kappa_p^{\,L-1}\!
\sum_{t=1}^{L}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{\,2}\big)\ .
}
$$

**收缩/非扩张特例（几何放大因子）**：若存在某算子范数使得 $\kappa_{p,t}\le 1$（例如白化后投影到“非负+次随机”锥，并采用 $\|\cdot\|_1/\|\cdot\|_\infty$ 诱导范数），则上式可细化为

$$
\boxed{\ 
|H_p(u,v)-\widetilde H_p(u,v)|\ \le\ 
\|\alpha\|^2\,\|\beta\|^2\ \Big(\sum_{t=1}^{L}(2\kappa\,\varepsilon_t+\varepsilon_t^{\,2})\Big)\ G_{1:L},
}
$$

其中

$$
G_{1:L}\ :=\ \sum_{s=1}^L \prod_{t=s+1}^L \kappa_{p,t}\ \le\ 
\begin{cases}
\dfrac{\kappa_p^{\,L}-1}{\kappa_p-1}, & \text{若 }\kappa_{p,t}\le \kappa_p\ (\kappa_p\neq 1),\\[6pt]
L, & \text{若 }\kappa_{p,t}\le 1\ \forall t.
\end{cases}
$$

（当全部 $\kappa_{p,t}\le 1$ 时，$G_{1:L}\le L$。）

##### (iii) 矩阵谱范数的推论

令 $H_p(P,S)\in\mathbb R^{m\times n}$（仅索引 $|u|+|v|=L$）。由
$\|X\|_2\le \|X\|_F\le \sqrt{mn}\,\|X\|_{\max}$ 与上节逐条目界，得

* **一般（均匀上界版）**

$$
\boxed{\ 
\|H_p(P,S)-\widetilde H_p(P,S)\|_2
\ \le\ \sqrt{mn}\ \|\alpha\|^2\,\|\beta\|^2\ \kappa_p^{\,L-1}
\sum_{t=1}^{L}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{\,2}\big).
}
$$

* **收缩/非扩张特例**

$$
\boxed{\ 
\|H_p(P,S)-\widetilde H_p(P,S)\|_2
\ \le\ \sqrt{mn}\ \|\alpha\|^2\,\|\beta\|^2\ 
\Big(\sum_{t=1}^{L}(2\kappa\,\varepsilon_t+\varepsilon_t^{\,2})\Big)\ G_{1:L}\ .
}
$$

> **简化**（等幅扰动）：若 $\varepsilon_t\le \varepsilon\ll 1$，则
> $\displaystyle \sum_{t=1}^{L}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{\,2}\big)\ \le\ 2\kappa L\,\varepsilon+L\,\varepsilon^{2}$。

**与 §5.4/§5.6 的一致性.**
上面“望远镜 + $\kappa_{p,t}$”即 §5.4 的时变版；取 $\kappa_{p,t}\le \kappa_p$ 得到你原先的 $\kappa_p^{\,L-1}$ 形式。几何放大因子 $G_{1:L}$ 与 §5.6 的时变放大子完全一致；当 $\kappa_{p,t}\le 1$ 时，统一退化为 $O(L)$。


### 5.2　乘积扰动与几何放大：$G_L(\kappa)$ 与转移算子谱半径

**设定.** 对每一层 $t=1,\ldots,L$ 与字母 $\sigma\in\Sigma$，记

$$
M_{t,\sigma}=A_t(\sigma)\otimes\overline{A_t(\sigma)},\qquad
\widetilde M_{t,\sigma}=\widetilde A_t(\sigma)\otimes\overline{\widetilde A_t(\sigma)} ,
$$

以及

$$
E_t(\sigma)=\widetilde A_t(\sigma)-A_t(\sigma),\quad
\Delta_{t,\sigma}=E_t(\sigma)\!\otimes\!\overline{A_t(\sigma)}
+ A_t(\sigma)\!\otimes\!\overline{E_t(\sigma)}
+ E_t(\sigma)\!\otimes\!\overline{E_t(\sigma)}.
$$

令

$$
\kappa_{p,t}:=\max_{\sigma}\big\{\|M_{t,\sigma}\|_2,\ \|\widetilde M_{t,\sigma}\|_2\big\},
\qquad
\kappa_p:=\max_{1\le t\le L}\kappa_{p,t}.
$$

##### 引理 5.3（单步 Liouville 扰动）

若 $\kappa:=\max_{t,\sigma}\|A_t(\sigma)\|_2$ 且 $\varepsilon_t:=\max_\sigma\|E_t(\sigma)\|_2$，则

$$
\boxed{\ \ \|\Delta_{t,\sigma}\|_2\ \le\ 2\,\kappa\,\varepsilon_t\ +\ \varepsilon_t^{\,2}\ .\ }
$$

*说明.* 用 $\|X\otimes Y\|_2=\|X\|_2\|Y\|_2$ 与三角不等式逐项上界即得。

##### 定理 5.4（乘积扰动的望远镜不等式）

对任意具体串 $x=(x_1,\ldots,x_L)\in\Sigma^L$，有恒等式

$$
\prod_{t=1}^L \widetilde M_{t,x_t}-\prod_{t=1}^L M_{t,x_t}
=\sum_{s=1}^L\Big(\prod_{t=s+1}^L \widetilde M_{t,x_t}\Big)\,\Delta_{s,x_s}\,\Big(\prod_{t=1}^{s-1} M_{t,x_t}\Big),
$$

从而

$$
\boxed{\
\Big\|\textstyle\prod_{t=1}^L \widetilde M_{t,x_t}-\prod_{t=1}^L M_{t,x_t}\Big\|_2
\ \le\ \sum_{s=1}^L\Big(\prod_{t=s+1}^L \kappa_{p,t}\Big)\,\|\Delta_{s,x_s}\|_2\,\Big(\prod_{t=1}^{s-1} \kappa_{p,t}\Big).
\ }
$$

若进一步 $\kappa_{p,t}\le \kappa_p$（所有 $t$）则

$$
\boxed{\
\Big\|\textstyle\prod_{t=1}^L \widetilde M_{t,x_t}-\prod_{t=1}^L M_{t,x_t}\Big\|_2
\ \le\ \kappa_p^{\,L-1}\sum_{s=1}^L \|\Delta_{s,x_s}\|_2\ .
\ }
$$

##### 推论5.4.1 (双线性输出的两类上界)

令 $\alpha,\beta$ 为适形向量。

**(A) 普适谱范版（无额外假设，安全）**

$$
\boxed{\
\big|\alpha^\top{\textstyle\prod_t}\widetilde M_{t,x_t}\beta-\alpha^\top{\textstyle\prod_t}M_{t,x_t}\beta\big|
\ \le\ \|\alpha\|_2\,\|\beta\|_2\ \kappa_p^{\,L-1}\!\sum_{s=1}^L \|\Delta_{s,x_s}\|_2.
\ }
$$

若 $\max_s\|\Delta_{s,x_s}\|_2\le \varepsilon$，则

$$
\big|\cdots\big|\ \le\ \|\alpha\|_2\,\|\beta\|_2\ L\,\kappa_p^{\,L-1}\,\varepsilon.
$$

**(B) 非扩张范数下的精炼 $G_L$ 版（需附加条件）**
若存在某**诱导算子范数** $\|\cdot\|_\bullet$ 使

$$
\Big\|\prod_{t=1}^{s-1} M_{t,x_t}\Big\|_\bullet \le 1\quad(\forall s),\qquad
\|\widetilde M_{t,x_t}\|_\bullet\le \kappa_{p,t}^{(\bullet)},
$$

（例如在“非负 + 行/列次随机”锥内，配合 $\|\cdot\|_1$ 或 $\|\cdot\|_\infty$ 可成立），则对相应的向量/对偶范数有

$$
\boxed{\
\big|\alpha^\top{\textstyle\prod_t}\widetilde M_{t,x_t}\beta-\alpha^\top{\textstyle\prod_t}M_{t,x_t}\beta\big|
\ \le\ \|\alpha\|_{\bullet,*}\,\|\beta\|_{\bullet}\ \varepsilon\ G_L(\kappa_p^{(\bullet)}),
\ }
$$

其中 $\varepsilon=\max_s\|\Delta_{s,x_s}\|_\bullet$、$\kappa_p^{(\bullet)}=\max_t \kappa_{p,t}^{(\bullet)}$，

$$
G_L(\kappa)=\sum_{t=0}^{L-1}\kappa^t=
\begin{cases}
\dfrac{\kappa^{L}-1}{\kappa-1}, & \kappa\neq1,\\[4pt]
L, & \kappa=1.
\end{cases}
$$

> 备注：在“白化 + 非负/次随机”坐标（见 §8.2）下可取 $\kappa_p^{(\bullet)}\le 1$，则上界随 $L$ 至多线性增长；若 $\kappa_p^{(\bullet)}<1$ 则对 $L$ 一致有界。

##### 命题 5.5（几何因子 $G_L$ 的基本性质）

对任意 $\kappa\ge0$,

$$
G_L(\kappa)=\sum_{t=0}^{L-1}\kappa^t=
\begin{cases}
\dfrac{\kappa^{L}-1}{\kappa-1}, & \kappa\neq 1,\\[6pt]
L, & \kappa=1.
\end{cases}
$$

于是：

1. 若 $\kappa\le 1$，则 $G_L(\kappa)\le L$（等号当且仅当 $\kappa=1$）。
2. 若 $\kappa<1$，则 $G_L(\kappa)\le \dfrac{1}{1-\kappa}$（与 $L$ 无关）。
3. 若 $\kappa>1$，则 $G_L(\kappa)=\Theta(\kappa^{L})$。

> **与谱半径的关系.** 在左规范下 $\rho(T)=1$（见 §3.1），但这并不蕴含 $\|M_{t,\sigma}\|_\bullet\le 1$。本节的长度放大由**单步算子范数**（$\kappa_{p,t}$、$\kappa_p$ 或在特定锥/范数下的 $\kappa_p^{(\bullet)}$）控制，与 $\rho(T)$ 的稳态/外围谱信息互补。

### 5.3　非齐次（时变）门列的稳定性与上界

令$M_{t,\sigma}:=A_t(\sigma)\otimes \overline{A_t(\sigma)}$,\ $\widetilde M_{t,\sigma}:=\widetilde A_t(\sigma)\otimes \overline{\widetilde A_t(\sigma)}$,
$\Delta_{t,\sigma}:=\widetilde M_{t,\sigma}-M_{t,\sigma}$。为统一覆盖真/扰动两侧，记
$$
\kappa_{p,t}:=\max_{\sigma}\big\{\|M_{t,\sigma}\|_2,\ \|\widetilde M_{t,\sigma}\|_2\big\},\qquad
\epsilon_p(t):=\max_{\sigma}\|\Delta_{t,\sigma}\|_2.
$$

对长度‑$L$ 的 Hankel 子矩阵 $H_p(P,S)\in\mathbb R^{m\times n}$（仅索引 $|u|+|v|=L$），记 $i=\alpha\otimes\overline\alpha,\ f=\beta\otimes\overline\beta$。

##### 定理 5.6（时变情形的稳健上界）

**(A) 一般谱范数上界（无额外收缩假设）**
对任意 $A_t(\sigma)$ 与 $\widetilde A_t(\sigma)$，有
$$
\boxed{\;
\|H_p-\widetilde H_p\|_2\ \le\ C_{P,S}\,
\sum_{s=1}^{L}\epsilon_p(s)\!\!\prod_{t\ne s}\kappa_{p,t}
\ \le\ 
C_{P,S}\,\kappa_p^{\,L-1}\!\sum_{t=1}^{L}\epsilon_p(t),
\;}
$$

其中 $\kappa_p:=\max_t \kappa_{p,t}$，且

$$
C_{P,S}:=\sqrt{mn}\,\|i\|_2\,\|f\|_2=\sqrt{mn}\,\|\alpha\|_2^{\,2}\,\|\beta\|_2^{\,2}.
$$

**(B) 可收缩范数下的“几何和”上界（单侧非扩张）**
若存在某诱导范数 $\|\cdot\|_\bullet$ 使对所有 $s$ 有$\big\|\prod_{t=1}^{s-1}M_{t,x_t}\big\|_\bullet\le 1$ 且$\|M_{t,x_t}\|_\bullet,\ \|\widetilde M_{t,x_t}\|_\bullet\le \kappa_{p,t}^{(\bullet)}$，
则记
$$
G_{1:L}(\kappa^{(\bullet)}):=\sum_{s=1}^{L}\ \prod_{t=s+1}^{L}\kappa_{p,t}^{(\bullet)},
\qquad
\epsilon_p^{(\bullet)}(t):=\max_{\sigma}\|\Delta_{t,\sigma}\|_\bullet,
$$

有

$$
\boxed{\;
\|H_p-\widetilde H_p\|_2
\ \le\ C_{P,S}^{(\bullet)}\,
\Big(\sum_{t=1}^{L}\epsilon_p^{(\bullet)}(t)\Big)\,
G_{1:L}\big(\kappa^{(\bullet)}\big),
\;}
$$

其中 $C_{P,S}^{(\bullet)}$ 仅由 $\sqrt{mn}$、$\|\alpha\|_{\bullet,*}^2$、$\|\beta\|_{\bullet}^2$ 及范数等价常数决定。
特别地，若 $\kappa_{p,t}^{(\bullet)}\le 1$（例如投影到“非负+次随机”锥并取 $\|\cdot\|_1/\|\cdot\|_\infty$），则
$G_{1:L}\le L$，故

$$
\|H_p-\widetilde H_p\|_2\ \le\ C_{P,S}^{(\bullet)}\,\Big(\sum_{t=1}^{L}\epsilon_p^{(\bullet)}(t)\Big)\,L.
$$

**Proof sketch（两种情形共通的要点，简述）**
对任意具体串 $x=(x_1,\dots,x_L)$，望远镜恒等式给出
$$
\prod_{t=1}^L \widetilde M_{t,x_t}-\prod_{t=1}^L M_{t,x_t}
=\sum_{s=1}^{L}\Big(\prod_{t=s+1}^L \widetilde M_{t,x_t}\Big)\Delta_{s,x_s}\Big(\prod_{t=1}^{s-1} M_{t,x_t}\Big).
$$

对每项取范数并上界得到**逐条目**误差

$$
|H_p(u,v)-\widetilde H_p(u,v)|
\le \|i\|\,\|f\|\sum_{s=1}^{L}\epsilon_p(s)\!\!\prod_{t\ne s}\kappa_{p,t},
$$

再由 $\|X\|_2\le \|X\|_F\le \sqrt{mn}\|X\|_{\max}$ 得到 (A)。
若改用 $\|\cdot\|_\bullet$ 且前缀链非扩张，则只保留**后缀**的放大，累加为 $G_{1:L}$，并再由范数等价转回谱范数，得 (B)。

**备注**

1. (A) 与 (B) 互补：(A) 无需任何收缩假设但更保守；(B) 在“白化+非负/次随机”等可收缩坐标下给出随 $L$ 至多线性增长的界。
2. 若 $\epsilon_p(t)\le \varepsilon$ 一致，则 (A) 给出$\|H_p-\widetilde H_p\|_2\le C_{P,S}\,L\,\kappa_p^{L-1}\,\varepsilon$；(B) 在 $\kappa^{(\bullet)}_{p,t}\le 1$ 时给出$\|H_p-\widetilde H_p\|_2\le C_{P,S}^{(\bullet)}\,L^2\,\varepsilon$。
3. 本节统一采用 $G_{1:L}$（后缀几何和）记号，与 §5.2 的定义一致。


---

## 第6章　可辨识性、条件数与最小实现

### 6.1　Gram 判据与 $\sigma_{\min}$ 下界（行列式/迹不等式）

**定理 6.1（限制‑Gram 下界）**
设 $H=O_PC_S$，令 $r=\operatorname{rank}H$。记 $k=\operatorname{rank}(C_S)$，取 $U\in\mathbb R^{D^2\times k}$ 为 $\mathrm{col}(C_S)$ 的任一正交基（$U^\top U=I_k$）。定义
$$
\mathcal O_P:=U^\top O_P^\top O_P\,U\in\mathbb R^{k\times k},\qquad
\mathcal C_S:=U^\top C_S C_S^\top\,U\in\mathbb R^{k\times k}.
$$

则

$$
\boxed{\quad
\sigma_r(H)\ \ge\ \sqrt{\lambda_{\min}(\mathcal O_P)}\;\sqrt{\lambda_{r}(\mathcal C_S)}\ .
\quad}
$$

**特例（$k=r$ 时）**：若 $\operatorname{rank}(C_S)=r$，则

$$
\boxed{\quad
\sigma_r(H)\ \ge\ \sqrt{\lambda_{\min}(\mathcal O_P)}\;\sqrt{\lambda_{\min}(\mathcal C_S)}\ .
\quad}
$$

*证明（要点）.* 写

$$
H^\top H=C_S^\top O_P^\top O_PC_S=(U^\top C_S)^\top\,\underbrace{(U^\top O_P^\top O_PU)}_{=\mathcal O_P}\,(U^\top C_S).
$$

由 Loewner 序 $\mathcal O_P\succeq \lambda_{\min}(\mathcal O_P)I$ 得

$$
H^\top H\ \succeq\ \lambda_{\min}(\mathcal O_P)\,(U^\top C_S)^\top(U^\top C_S),
$$

对第 $r$ 个特征值取下界即
$\sigma_r(H)^2=\lambda_r(H^\top H)\ge \lambda_{\min}(\mathcal O_P)\,\lambda_r\!\big((U^\top C_S)(U^\top C_S)^\top\big) = \lambda_{\min}(\mathcal O_P)\,\lambda_r(\mathcal C_S)$。
$k=r$ 时把 $\lambda_r$ 退化为 $\lambda_{\min}$ 即得特例。□

> *备注.* 若愿意用 $r\times r$ 形式：任取 $U_r\in\mathbb R^{D^2\times r}$ 使 $\mathrm{span}(U_r)\subseteq \mathrm{col}(C_S)$ 且 $\operatorname{rank}(U_r^\top C_S)=r$，则同理有
> $\displaystyle \sigma_r(H)\ \ge\ \sqrt{\lambda_{\min}(U_r^\top O_P^\top O_P U_r)}\;\sqrt{\lambda_{\min}(U_r^\top C_S C_S^\top U_r)}$。

**（行列式/迹下界）** 若 $\|\ell_p(u)\|_2\le 1,\ \|r_p(v)\|_2\le 1$，则

$$
\operatorname{tr}(\mathcal O_P)=\|O_PU\|_F^2=\sum_{u\in P}\|U^\top \ell_p(u)\|_2^2\le |P|,\qquad
\operatorname{tr}(\mathcal C_S)=\|U^\top C_S\|_F^2=\sum_{v\in S}\|U^\top r_p(v)\|_2^2\le |S|.
$$

因此对任何 $q\times q$ 的 PSD 矩阵 $A$ 有 $\lambda_{\min}(A)\ge \det(A)/\operatorname{tr}(A)^{\,q-1}$，从而：

* 当 $k=r$ 时，

$$
\lambda_{\min}(\mathcal O_P)\ \ge\ \frac{\det(\mathcal O_P)}{|P|^{\,r-1}},\qquad
\lambda_{\min}(\mathcal C_S)\ \ge\ \frac{\det(\mathcal C_S)}{|S|^{\,r-1}}.
$$

* 一般 $k\ge r$ 时，对上一“$r\times r$”版本（取 $U_r$）同样成立。

**命题 6.2（log‑det 子模与 $\sigma_{\min}$ 的桥接）**
定义
$$
F_P(\mathcal S)=\log\det\!\Big(I+\lambda^{-1}\!\!\sum_{u\in\mathcal S}\ell_p(u)\ell_p(u)^\top\Big),\qquad \lambda>0.
$$

则 $F_P$ 关于集合 **单调且子模**；在基数约束 $|\mathcal S|=m$ 下，贪心选择达到 $(1-1/e)$ 近似最优。
此外，设 $M_P:=\sum_{u\in P}\ell_p(u)\ell_p(u)^\top\succeq0$，对任意 $r$ 与任意正交 $U_r\in\mathbb R^{D^2\times r}$ 有
$$
\boxed{\quad
\det\!\big(U_r^\top M_P U_r\big)\ \le\ \lambda^{r}\,\det\!\big(I+\lambda^{-1}M_P\big)\ .
\quad}
$$

因此**最大化 $F_P$** 将**单调**提升所有这类压缩行列式（特别是取 $\mathrm{span}(U_r)\subseteq\mathrm{col}(C_S)$ 的那些），再配合定理 6.1 的限制‑Gram 下界，即可提升 $\sigma_r(H)$ 的保守下界。

*证明要点.* 单调/子模性由 $\log\det$ 在 PSD 锥上的单调性与“收益递减”公式
$\Delta(u\mid\mathcal S)=\log(1+\lambda^{-1}\ell_p(u)^\top (I+\lambda^{-1}M_{\mathcal S})^{-1}\ell_p(u))$ 直接得出；贪心近似为经典结论。对桥接式，令 $\mu_1\ge\cdots\ge \mu_r$ 为 $U_r^\top M_P U_r$ 的特征值，有 $\mu_i\le \lambda_i(M_P)$（Courant–Fischer 压缩谱界），于是
$$
\det(U_r^\top M_P U_r)=\textstyle\prod_{i=1}^r \mu_i
\ \le\ \prod_{i=1}^r \lambda_i(M_P)
\ \le\ \prod_{i=1}^r \lambda\Big(1+\tfrac{\lambda_i(M_P)}{\lambda}\Big)
\ \le\ \lambda^r \det\!\big(I+\lambda^{-1}M_P\big).
$$

> *提示.* $(1-1/e)$ 的近似保证仅适用于 $F_P$ 本身；对 $\sigma_{\min}(H)$ 我们给出的是“单调桥接”的保守提升，而非近似比保证。


### 6.2　可观测/可控制性与最小实现；相似变换与规范化

> 设 $\mathbb F\in\{\mathbb R,\mathbb C\}$。除非另述，$H$ 指**无限 Hankel** 矩阵 $H(u,v)=p(uv)$；有限长度情形以**块‑Hankel** $H^{(\le L)}$ 取代，并仅对 $|w|\le L$ 断言。
> 记 $(\cdot)^\top$ 为转置；在涉及 SVD/白化处，复数域用共轭转置 $(\cdot)^\dagger$。

##### 定义 6.3（可观测 / 可控制子空间）

给定 WFA 表示 $(i,\{B_\sigma\},f)$，记 $B_u:=B_{u_1}\cdots B_{u_{|u|}}$。定义

$$
\mathcal O:=\operatorname{span}\{\,i^\top B_u:\ u\in\Sigma^\ast\},\qquad
\mathcal C:=\operatorname{span}\{\,B_v f:\ v\in\Sigma^\ast\}.
$$

令无限 Hankel 矩阵 $H(u,v)=p(uv)$。

**（无限长度）**
始终有

$$
\operatorname{rank} H\ \le\ \min\{\dim\mathcal O,\ \dim\mathcal C\}.
$$

若该表示**最小**（同时可达且可观测），则

$$
\operatorname{rank} H\ =\ \dim\mathcal O\ =\ \dim\mathcal C .
$$

**（有限长度 / 块‑Hankel）**
给定 $L\ge0$，定义

$$
\mathcal O^{(\le L)}:=\operatorname{span}\{\,i^\top B_u:\ |u|\le L\},\quad
\mathcal C^{(\le L)}:=\operatorname{span}\{\,B_v f:\ |v|\le L\}.
$$

用所有满足 $|u|\!,|v|\!\ge0,\ |u|+|v|\le L$ 的索引对 $(u,v)$ 构成**块‑Hankel** $H^{(\le L)}$，并记

$$
r_L:=\operatorname{rank} H^{(\le L)} .
$$

则

$$
r_L\ \le\ \min\{\dim\mathcal O^{(\le L)},\ \dim\mathcal C^{(\le L)}\}.
$$

若选择有限索引集合 $P\subseteq\Sigma^{\le L}$、$S\subseteq\Sigma^{\le L}$，使得

$$
\operatorname{span}\{\,i^\top B_u:\ u\in P\,\}=\mathcal O^{(\le L)},\qquad
\operatorname{span}\{\,B_v f:\ v\in S\,\}=\mathcal C^{(\le L)},
$$

并以所有满足 $|u|+|v|\le L$ 的 $(u,v)\in P\times S$ 取子矩阵 $H^{(\le L)}(P,S)$，则

$$
\operatorname{rank} H^{(\le L)}(P,S)\ =\ r_L .
$$

特别地，若**截断最小性**成立（$\dim\mathcal O^{(\le L)}=\dim\mathcal C^{(\le L)}=r_L$），则有

$$
\operatorname{rank} H^{(\le L)}\ =\ \dim\mathcal O^{(\le L)}\ =\ \dim\mathcal C^{(\le L)}\ =\ r_L .
$$

##### 定理 6.4（最小实现与 Hankel 秩等价；唯一到相似）

若 $\operatorname{rank}H=r<\infty$，则存在维度为 $r$ 的线性表示 $(i,\{B_\sigma\},f)$ 使

$$
p(w)=i^\top B_w f,\qquad \forall\,w\in\Sigma^\ast,
$$

且任何再现同一 $p(\cdot)$ 的表示维度 $\ge r$。任意两组**最小**表示唯一到相似变换：存在可逆 $Q\in\mathrm{GL}(r)$ 使

$$
i'=Q^\top i,\qquad f'=Q^{-1}f,\qquad B'_\sigma=Q^{-1}B_\sigma Q\ \ (\forall\sigma).
$$

**有限长度（块‑Hankel）版.** 令 $r_L=\operatorname{rank}H^{(\le L)}$。则存在维度为 $r_L$ 的表示，用**同一**组 $\{B_\sigma\}$ 同时再现所有 $|w|\le L$ 的值；任何能在 $|w|\le L$ 上再现的表示维度 $\ge r_L$。

##### 命题 6.5（恒等校准：白化/平衡化后一致恒等）

设经验 Hankel $\widehat H\in\mathbb F^{m\times n}$ 的**截断秩**为 $r$，其截断 SVD 为

$$
\widehat H=U_r\Sigma_r V_r^\dagger,\qquad \Sigma_r\succ0.
$$

取任意 $\lambda\ge0$，令

$$
W'_L=(\Sigma_r+\lambda I)^{-1/2}U_r^\dagger,\quad
W'_R=V_r(\Sigma_r+\lambda I)^{-1/2},\quad
\widehat S:=W'_L\,\widehat H\,W'_R\ (\succ0),
$$

并定义

$$
W_L=\widehat S^{-1/2}W'_L,\qquad W_R=W'_R\,\widehat S^{-1/2}.
$$

则在秩‑$r$ 子空间上**严格有**

$$
W_L\,\widehat H\,W_R=I_r.
$$

令后缀首字母的列掩膜 $\{\Pi_\sigma\}_{\sigma\in\Sigma}$ 互斥且完备（$\sum_\sigma \Pi_\sigma=I$），设

$$
\widehat H_\sigma=\widehat H\,\Pi_\sigma,\qquad \widehat B_\sigma=W_L\,\widehat H_\sigma\,W_R,
$$

则同样**严格有**

$$
\sum_{\sigma\in\Sigma}\widehat B_\sigma=I_r.
$$

> 数值备注：若为稳定性将 $\widehat S$ 替换为 $\widehat S+\varepsilon I\ (\varepsilon>0)$，则上述等式在秩‑$r$ 子空间内变为高精度近似，偏差由 $\varepsilon$ 控制。

### 6.3　条件数、信息可达性与相位/基对齐

> 本节统一使用谱范数 $\|\cdot\|_2$。所有陈述在给定的符号与构造下**无额外隐含假设**，且均可直接验证。

##### 定义 6.6（相干度） 

$$
\mu:=\max\Big\{\max_{u}\sum_{v}p(u,v),\ \max_{v}\sum_{u}p(u,v)\Big\}\in[0,1].
$$

它是长度‑$L$ Hankel 层的最大行/列边缘概率；在 §9 的矩阵 Bernstein / Freedman 集中不等式中，$\mu$ 作为方差尺度出现。

##### 命题 6.7（恒等校准与对齐不变性）

令 $H\in\mathbb R^{m\times n}$ 为长度‑$L$ 的概率‑Hankel 子矩阵，截断秩为 $r$，其非零奇异值为
$\sigma_1\ge\cdots\ge\sigma_r=\gamma>0$。取白化与“恒等校准”如下：

$$
W'_L=(\Sigma_r+\lambda_{\rm wh} I)^{-1/2}U_r^\top,\quad 
W'_R=V_r(\Sigma_r+\lambda_{\rm wh} I)^{-1/2},
$$

$$
\widehat S=W'_L\,\widehat H\,W'_R,\qquad 
W_L=\widehat S^{-1/2}W'_L,\quad W_R=W'_R\,\widehat S^{-1/2}.
$$

定义

$$
\widehat B_\sigma:=W_L\,\widehat H_\sigma\,W_R\quad(\sigma\in\Sigma).
$$

1. **恒等和**：$\displaystyle \sum_{\sigma\in\Sigma}\widehat B_\sigma=I_r$。
2. **正交共轭不变性**：对任意 $R\in O(r)$，$\sum_{\sigma}R^\top \widehat B_\sigma R=I_r$。
3. **统一对齐存在性**：取 $R=\operatorname{polar}((W_R^\star)^{\!\top}W_R)\in O(r)$，则该单一 $R$ 同时对齐所有 $\{\widehat B_\sigma\}$ 与真值坐标，不改变恒等和。

*说明.* 第 1) 为校准构造的代数恒等式；第 2)–3) 为线性代数基本事实（极分解），与数据噪声无关。

##### 引理 6.8（数据残差在真白化坐标下的保守上界） 

$$
W_L^{\prime\star}=(\Sigma_r+\lambda_{\rm wh} I)^{-1/2}U_r^\top,\quad 
W_R^{\prime\star}=V_r(\Sigma_r+\lambda_{\rm wh} I)^{-1/2},
$$

$$
S^\star=W_L^{\prime\star}H\,W_R^{\prime\star}
=(\Sigma_r+\lambda_{\rm wh} I)^{-1/2}\,\Sigma_r\,(\Sigma_r+\lambda_{\rm wh} I)^{-1/2}\succ0.
$$

定义“**真白化坐标**”下的估计块

$$
\breve B_\sigma:=S^{\star-1/2}\,W_L^{\prime\star}\,\widehat H_\sigma\,W_R^{\prime\star}\,S^{\star-1/2},\qquad
B_\sigma^\star:=S^{\star-1/2}\,W_L^{\prime\star}\,H_\sigma\,W_R^{\prime\star}\,S^{\star-1/2}.
$$

记 $\Delta:=\|\widehat H-H\|_2$、$\gamma:=\sigma_r(H)>0$、$\gamma_\lambda:=\gamma+\lambda_{\rm wh}$。则

$$
\boxed{\quad
\|\breve B_\sigma-B_\sigma^\star\|_2
\ \le\ \frac{\Delta}{\gamma}\qquad (\forall\,\sigma\in\Sigma).
\quad}
$$

*证明（一步式）.*

$$
\|\breve B_\sigma-B_\sigma^\star\|
=\|S^{\star-1/2}W_L^{\prime\star}(\widehat H_\sigma-H_\sigma)W_R^{\prime\star}S^{\star-1/2}\|
\le \|S^{\star-1/2}\|^2\|W_L^{\prime\star}\|\,\|W_R^{\prime\star}\|\,\|\widehat H_\sigma-H_\sigma\|.
$$

其中 $\|W_L^{\prime\star}\|=\|W_R^{\prime\star}\|=(\gamma_\lambda)^{-1/2}$，
$\|S^{\star-1/2}\|^2=\gamma_\lambda/\gamma$，且 $\|\widehat H_\sigma-H_\sigma\|\le \|\widehat H-H\|=\Delta$。合并得 $\Delta/\gamma$。

> 注：该界**不需要**子空间错位或矩阵函数扰动分析；仅依赖 $\gamma>0$ 与算子范数乘法性，因而稳健可靠。它比较的是在**固定真白化坐标**下的逐字母块 $\breve B_\sigma$ 与 $B_\sigma^\star$。
> 与之相对，$\widehat B_\sigma$（校准坐标用 $\widehat S$）的更细界需要额外的子空间与函数扰动工具，本收缩版不主张该类更强断言。

##### 备注 6.9（实践含义） 

* **恒等和与统一对齐**保证了：校准后 $\{\widehat B_\sigma\}$ 在旋转不变意义下可直接比较、组合与复现实验；该不变量对后续建模与评估至关重要。
* **引理 6.8**提供了一个**无条件**的保守上界：在真白化坐标下，仅由 $\Delta/\gamma$ 控制逐字母误差。若需要把界转移到“校准坐标”（使用 $\widehat S$）或获得更精细的长度传播界，应额外引入子空间扰动与矩阵函数扰动的标准引理（参见矩阵扰动理论）；本节为求“无懈可击”，不作该类扩展主张。

---

## 第7章　下界、反例与典型性

> 设 $H_p(P,S)$ 为长度 $L$、切分点 $t_\star$ 下仅索引 $|u|+|v|=L$ 的概率‑Hankel 子矩阵，$m=|P|,\ n=|S|$。

### 7.1　随机/高纠缠电路的“满秩倾向”

**定理 7.1（几乎处处满秩，受 $D^2$ 约束）**
固定 $L,t_\star,P,S$。若 $|\psi\rangle$ 的分布对 Haar 测度**绝对连续**，则

$$
\Pr\!\big[\operatorname{rank}H_p(P,S)=\min\{m,n\}\big]=1.
$$

若进一步已知 $|\psi\rangle$ 可由 MPS 键维 $D$ 表达（从而 $\operatorname{rank}H_p\le D^2$），且参数分布对相应参数空间的勒贝格测度绝对连续，并且存在一组参数使某个 $\min{D^2,m,n}$ 阶主子式非零（该行列式多项式非常值），则

$$
\Pr\!\big[\operatorname{rank}H_p(P,S)=\min\{D^2,m,n\}\big]=1.
$$

*说明.* 不满秩等价于若干主子式多项式同时为零；非常值多项式的零集在连续分布下测度为零。离散族（如 Clifford 精确 2‑design）不满足绝对连续，因而不适用此“几乎处处”结论。

### 7.2　劣条件与不可学区域

> 默认“平方”为逐元素平方；二元字母表；完全枚举该层时 $m=|P|=2^{t_*},\ n=|S|=2^{L-t_*}$。**整体归一化只会乘一个公共比例因子，不影响以下秩与夹逼结论。**

##### 7.2A（精确降秩的极端反例）

取 $D=2$，

$$
A(0)=\mathrm{diag}(1,\eta),\quad A(1)=\mathrm{diag}(\eta,1)\ (0<\eta<1),\quad
\alpha=\beta=e_1 .
$$

则对任意 $u,v$,

$$
H_a(u,v)=\eta^{\#1(u)+\#1(v)},\qquad
H_p(u,v)=\eta^{2\#1(u)}\eta^{2\#1(v)}=a(u)\,b(v),
$$

即 $H_p=a\,b^\top$ 为外积，因而

$$
\operatorname{rank}H_p(P,S)=1\qquad(\text{任意 }P,S,L).
$$

##### 7.2B（“近奇异”但稳健的形态）

取边界 $\alpha=\beta=[1,\ c]^\top$（$0<c\le1$），令

$$
H_a(u,v)=A(u,v)+c^2 C(u,v),\quad
A(u,v)=\eta^{\#1(u)+\#1(v)},\quad
C(u,v)=\eta^{\#0(u)+\#0(v)}.
$$

则

$$
H_p=(A+c^2C)^{\circ 2}=A^{\circ2}+2c^2(A\!\circ C)+c^4 C^{\circ2},
$$

三项均为秩‑1 外积，故 $\operatorname{rank}H_p\le 3$。

**完全枚举层的谱范数：** 记

$$
a_u=\eta^{\#1(u)},\ b_v=\eta^{\#1(v)},\ c_u=\eta^{\#0(u)},\ d_v=\eta^{\#0(v)} .
$$

则

$$
A^{\circ2}=(a^{\circ2})(b^{\circ2})^\top,\quad
C^{\circ2}=(c^{\circ2})(d^{\circ2})^\top,\quad
A\!\circ C=(a\!\circ c)(b\!\circ d)^\top=\eta^L\,\mathbf 1_m\mathbf 1_n^\top,
$$

从而

$$
\|A^{\circ2}\|_2=(1+\eta^4)^{L/2},\quad
\|c^4C^{\circ2}\|_2=c^4(1+\eta^4)^{L/2},\quad
\|2c^2(A\!\circ C)\|_2=2c^2\,\eta^L\sqrt{mn}=2c^2(\sqrt2\,\eta)^L .
$$

**奇异值夹逼（关键不等式）：** 设

$$
H_0:=A^{\circ2}+c^4 C^{\circ2},\qquad E:=2c^2(A\!\circ C),\qquad H_p=H_0+E.
$$

记（两侧列向量归一化后的）夹角余弦

$$
\rho_U=\frac{\langle a^{\circ2},c^{\circ2}\rangle}{\|a^{\circ2}\|\|c^{\circ2}\|}
=\Big(\tfrac{2\eta^2}{1+\eta^4}\Big)^{t_*},\qquad
\rho_V=\Big(\tfrac{2\eta^2}{1+\eta^4}\Big)^{L-t_*}.
$$

则有

$$
\boxed{\ \ \sigma_3(H_p)\ \le\ \|E\|_2\ =\ 2c^2(\sqrt2\,\eta)^L\ ,\ }
$$

以及（乘法型下界 + Gram‑特征值）

$$
\boxed{\sigma_2\left(H_0\right) \geq \frac{c^4}{1+c^4}\left(1+\eta^4\right)^{L / 2} \sqrt{\left(1-\rho_U^2\right)\left(1-\rho_V^2\right)}}
$$

进一步用 $|\sigma_k(X+Y)-\sigma_k(X)|\le \|Y\|_2$ 得

$$
\boxed{\sigma_2\left(H_p\right) \geq \frac{c^4}{1+c^4}\left(1+\eta^4\right)^{L / 2} \sqrt{\left(1-\rho_U^2\right)\left(1-\rho_V^2\right)}-2 c^2(\sqrt{2} \eta)^L}
$$

> 注：当 $c$ 不太小且 $\eta<1$ 固定、$\rho_U,\rho_V$ 未退化到 1 时，右式主项随 $L$ 呈 $(1+\eta^4)^{L/2}$ 级增长；近奇异仅在 $c\to0$ 或 $\eta\to1$（导致 $\rho_{U/V}\to1$）时出现。

### 7.3　样本复杂度的流程依赖（谱学习/白化‑反演）

记 one‑shot 频数估计的谱误差 $\Delta=|\widehat H-H|_2$，其典型规模为 $\Delta\approx \sqrt{\mu/N}$（忽略常数与对数因子；$\mu$ 为第9章定义的相干度）。对白化‑反演‑再递推的**整层重建**流程，有两道门槛：

1. **白化/反演稳定门槛（必要）**
   为避免 $1/\sigma_{\min}(H_p)$ 的放大失控，需要

$$
\boxed{\quad N\ \gtrsim\ \frac{\mu}{\sigma_{\min}(H_p)^2}\ .\quad}
$$

2. **达到点态精度 $\varepsilon$ 的总体规模（充分阶）**
   由第11章的端到端传播（长度放大 $G_L(\kappa_B)$、白化正则 $\gamma_\lambda$ 与谱隙 $\mathrm{gap}$），需

$$
\boxed{\quad
N\ \gtrsim\ 
\frac{\mu\,G_L(\kappa_B)^2}{\varepsilon^2}\,
\Big(\tfrac{1}{\mathrm{gap}}+\tfrac{1}{\gamma_\lambda}\Big)^{\!2}.
\quad}
$$

综合取两者的最大（常数与对数项略）。

> **仅估计单点 $p(x)$**：直接频数法已达 $N=\Theta(\varepsilon^{-2})$，与 $\sigma_{\min}(H_p)$ 无关；上述标度专指“经由 Hankel‑反演同时重建整层分布”的流程。

### 7.4　无结构情形的信息论下界

**命题 7.4（维度下界）**
若不施加近低秩或收缩/有界范数等结构，学习长度 $L$ 的分布 $p(\cdot)$ 至 TV 误差 $\varepsilon$ 至少需要

$$
\boxed{\quad N\ \ge\ \Omega\!\big(d^L/\varepsilon^2\big),\quad}
$$

与状态空间大小同阶（经典分布估计的 minimax 下界）。

---

## 第8章　稳健性与扩展范畴

### 8.1　小扰动稳健：门噪声到 $H_p$ 的传递界

##### 定理 8.1（端到端噪声传递）

设 $\|E_t(\sigma)\|_2\le \varepsilon_t$。则有以下两种严格有效的上界：

**(A) 普适谱范数版（无任何收缩假设）**

$$
\boxed{\ 
\|H_p-\widetilde H_p\|_2
\ \le\ 
C_{P,S}\,\kappa_p^{\,L-1}\!
\sum_{t=1}^{L}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{2}\big).
\ }
$$

**(B) 可收缩范数版（白化/投影后常用）**
若存在某诱导范数 $\|\cdot\|_\bullet$ 使对全部 $s$ 有 $\big\|\prod_{t=1}^{s-1}M_{t,x_t}\big\|_\bullet\le 1$，且
$\|M_{t,\sigma}\|_\bullet,\ \|\widetilde M_{t,\sigma}\|_\bullet\le \kappa_{p,t}^{(\bullet)}$，则

$$
\boxed{\ 
\|H_p-\widetilde H_p\|_2
\ \le\
C_{P,S}^{(\bullet)}\,
\Big(\sum_{t=1}^{L}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{2}\big)\Big)\,
G_{1:L}\!\big(\kappa^{(\bullet)}\big),
\ }
$$

其中 $G_{1:L}(\kappa):=\sum_{s=1}^{L}\prod_{t=s+1}^{L}\kappa_{p,t}$；当 $\kappa_{p,t}^{(\bullet)}\le 1$ 时 $G_{1:L}\le L$。
常数 $C_{P,S}^{(\bullet)}$ 仅由 $\sqrt{mn}$、$\|\alpha\|_{\bullet,*}^2$、$\|\beta\|_{\bullet}^2$ 及范数等价常数决定。

> **简化（小扰动一致上界）**：若 $\varepsilon_t\le \varepsilon\ll 1$，则
> (A) 给出 $\|H_p-\widetilde H_p\|_2\ \le\ C_{P,S}\,(2\kappa+\varepsilon)\,L\,\kappa_p^{L-1}\,\varepsilon$；
> (B) 在 $\kappa_{p,t}^{(\bullet)}\le 1$ 时给出 $\|H_p-\widetilde H_p\|_2\ \le\ C_{P,S}^{(\bullet)}\,(2\kappa+\varepsilon)\,L\,\varepsilon$。

*Proof sketch.* 由乘积望远镜恒等式（第 5 章）结合 $\|\Delta_{t,\sigma}\|_2$ 的单步界；逐条目上界与 $\|X\|_2\le \|X\|_F\le \sqrt{mn}\|X\|_{\max}$ 转为谱范数；(B) 仅对后缀链计放大，累加得几何和 $G_{1:L}$。

##### 推论 8.2（逐割截断与门噪声的合并界）

若在逐割最优截断后得到 $\tilde H_p$（截断尾能量 $\{\epsilon_t\}$），并再施加上述门扰动得到 $\widehat H_p$，则
$$
\boxed{\ 
\|H_p-\widehat H_p\|_2
\ \le\
\underbrace{2\Big(\textstyle\sum_{t}\epsilon_t^{2}\Big)^{\!1/2}}_{\displaystyle:=\ \Delta_H\ \ (\le 4\tau)}
\ +\
\begin{cases}
\displaystyle C_{P,S}\,\kappa_p^{\,L-1}\!\sum_{t}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{2}\big), & \text{(A)} \\[8pt]
\displaystyle C_{P,S}^{(\bullet)}\!\Big(\sum_{t}\big(2\kappa\,\varepsilon_t+\varepsilon_t^{2}\big)\Big)\,G_{1:L}\!\big(\kappa^{(\bullet)}\big), & \text{(B)}
\end{cases}
}
$$

其中 $\tau=\sum_t \epsilon_t$。上式分别对应定理 8.1 的两种情形。

### 8.2　非负/次随机锥与可收缩范数（从 $G_L(\kappa_B^{(\bullet)})$ 向 $O(L)$）

##### 设定与记号（匹配范数；统一写法） 

令
$$
\mathcal K_{\rm row}=\Big\{\{B_\sigma\}:\ B_\sigma\ge 0,\ \sum_{\sigma}B_\sigma\ \text{行随机}\Big\},\qquad
\mathcal K_{\rm col}=\Big\{\{B_\sigma\}:\ B_\sigma\ge 0,\ \sum_{\sigma}B_\sigma\ \text{列随机}\Big\}.
$$

- 当 $\{B_\sigma\}\in\mathcal K_{\rm row}$ 时，我们采用诱导范数 $\|\cdot\|_\bullet:=\|\cdot\|_\infty$（矩阵最大行和）；其对偶向量范数为 $\|\cdot\|_{\bullet,*}=\|\cdot\|_1$。
- 当 $\{B_\sigma\}\in\mathcal K_{\rm col}$ 时，采用 $\|\cdot\|_\bullet:=\|\cdot\|_1$（最大列和）；其对偶为 $\|\cdot\|_{\bullet,*}=\|\cdot\|_\infty$。

在本节中，记
$$
\boxed{\ \kappa_B^{(\bullet)}\ :=\ \max_{\sigma}\,\|B_\sigma\|_\bullet\ .\ }
$$
几何因子统一记为
$$
G_L\big(\kappa\big)=\sum_{t=0}^{L-1}\kappa^t=
\begin{cases}
\dfrac{\kappa^{L}-1}{\kappa-1}, & \kappa\neq 1,\\[6pt]
L, & \kappa=1.
\end{cases}
$$

##### 定理 8.3（收缩性与长度 $O(L)$ 界；匹配范数版）

若 $\{B_\sigma\}\in\mathcal K_{\rm row}$（分别地 $\mathcal K_{\rm col}$），则在匹配诱导范数下成立
$$
\boxed{\ \ \max_{\sigma}\|B_\sigma\|_\bullet\ \le\ 1,\qquad
\Big\|\prod_{t=1}^L B_{x_t}\Big\|_\bullet\ \le\ 1\quad(\forall\,x\in\Sigma^L).\ \ }
$$
因此在 §5 的望远镜展开中，几何因子满足
$$
\boxed{\ \ G_L\big(\kappa_B^{(\bullet)}\big)\ \le\ L,\quad \text{从而长度依赖统一降为 } O(L).\ \ }
$$
**理由（要点，行随机情形；列随机对偶同理）**：由 $B_\sigma\ge0$ 且 $\sum_\sigma B_\sigma$ 行随机，逐行求和得
$$
\sum_j (B_\sigma)_{ij}\ \le\ \sum_j \sum_\tau (B_\tau)_{ij}\ =\ 1\quad(\forall i),
$$
故每个 $B_\sigma$ 行**次**随机，$\|B_\sigma\|_\infty\le 1$。两非负行次随机矩阵 $M,N$ 的乘积仍行次随机（$N\mathbf e\le \mathbf e \Rightarrow MN\mathbf e\le M\mathbf e\le \mathbf e$），故
 $\big\|\prod_{t=1}^L B_{x_t}\big\|_\infty\le 1$。列随机 + $\|\cdot\|_1$ 完全对偶。□

> **备注（必要性）**：非负性 $B_\sigma\ge 0$ 是不可或缺的。若允许负元，虽然 $\sum_\sigma B_\sigma$ 可为行/列随机，但单个 $B_\sigma$ 的诱导范数可能 **>1**（正负抵消），则非扩张不再保证。

##### 命题 8.4（投影偏差的小量性；两种等价上界）

将估计 $\{\widehat B_\sigma\}$ 投影到 $\mathcal K_{\rm row}$（或 $\mathcal K_{\rm col}$）得到
 $\{\widehat B_\sigma^{\rm proj}\}$。令
$$
\boxed{\ \ \delta\ :=\ \max_{\sigma}\,\big\|\widehat B_\sigma-\widehat B_\sigma^{\rm proj}\big\|_\bullet.\ \ }
$$
则对任意字串 $x=x_{1:L}$ 与边界向量 $\alpha,\beta$（匹配对偶范数对）成立
$$
\boxed{\ 
\begin{aligned}
\big|\alpha^\top\big(\textstyle\prod_{t=1}^L\widehat B_{x_t}^{\rm proj}-\prod_{t=1}^L\widehat B_{x_t}\big)\beta\big|
&\le\ \|\alpha\|_{\bullet,*}\,\|\beta\|_{\bullet}\,\delta\sum_{s=1}^{L}(1+\delta)^{s-1}\\
&=\ \|\alpha\|_{\bullet,*}\,\|\beta\|_{\bullet}\,\big((1+\delta)^{L}-1\big) \quad \text{（闭式界）}\\[2pt]
&\le\ \|\alpha\|_{\bullet,*}\,\|\beta\|_{\bullet}\,L\,\delta\,(1+\delta)^{L-1}\quad \text{（简化界）}.
\end{aligned}\ }
$$
**证明（要点）**：望远镜展开
$$
\prod_{t=1}^L \widehat B^{\rm proj}_{x_t}-\prod_{t=1}^L \widehat B_{x_t}
=\sum_{s=1}^{L}\Big(\prod_{t=s+1}^{L}\widehat B^{\rm proj}_{x_t}\Big)\,\Delta_{x_s}\,\Big(\prod_{t=1}^{s-1}\widehat B_{x_t}\Big),
\quad \Delta_{x_s}=\widehat B^{\rm proj}_{x_s}-\widehat B_{x_s}.
$$
投影后链属于 $\mathcal K\Rightarrow \big\|\prod_{t=s+1}^{L}\widehat B^{\rm proj}_{x_t}\big\|_\bullet\le 1$；
 $\|\widehat B_{x_t}\|_\bullet\le \|\widehat B_{x_t}^{\rm proj}\|_\bullet+\|\Delta_{x_t}\|_\bullet\le 1+\delta$ $\Rightarrow$
 $\big\|\prod_{t=1}^{s-1}\widehat B_{x_t}\big\|_\bullet\le (1+\delta)^{s-1}$。
 再用对偶范数不等式 $|\alpha^\top M\beta|\le \|\alpha\|_{\bullet,*}\|M\|_\bullet\|\beta\|_\bullet$ 并求和即得。□

**小尺度近似（更直观）**：若 $L\delta\le c$，利用 $(1+\delta)^L\le e^{L\delta}\le e^c$ 得
$$
\sum_{s=1}^{L}(1+\delta)^{s-1}=\frac{(1+\delta)^L-1}{\delta}\ \le\ \frac{e^{L\delta}-1}{\delta}\ \le\ \frac{e^c-1}{c}\cdot L,
$$
于是
$$
\boxed{\ \ 
\big|\cdots\big|\ \le\ C(c)\,\|\alpha\|_{\bullet,*}\,\|\beta\|_{\bullet}\,L\,\delta,\qquad
C(c):=\frac{e^c-1}{c}\ .
\ \ }
$$
这说明投影仅引入 **$O(L\delta)$** 级的附加点态误差，不改变随样本量的收敛阶（典型地 $\delta=O_\mathbb{P}(1/\sqrt N)$）。

##### 推论 8.4.1（归一化对误差的影响）

设（如 §12.2/§12.4）在秩‑$r$ 子空间有
 $\sum_\sigma \widehat B_\sigma=I$ 且经投影后 $\sum_\sigma \widehat B_\sigma^{\rm proj}=I$（逐元素或矩阵意义皆可）。取固定的 $\widehat\alpha,\widehat\beta$（按 §12.3 的边界估计构造，与投影无关），令 $Z=\widehat\alpha^\top\widehat\beta>0$，并用同一 $Z$ 做质量重标定 $\widehat\beta\leftarrow \widehat\beta/Z$。则
$$
\begin{aligned}
&\Big|\tfrac{1}{Z}\widehat\alpha^\top\Big(\prod_t\widehat B^{\rm proj}_{x_t}-\prod_t\widehat B_{x_t}\Big)\widehat\beta\Big|
=\frac{1}{Z}\,\big|\widehat\alpha^\top(\cdots)\widehat\beta\big|\\
&\ \le\ \frac{1}{Z}\,\|\widehat\alpha\|_{\bullet,*}\,\|\widehat\beta\|_{\bullet}\cdot
\begin{cases}
(1+\delta)^L-1,&\text{（闭式）}\\
L\,\delta\,(1+\delta)^{L-1},&\text{（简化）}
\end{cases}
\end{aligned}
$$
即**归一化仅乘上常数因子 $1/Z$**，不改变 $\delta$ 的阶。若仅知 $Z\ge \gamma_0>0$，则整体常数再乘 $1/\gamma_0$。

> **说明**：在恒等校准下 $\sum_\sigma B_\sigma=I$ 与投影后保持该性质，故两侧**总质量**均为 $\widehat\alpha^\top\widehat\beta=Z$。使用同一 $Z$ 重标定不会引入与 $\delta$ 相关的附加阶。

#####  备注 8.4.2（谱范数版本——需要时的换范数）

若需将点态误差上界转为谱范数形式，可用有限维换范数，诸如
$$
\|X\|_2\ \le\ \sqrt{\|X\|_1\|X\|_\infty}\ \le\ \sqrt{r}\,\|X\|_\bullet,
$$
其中 $r$ 为矩阵维度（秩‑$r$ 子空间）。据此可将上述 $\|\cdot\|_\bullet$ 界以维度常数转写成 $\|\cdot\|_2$ 界；本节主结论（非扩张与 $O(L)$）保持不变，仅常数改变。

### 8.3　多切分 / 多视角 Hankel 的联合结构

**动机.** 对单一切分点 $t_\star$ 或单一窗口长度 $L$ 得到的 $H_p(P,S)$，可能在数值上劣条件或对最小表示覆盖不全。把多个视角（不同 $L_k,t_{\star,k},P_k,S_k$）统一到同一最小实现子空间下联合分析，可以显著提升**可辨识性**与**稳健性**。

#### 8.3.1　统一坐标：站立假设与实现约定

**站立假设（统一线性表示）.**
 由 §3.7 / §6.4：若（无限或块‑）Hankel 的秩为 $r\le D^2$，则存在维度为 $r$ 的线性表示
$$
p(w)=i^\top B_{w} f,\qquad w\in\Sigma^\ast .
$$
对所有视角 $k=1,\dots,K$，仅有**前缀/后缀选集不同**：
$$
P_k\subseteq\Sigma^{\le L_k},\qquad S_k\subseteq\Sigma^{\le L_k},
$$
它们对应的 Hankel 子矩阵都可视为同一组 $(i,{B_\sigma},f)$ 在不同索引上的限制。

**目标.** 在一个公共的 $r$ 维坐标中同时表示所有视角，使得：

- 每个视角的秩与最小实现维度等结构不变量保持不变；

- 在该 $r$ 维子空间内，可以构造满足
  $$
  \sum_{\sigma\in\Sigma}\widehat B_\sigma = I_r
  $$
  的规范化转移算子族 ${\widehat B_\sigma}$。

实现上可以采用以下任一流程，二者都只对 $r$ 维子空间做可逆线性变换。

**方法 A：参考视角白化 + 恒等校准**

1. 选取一个参考视角 $k_{\rm ref}$，其估计 Hankel 记为 $\widehat H^{(\text{ref})}$，假设在秩‑$r$ 上有清晰谱隙。作秩‑$r$ 截断 SVD：
   $$
   \widehat H^{(\text{ref})}=U_r\Sigma_r V_r^\dagger .
   $$

2. 按 §6.5 的“恒等校准”构造可逆矩阵 $W_L,W_R$，在秩‑$r$ 子空间内满足
   $$
   W_L\,\widehat H^{(\text{ref})}\,W_R = I_r,
   \qquad
   \widehat B_\sigma:=W_L\,\widehat H^{(\text{ref})}_\sigma\,W_R,
   \quad
   \sum_{\sigma}\widehat B_\sigma = I_r .
   $$

3. 对任意其它视角 $k$，统一坐标：
   $$
   \widehat H_{\rm uni}^{(k)} := W_L\,\widehat H^{(k)}\,W_R .
   $$
   这样得到的 $\widehat H_{\rm uni}^{(k)}$ 全部处在同一 $r$ 维坐标下，仅做了可逆变换，不改变各视角的秩与最小实现结构。

**方法 B：联合 Gram + 恒等校准（推荐）**

1. 对每个视角作估计分解 $\widehat H^{(k)}\approx \widehat O^{(k)}\widehat C^{(k)}$，构造联合 Gram：
   $$
   G_O:=\sum_k \widehat O^{(k)\top}\widehat O^{(k)},\qquad
   G_C:=\sum_k \widehat C^{(k)}\widehat C^{(k)\top}.
   $$
   在各自的前 $r$ 维特征子空间上（必要时加岭 $\lambda_{\rm wh}>0$）选取可逆矩阵 $W_O,W_C$ 进行白化，使得
   $$
   W_O\,G_O\,W_O^\top \approx I_r,\qquad
   W_C^\top\,G_C\,W_C \approx I_r.
   $$

2. 用 $(W_O,W_C)$ 同时变换所有视角：
   $$
   \breve H^{(k)}:=W_O\,\widehat H^{(k)}\,W_C .
   $$
   这一步把所有视角统一到同一 $r$ 维“白化子空间”，不改变各自的秩与最小实现维度。

3. 在该子空间内选一个聚合 Hankel（如加权平均）
   $$
   \breve H^{(\text{agg})} := \sum_k w_k\,\breve H^{(k)},
   $$
   对 $\breve H^{(\text{agg})}$ 再执行一次 §6.5 的恒等校准，得到新的可逆矩阵 $\widetilde W_L,\widetilde W_R$，使得
   $$
   \widetilde W_L\,\breve H^{(\text{agg})}\,\widetilde W_R = I_r,\qquad
   \widehat B_\sigma:=\widetilde W_L\,\breve H^{(\text{agg})}_\sigma\,\widetilde W_R,\quad
   \sum_\sigma \widehat B_\sigma = I_r .
   $$

4. 对每个视角取统一表示：
   $$
   \widehat H_{\rm uni}^{(k)} := \widetilde W_L\,\breve H^{(k)}\,\widetilde W_R.
   $$
   这样得到的所有 $\widehat H_{\rm uni}^{(k)}$ 共享同一 $r$ 维坐标与一组规范化转移算子 ${\widehat B_\sigma}$。

**统一记号.**
 在上述任一流程得到的公共 $r$ 维坐标中，我们可以写
$$
H^{(k)}=O^{(k)}C^{(k)},\qquad
O^{(k)}[u,:]=i^\top B_u,\quad
C^{(k)}[:,v]=B_v f,
$$
其中 $(i,{B_\sigma},f)$ 是同一个最小线性表示在该坐标中的实现。这说明多切分 / 多视角 Hankel 都被嵌入到了一个统一、有限维的线性系统里。

##### 定义 8.5（联合 Hankel 与块特征）

堆叠所有视角的行/列特征：
$$
\mathcal O_{\rm joint}:=
\begin{bmatrix}
O^{(1)}\\[-1mm]\vdots\\[-1mm]O^{(K)}
\end{bmatrix}\in\mathbb R^{(\sum m_k)\times r},\qquad
\mathcal C_{\rm joint}:=
\begin{bmatrix}
C^{(1)}&\cdots&C^{(K)}
\end{bmatrix}\in\mathbb R^{r\times(\sum n_k)} .
$$
定义联合 Hankel：
$$
\boxed{\,H_{\rm joint}:=\mathcal O_{\rm joint}\,\mathcal C_{\rm joint}\, } .
$$

##### 命题 8.5.1（秩上界）

$$
\boxed{\ \operatorname{rank}(H_{\rm joint})\ \le\ 
\min\{\operatorname{rank}\mathcal O_{\rm joint},\operatorname{rank}\mathcal C_{\rm joint}\}\ \le\ r\ \le D^2.\ }
$$

若对每个视角再用选择矩阵限制到“同层条目”（$|u|+|v|=L_k$），所得子矩阵的秩不会增加。

*证明略.* 由 $\operatorname{rank}(AB)\le\min{\operatorname{rank}A,\operatorname{rank}B}$ 以及“取行/列子矩阵不增秩”即得。

##### 定理 8.6（联合视角的最小奇异值下界）

仍采用 8.3.1 中的记号：对每个视角 $k=1,\dots,K$，有分解
$$
H^{(k)} = O^{(k)} C^{(k)},\quad
O^{(k)}\in\mathbb R^{m_k\times r},\ C^{(k)}\in\mathbb R^{r\times n_k},
$$
并定义
$$
\mathcal O_{\rm joint}=
\begin{bmatrix}
O^{(1)}\\[-1mm]\vdots\\[-1mm]O^{(K)}
\end{bmatrix}\in\mathbb R^{(\sum m_k)\times r},\qquad
\mathcal C_{\rm joint}=
\begin{bmatrix}
C^{(1)}&\cdots&C^{(K)}
\end{bmatrix}\in\mathbb R^{r\times(\sum n_k)},
$$
记 $\sigma_r(\cdot)$ 为第 $r$ 个奇异值（若秩小于 $r$ 则取为 0）。

##### (A) O/C‑层的乘法型下界

$$
\boxed{
\ \sigma_r(H_{\rm joint})
\ \ge\ \sigma_r(\mathcal O_{\rm joint})\ \sigma_r(\mathcal C_{\rm joint})
\ =\ \sqrt{\lambda_{\min}(\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint})}\,
   \sqrt{\lambda_{\min}(\mathcal C_{\rm joint}\mathcal C_{\rm joint}^\top)}\ .
}
$$

**证明要点（简）**：
 对 $\mathcal O_{\rm joint},\mathcal C_{\rm joint}$ 做紧致 SVD：
$$
\mathcal O_{\rm joint}=U_O\Sigma_O V_O^\top,\quad
\mathcal C_{\rm joint}=U_C\Sigma_C V_C^\top,
$$
其中 $\Sigma_O,\Sigma_C\in\mathbb R^{r\times r}$ 为对角矩阵，且
 $\sigma_r(\mathcal O_{\rm joint})=\sigma_{\min}(\Sigma_O)$、$\sigma_r(\mathcal C_{\rm joint})=\sigma_{\min}(\Sigma_C)$。

则
$$
H_{\rm joint}
= U_O \underbrace{\big(\Sigma_O Q \Sigma_C\big)}_{=:X} V_C^\top,\qquad
Q:=V_O^\top U_C\in O(r).
$$
非零奇异值与 $X$ 相同。又
$$
\sigma_{\min}(X)
\ \ge\ \sigma_{\min}(\Sigma_O)\,\sigma_{\min}(Q)\,\sigma_{\min}(\Sigma_C)
=\sigma_r(\mathcal O_{\rm joint})\,\sigma_r(\mathcal C_{\rm joint}),
$$
其中用到了 $\sigma_{\min}(ABC)\ge\sigma_{\min}(A)\sigma_{\min}(B)\sigma_{\min}(C)$（可逆情形由 $(ABC)^{-1}=C^{-1}B^{-1}A^{-1}$ 直接得到），以及正交矩阵 $Q$ 的 $\sigma_{\min}(Q)=1$。
 故得结论。

##### (B) Gram 分解下界

进一步地，有
$$
\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint}
=\sum_{k=1}^k O^{(k)\top}O^{(k)},\quad
\mathcal C_{\rm joint}\mathcal C_{\rm joint}^\top
=\sum_{k=1}^k C^{(k)}C^{(k)\top}.
$$
对任意 PSD 矩阵族 $A_k\succeq0$ 有
$$
A_k\succeq \lambda_{\min}(A_k)I\quad\Rightarrow\quad
\sum_k A_k\succeq \big(\sum_k\lambda_{\min}(A_k)\big)I,
$$
从而
$$
\lambda_{\min}\Big(\sum_k A_k\Big)\ \ge\ \sum_k\lambda_{\min}(A_k).
$$
应用到上式得到
$$
\lambda_{\min}(\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint})
\ \ge\ \sum_k \lambda_{\min}(O^{(k)\top}O^{(k)}),
$$
代回 (A) 有
$$
\boxed{
\ \sigma_r(H_{\rm joint})\ \ge\
\sqrt{\Big(\sum_k \lambda_{\min}(O^{(k)\top}O^{(k)})\Big)
      \Big(\sum_k \lambda_{\min}(C^{(k)}C^{(k)\top})\Big)}\ .
}
$$
这给出了一个非常直接的“多视角累积提升”式的 σ$_r$ 下界。

##### (C) 加权联合（任意 $w_k>0$）

定义加权联合矩阵
$$
H_{\rm joint}^{(w)}:=
\begin{bmatrix}
w_1 O^{(1)}\\[-1mm]\vdots\\[-1mm]w_K O^{(K)}
\end{bmatrix}
\begin{bmatrix}
C^{(1)}&\cdots&C^{(K)}
\end{bmatrix}
=\mathcal O^{(w)}\,\mathcal C^{(w)},
$$
其中
$$
\mathcal O^{(w)}=
\begin{bmatrix}
w_1 O^{(1)}\\[-1mm]\vdots\\[-1mm]w_K O^{(K)}
\end{bmatrix},\qquad
\mathcal C^{(w)}=
\begin{bmatrix}
C^{(1)}&\cdots&C^{(K)}
\end{bmatrix}.
$$
与 (A) 完全同理有
$$
\boxed{\ 
\sigma_r(H_{\rm joint}^{(w)})\ \ge\ \sigma_r(\mathcal O^{(w)})\,\sigma_r(\mathcal C^{(w)}),
}
$$
同时其 Gram 为
$$
\mathcal O^{(w)\top}\mathcal O^{(w)}
=\sum_k w_k^2\,O^{(k)\top}O^{(k)},\quad
\mathcal C^{(w)}\mathcal C^{(w)\top}
=\sum_k C^{(k)}C^{(k)\top},
$$
故
$$
\boxed{
\ \sigma_r(H_{\rm joint}^{(w)})\ \ge\
\sqrt{\Big(\sum_k w_k^2 \lambda_{\min}(O^{(k)\top}O^{(k)})\Big)
      \Big(\sum_k \lambda_{\min}(C^{(k)}C^{(k)\top})\Big)}\ .
}
$$

##### 推论 8.6.1（综合下界）

综合 (A)、(B)，得到
$$
\boxed{\ 
\sigma_r(H_{\rm joint})\ \ge\ 
\sigma_r(\mathcal O_{\rm joint})\,\sigma_r(\mathcal C_{\rm joint})
\ \ge\
\sqrt{\Big(\sum_k \lambda_{\min}(O^{(k)\top}O^{(k)})\Big)
      \Big(\sum_k \lambda_{\min}(C^{(k)}C^{(k)\top})\Big)}\ .
}
$$
即：多视角联合后的最小奇异值，至少由所有视角的行/列 Gram 的“最小特征值和”给出一个明确的可证下界。

##### 推论 8.6.2（秩恢复）

若存在某一视角 $k_0$ 使得
$$
\mathrm{rank}O^{(k_0)}=\mathrm{rank}C^{(k_0)}=r,
$$
则
$$
\mathrm{rank}\,\mathcal O_{\rm joint}=\mathrm{rank}\,\mathcal C_{\rm joint}=r
\quad\Rightarrow\quad
\sigma_r(\mathcal O_{\rm joint})>0,\ \sigma_r(\mathcal C_{\rm joint})>0,
$$
由定理 8.6(A) 得
$$
\boxed{\ \sigma_r(H_{\rm joint})>0,\ }
$$
即联合多视角之后必然恢复到满秩‑$r$ 的“稳定区间”。

##### 定理 8.7（log‑det 子模选择与 σ$_r$ 下界的桥接）

在白化后的 $r$ 维坐标中，令行/列特征为
 $\phi_P^{(k)}(u)\in\mathbb R^{1\times r}$、$\phi_S^{(k)}(v)\in\mathbb R^{r\times 1}$。对行侧选集 $\{\mathcal S_k\}$、列侧选集 $\{\mathcal T_k\}$ 定义
$$
F_P(\{\mathcal S_k\})=\log\det\!\Big(I_r+\lambda^{-1}\sum_k\sum_{u\in\mathcal S_k}\phi_P^{(k)}(u)^\top\phi_P^{(k)}(u)\Big),
$$

##### (i) 单调 + 子模 + 贪心

- 对任一候选 $u$，其边际增益为
  $$
  \Delta(u\mid\{\mathcal S_k\})=
  \log\Big(1+\lambda^{-1}\phi^\top\big(I+\lambda^{-1}M_{\mathcal S}\big)^{-1}\phi\Big)\ \ge0,
  $$
  且随 $\{\mathcal S_k\}$ 扩大单调递减 ⇒ $F_P$ 单调且子模；$F_S$ 同理。

- 在总选点数（或分视角配额）约束下，对 $F_P$ 或 $F_S$ 做贪心，保证 $(1-1/e)$ 近似最优（经典 D‑optimal 结果）。

因此：
$$
\boxed{\ \ F_P,F_S\ \text{关于集合均单调且子模，贪心达 }(1-1/e)\text{ 近似}.\ }
$$

##### (ii) 与 Gram / σ$_r(H_{\rm joint})$ 的桥接

令
$$
M_P=\sum_k\sum_{u\in\mathcal S_k}\phi_P^{(k)}(u)^\top\phi_P^{(k)}(u),\quad
M_S=\sum_k\sum_{v\in\mathcal T_k}\phi_S^{(k)}(v)\phi_S^{(k)}(v)^\top.
$$
则：

- $\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint}$ 在所选行上的“压缩 Gram”即由 $M_P$ 给出；$\mathcal C_{\rm joint}\mathcal C_{\rm joint}^\top$ 对应 $M_S$。
- 利用第 6 章的限制‑Gram + log‑det 桥接（定理 6.1 + 命题 6.2），可从 $F_P,F_S$ 的增大得到
   $\lambda_{\min}(\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint})$、$\lambda_{\min}(\mathcal C_{\rm joint}\mathcal C_{\rm joint}^\top)$ 的**可证下界**单调提升。
- 再代入定理 8.6(A)，得到：

$$
\boxed{\ 
F_P,F_S\ \text{通过提升 Gram 的最小特征值下界，单调地抬高 }
\sigma_r(H_{\rm joint})\ \text{的可证下界}.
}
$$

换句话说：**用 log‑det 贪心选集，并不是直接优化 $\sigma_r(H_{\rm joint})$，但它能单调地提升一个严格的、谱论上的下界**。

#### 8.3.2 与非负/次随机锥的兼容 & 长度 $O(L)$ 放大

在恒等校准后，将估计得到的 $\{\widehat B_\sigma\}$（以及后续多视角联合得到的 $\{B_\sigma\}$）投影到

- 行非负 + 行次随机锥 $\mathcal K_{\rm row}$ 并配合 $\|\cdot\|_\infty$，或
- 列非负 + 列次随机锥 $\mathcal K_{\rm col}$ 并配合 $\|\cdot\|_1$，

则对匹配诱导范数 $\|\cdot\|_\bullet$ 有
$$
\boxed{\ \max_\sigma \|B_\sigma\|_\bullet\ \le\ 1,\qquad
\Big\|\prod_{t=1}^{L} B_{x_t}\Big\|_\bullet\ \le\ 1\quad(\forall x\in\Sigma^L).\ }
$$
因此在第 5 章/第 8 章使用的望远镜展开里，几何放大因子满足
$$
\boxed{\ G_L\big(\kappa_B^{(\bullet)}\big)\ \le\ L,\ }
$$
即长度依赖从一般的 $G_L(\kappa)$（几何级数）统一降为 **线性 $O(L)$**。

多切分 / 多视角联合只会改变

- Gram 的条件数及
- $\sigma_r(H_{\rm joint})$ 的数值和下界，

但只要最后仍然投影到同一个非负/次随机锥下，以上“非扩张 + $O(L)$ 放大”的分析保持完全有效。

于是，与第 11.4 节的端到端误差传播结合，可得到在**联合多视角 + 非负/次随机规范**下，整个学习算法对长度 $L$ 的误差放大始终为 **$O(L)$**。

---

# ==Part III　统计学习理论==

## 第9章　Hankel 估计的集中不等式

**统一设定.** 固定长度 $L$、切分点 $t_\star$，以及前缀/后缀集合 $P\subseteq\Sigma^{t_\star}$、$S\subseteq\Sigma^{L-t_\star}$，令 $m=|P|$、$n=|S|$。主矩阵 $H:=H_p(P,S)\in\mathbb R^{m\times n}$。样本为独立抽取的长度 $L$ 串 $x^{(1)},\dots,x^{(N)}\sim p$。对每个 $x^{(i)}$，按唯一分解 $x^{(i)}=u^{(i)}v^{(i)}$（$|u|+|v|=L$）更新**经验 Hankel**

$$
\widehat H=\frac1N\sum_{i=1}^N Z_i,\qquad
(Z_i)_{u,v}=\mathbf 1\{(u,v)=(u^{(i)},v^{(i)})\}.
$$

记谱误差 $\Delta:=\|\widehat H-H\|_2$。另外定义**相干度**

$$
\mu:=\max\Big\{\max_{u\in P}\sum_{v\in S}H(u,v),\ \max_{v\in S}\sum_{u\in P}H(u,v)\Big\}\in[0,1],
$$

即行/列边缘分布的最大值。

### 9.1　one‑shot 频数的矩阵 Bernstein（相干度 $\mu$）

**定理 9.1（矩阵 Bernstein，高概率）.**
存在绝对常数 $C_1,C_2>0$，对任意 $\delta\in(0,1)$，以概率至少 $1-\delta$，

$$
\boxed{\quad
\|\widehat H-H\|_2\ \le\ 
C_1\sqrt{\frac{\mu\,\log\!\big((m+n)/\delta\big)}{N}}
\ +\ 
C_2\,\frac{\log\!\big((m+n)/\delta\big)}{N}\ .
\quad}
$$

**Proof sketch.** 写作 $\widehat H-H=\frac1N\sum_{i=1}^N X_i$，其中 $X_i=Z_i-\mathbb E Z_i$ 为独立零均值矩阵。

* **范数上界：** $\|X_i\|_2\le\|Z_i\|_2+\|\mathbb EZ_i\|_2\le 1+1\le 2$（常数可吸收）。
* **方差参数：**
  $\mathbb E[X_iX_i^\top]=\mathbb E[Z_iZ_i^\top]-HH^\top$，且 $\|\mathbb E[Z_iZ_i^\top]\|_2=\max_u \sum_v H(u,v)\le \mu$；同理 $\|\mathbb E[X_i^\top X_i]\|_2\le \mu$。故 Bernstein 的方差尺度为 $\sigma^2\le \mu$。
* 应用矩阵 Bernstein（带尺寸项 $\log(m+n)$）即得结论。

**命题 9.2（期望误差）.**
存在绝对常数 $C_3>0$ 使

$$
\mathbb E\|\widehat H-H\|_2 \le
C_3\sqrt{\frac{\mu\,\log\big(1+\tfrac{\mathrm{tr}(V)}{\|V\|}\big)}{N}}
+C_4\,\frac{\log\big(1+\tfrac{\mathrm{tr}(V)}{\|V\|}\big)}{N}.
$$

**引理 9.3（掩膜/对齐不增性）.**
对任意列掩膜 $\Pi$（0–1对角），$\|\widehat H\Pi-H\Pi\|_2\le \|\widehat H-H\|_2$。
*意义：* 对每个字母 $\sigma$ 的对齐矩阵 $H_\sigma=H\Pi_\sigma$ 亦服从同阶集中，且无需额外 $\log d$ 代价。

### 9.2　滑窗依赖的鞅版本与块抽样

设观察到更长串 $x^{(i)}\in\Sigma^{T}$（$T\ge L$）。对每条串取所有窗口 $\mathcal W_L(x^{(i)})=\{w_{i,1},\dots,w_{i,K}\}$，其中 $K=T-L+1$。经验 Hankel 改写为

$$
\widehat H=\frac{1}{N K}\sum_{i=1}^N \sum_{j=1}^K Z_{i,j},\qquad
(Z_{i,j})_{u,v}=\mathbf 1\{w_{i,j}=uv\}.
$$

同一条串内的窗口相关，不能直接按 $N K$ 个独立样本处理。

**命题 9.4（保守界：不假设混合）.**
即使使用全部窗口，只利用“每条长串独立”的事实，仍有

$$
\|\widehat H-H\|_2\ \lesssim\ \sqrt{\frac{\mu\,\log((m+n)/\delta)}{N}}\ +\ \frac{\log((m+n)/\delta)}{N},
$$

与 one‑shot 同阶（隐藏常数略优）。
*意义：* 若不引入额外独立性/混合假设，滑窗只能改善常数，无法改善 $1/\sqrt N$ 阶。

**定理 9.5（块抽样/稀释窗，在混合假设下）**
设每条长串由**平稳 β‑混合**过程生成，混合系数为 $\beta(\tau)$。取步长 $s\ge L$，按间隔 $s$ 选取不重叠窗口，$K_s=\lfloor K/s\rfloor$。令**依赖膨胀因子**
$$
\eta(s)\ :=\ 1+2\sum_{j\ge1}\beta(js)\ \ (\ge1).
$$

则以概率至少 $1-\delta$，

$$
\|\widehat H-H\|_2\ \le\ 
C\!\left(
\sqrt{\frac{\mu\,\eta(s)\,\log((m+n)/\delta)}{N\,K_s}}
+\frac{\log((m+n)/\delta)}{N\,K_s}
\right).
$$

**备注**：若混合足够快且 $s$ 超过混合时间，则 $\eta(s)\approx 1$，上式退化为原来的 $N K_s$ 有效样本量界。

**定理 9.6（矩阵 Freedman：鞅依赖版）.**
若沿着窗口索引 $(i,j)$ 构造自然滤过，使 $\{Z_{i,j}-\mathbb E[Z_{i,j}\mid \mathcal F_{i,j-1}]\}$ 成为矩阵鞅差序列，且其条件方差过程的谱范数几乎处处上界为 $\sigma^2\le \mu\cdot \eta$（$\eta\ge1$ 为依赖放大系数，可由$\beta$-mixing 或 $\phi$-mixing 系数给出），则

$$
\|\widehat H-H\|_2\ \le\ 
C\left(
\sqrt{\frac{\mu\,\eta\,\log((m+n)/\delta)}{N K}}
+\frac{\log((m+n)/\delta)}{N K}
\right)
$$

以概率至少 $1-\delta$。
*意义：* 在“适度混合”或经验证明 $\eta$ 有界时，可将总窗口数 $N K$ 视作有效样本量（折损 $\eta$）。

### 9.3　带权/非均匀采样与稳健化

**加权/预条件化思路.** 行/列边缘高度不均会放大 $\mu$。可用三种方式降低方差：

1. **边缘预白化（数据侧）**：令经验边缘 $\widehat r_u=\sum_v \widehat H(u,v)$、$\widehat c_v=\sum_u \widehat H(u,v)$。对损失或回归使用权重

$$
w_u=\frac{1}{\sqrt{\widehat r_u+\lambda}},\quad
w'_v=\frac{1}{\sqrt{\widehat c_v+\lambda}},
$$

相当于在估计或学习时对 $\widehat H$ 施加 $W \widehat H W'$ 的预条件化，从而把有效相干度压向常数。

2. **重要性加权（采样侧）**：若可控制窗口选择分布 $\pi(u,v)$（主动采样/重采样），使用 Horvitz–Thompson 型无偏估计

$$
\widehat H=\frac1M\sum_{k=1}^M \frac{\mathbf 1\{(u_k,v_k)\}}{\pi(u_k,v_k)} e_{u_k}e_{v_k}^\top,
$$

其方差由 $\max_{u,v} \frac{H(u,v)}{\pi(u,v)}$ 控制，选择 $\pi\propto H$ 最优（理想化）；实践中以边缘近似 $\pi(u,v)\propto r_u c_v$。

3. **稳健化（抗异常）**：将样本分为 $B$ 组，计算组均值 $\widehat H^{(b)}$，取**谱几何中值** $\operatorname{med}_b \widehat H^{(b)}$。若组内离群率 < 1/4，则以常数概率保证

$$
\|\operatorname{med}-H\|_2\ \lesssim\ \sqrt{\frac{\mu}{N}}\ ,
$$

并对重尾或小量污染具鲁棒性（常数依赖 $B$）。

---

## 第10章　泛化与复杂度

我们考虑用观测到的条目损失学习/近似 $H$ 或其低维表示。令函数族

$$
\mathcal F_*=\{M\in\mathbb R^{m\times n}:\ \|M\|_*\le \tau_*\}.
$$

假设单条目损失 $\ell(\hat y,y)$ 对第一变量 1‑Lipschitz（如绝对误差、hinge、logistic 的截断梯度区间等）。

### 10.1　核范球与 Rademacher/覆盖数上界

**定理 10.1（Rademacher 复杂度）.**
令训练集为 $\{(u_i,v_i)\}_{i=1}^N$（按 $H$ 的 one‑shot 机制抽样），定义特征矩阵 $X_i=e_{u_i}e_{v_i}^\top$。则
$$
\mathfrak R_N(\mathcal F_*)\ :=\ \mathbb E\Big[\sup_{\|M\|_*\le \tau_*}\frac1N\sum_{i=1}^N \varepsilon_i \langle M,X_i\rangle\Big]
\ \le\ C\,\tau_*\,\sqrt{\frac{\mu\,\log(m+n)}{N}}\quad
(\text{亦可加 }+\,C'\,\tau_*\tfrac{\log(m+n)}{N}\text{ 的次要项}) ,
$$

其中 $\varepsilon_i$ 为独立 Rademacher 随机变量，$\mu$ 为第 9 章定义的相干度。

**Proof sketch.** 由核范/谱范对偶 $\sup_{\|M\|_*\le\tau_*}\langle M,A\rangle=\tau_*\|A\|_2$，得

$$
\mathfrak R_N(\mathcal F_*)=\tau_*\,\mathbb E\Big\|\frac1N\sum_i \varepsilon_i X_i\Big\|_2.
$$

对 $S=\sum_i \varepsilon_i X_i$ 用非交换 Khintchine 或矩阵 Bernstein 的期望版，上界
$\mathbb E\|S/N\|_2 \lesssim \sqrt{\mu\log(m+n)/N}$（方差尺度由最大行/列边缘 $\mu$ 控制，维度项为 $\log(m+n)$），即得结论。

**定理 10.2（期望泛化间隙）.**
对任意 1‑Lipschitz 条目损失，有

$$
\mathbb E[\text{gen gap}]\ \le\ C\,\tau_*\,\sqrt{\frac{\mu\,\log(m+n)}{N}}
\quad(\text{同样可附 }+\,C'\,\tau_*\tfrac{\log(m+n)}{N}).
$$

**推论 10.3（高概率版）.**
以概率至少 $1-\delta$，

$$
\text{gen gap}\ \le\ C\,\tau_*\,\sqrt{\frac{\mu\,\log(m+n)}{N}}\ +\ C'\,\sqrt{\frac{\log(1/\delta)}{N}}.
$$

### 10.2　有效秩、Frobenius 范数与核范的链接

我们希望把“Hankel 近低秩”转成一个对核范球的假设，从而和第 10.1 节的核范 Rademacher 界对接。

##### 命题 10.4（核范–Frobenius–秩 / 有效秩）

设矩阵 $M\in\mathbb R^{m\times n}$ 的奇异值为 $\sigma_1\ge\cdots\ge\sigma_r>0$，其余为 0。

1. 若 $\operatorname{rank}(M)\le r$，则
   $$
   \|M\|_*\ =\ \sum_{i=1}^r\sigma_i\ \le\ \sqrt r\Big(\sum_{i=1}^r\sigma_i^2\Big)^{1/2}
   =\sqrt r\,\|M\|_F .
   $$

2. 定义**有效秩**
   $$
   r_{\rm eff}(M)\ :=\ \frac{\|M\|_*^2}{\|M\|_F^2}\ \in\ [1,\ \operatorname{rank}(M)] ,
   $$
   则有
   $$
   \|M\|_*\ =\ \sqrt{r_{\rm eff}(M)}\;\|M\|_F .
   $$

> 说明：$r_{\rm eff}$ 把“有多少能量集中在前几个奇异值”编码进来：当奇异值衰减快时，$r_{\rm eff}\ll\operatorname{rank}(M)$。

##### 定理 10.5（目标依赖的统一收敛界）

记核范球
$$
\mathcal F_*:=\{M\in\mathbb R^{m\times n}:\ \|M\|_*\le\tau_*\}.
$$
样本 ${(u_i,v_i)}_{i=1}^N$ 按 §9 的 one‑shot 模型抽取（即 $(u_i,v_i)$ 以 Hankel 权重 $H(u,v)$ 采样），并用某个**条目损失** $\ell$（对预测值 1‑Lipschitz、且有界在 $[0,1]$）定义经验/真实风险
$$
\widehat{\mathcal L}(M)=\frac1N\sum_{i=1}^N\ell\big(M_{u_i,v_i}\big),\qquad
\mathcal L(M)=\mathbb E_{(u,v)\sim H}[\ell(M_{u,v})].
$$
第 10.1 节给出的 Rademacher 界说明：存在常数 $C,C'>0$，对任意 $\delta\in(0,1)$，以概率至少 $1-\delta$，
$$
\sup_{M\in\mathcal F_*}\big|\mathcal L(M)-\widehat{\mathcal L}(M)\big|
\ \le\ 
C\,\tau_*\,\sqrt{\frac{\mu\,\log((m+n)/\delta)}{N}}
\ +\ 
C'\,\tau_*\,\frac{\log((m+n)/\delta)}{N},
$$
其中 $\mu$ 为第 9 章的**相干度**。

现在假设存在某个“目标矩阵” $H$（例如 Hankel 真值），满足
$$
\|H\|_F\le\tau_F,\qquad r_{\rm eff}(H)\le r,
$$
则由命题 10.4，有
$$
\|H\|_*\ \le\ \sqrt r\,\|H\|_F\ \le\ \sqrt r\,\tau_F.
$$
因此只要取
$$
\tau_*=\sqrt r\,\tau_F,
$$
就保证 $H\in\mathcal F_*$. 于是得到：

> **定理 10.5（目标依赖统一收敛界）**
>  在上述设定下，取 $\tau_*=\sqrt r,\tau_F$，则存在常数 $C,C'>0$ 使得
> $$
> \mathbb E\Big[\sup_{M\in\mathcal F_*}\big|\mathcal L(M)-\widehat{\mathcal L}(M)\big|\Big]
> \ \le\ 
> C\,\sqrt r\,\tau_F\,\sqrt{\frac{\mu\,\log(m+n)}{N}}
> \ +\ 
> C'\,\sqrt r\,\tau_F\,\frac{\log(m+n)}{N}.
> $$
> 特别地，若用经验风险最小化或带核范正则的学习器得到 $\widehat M\in\mathcal F_*$，则对任何 $M^\star\in\mathcal F_*$（包括 $H$ 在内）有
> $$
> \mathbb E\big[\mathcal L(\widehat M)-\mathcal L(M^\star)\big]
> \ \le\ 
> 2C\,\sqrt r\,\tau_F\,\sqrt{\frac{\mu\,\log(m+n)}{N}}
> \ +\ O\!\Big(\sqrt r\,\tau_F\,\frac{\log(m+n)}{N}\Big).
> $$

> 解释：
>  这条界同时体现了
>
> - **矩阵能量** $\tau_F=|H|_F$；
> - **有效秩** $r_{\rm eff}(H)\lesssim r$；
> - **采样结构** $\mu$（偏向度越大，相干度越大，越难）。

### 10.3　PAC‑Bayes 与互信息型界

本节考虑更一般的“学习算法”层面的界，与具体的核范 / Hankel 结构正交，用来刻画：**低秩参数化／压缩如何通过 KL 或互信息进入泛化界**。

为简洁，统一假设：

- 单样本损失 $\ell:\mathbb R\to[0,1]$；
- 对任意参数 $\theta$ 和样本 $(u,v)$，预测为某个标量 $f_\theta(u,v)$，损失为 $\ell(f_\theta(u,v))$；
- 训练集 $S=((u_1,v_1),\dots,(u_N,v_N))$ i.i.d. 生成；
- 学习算法输出一个后验分布 $Q_S$（在参数空间上），随机预测器从 $Q_S$ 抽样得到。

记真实风险与经验风险
$$
\mathcal L(\theta)=\mathbb E_{(u,v)}[\ell(f_\theta(u,v))],\qquad
\widehat{\mathcal L}_S(\theta)=\frac1N\sum_{i=1}^N\ell\big(f_\theta(u_i,v_i)\big),
$$
并定义对应后验下的**泛化间隙**
$$
\mathrm{gen\ gap}(Q_S):=\mathbb E_{\theta\sim Q_S}\big[\mathcal L(\theta)-\widehat{\mathcal L}_S(\theta)\big].
$$

##### 定理 10.6（PAC‑Bayes：有界损失版）

令 $P$ 为任意先验分布（与数据 $S$ 独立），$Q_S$ 为算法在 $S$ 上得到的后验。则存在绝对常数 $C>0$，对任意 $\delta\in(0,1)$，以概率至少 $1-\delta$（对训练集抽样）有
$$
\Big|\mathrm{gen\ gap}(Q_S)\Big|
\ \le\ 
C\,\sqrt{\frac{\mathrm{KL}(Q_S\|P)+\log(1/\delta)}{N}}.
$$

> 说明：
>
> - 这是标准 PAC‑Bayes 不等式在“损失有界于 $[0,1]$”情形的直接应用；
> - 如果损失原本是 $L$‑Lipschitz 但不在 $[0,1]$，可以先做剪裁 / 线性缩放到 $[0,1]$，把 Lipschitz 常数吸收到 $C$ 中；
> - 该界与特征分布（如 Hankel 结构、$\mu$ 等）**无关**，因此是对第 10.1–10.2 节的“结构型界”的补充，而不是替代。

**低秩参数化的作用（备注）**

若参数用低秩因子化表示，如矩阵 $M=UV^\top$，$U\in\mathbb R^{m\times r},V\in\mathbb R^{n\times r}$，则总参数维度约为 $(m+n)r$。这里假设 $Q_S$ 也是某个高斯或被限制在半径 $R$ 的欧氏球中，因此 $KL$ 与期望平方范数成正比。对各向同性高斯先验 $P=\mathcal N(0,\sigma^2 I)$，若后验 $Q_S$ 也集中在一个“能量有限”的区域（例如 $\mathbb E_{Q_S}[|U|_F^2+|V|_F^2]\lesssim R^2$），则 KL 通常满足
$$
\mathrm{KL}(Q_S\|P)\ \lesssim\ (m+n)r\cdot \frac{R^2}{\sigma^2},
$$
从而 PAC‑Bayes 界给出
$$
\big|\mathrm{gen\ gap}(Q_S)\big|\ \lesssim\ \sqrt{\frac{(m+n)r}{N}}\quad(\text{忽略常数与尺度因子}).
$$
这正体现了：**维度越低（$r$ 越小）、参数范数越小，KL 越小，泛化越好**。

##### 命题 10.7（互信息型界）

记 $\mathcal A$ 为（可能随机化的）学习算法，它把训练集 $S$ 映射到随机输出 $\mathcal A(S)$（例如后验 $Q_S$ 的一个随机样本，或整个后验的编码）。令
$$
I(\mathcal A(S);S)
$$
为算法输出与训练集之间的互信息。

> **命题 10.7（互信息泛化界）**
>  在上述设定下，存在绝对常数 $C>0$ 使得
> $$
> \mathbb E\big[\mathrm{gen\ gap}(Q_S)\big]
> \ \le\ 
> C\,\sqrt{\frac{I(\mathcal A(S);S)}{N}}.
> $$
> 期望是同时对训练集抽样和算法随机性取的。

> 说明：
>
> - 这是 Russo–Zou、Xu–Raginsky 类型信息论泛化界在“损失有界于 $[0,1]$”情形下的直接形式；
> - 该界不显式依赖 Hankel 结构或 $\mu$，但 $I(\mathcal A(S);S)$ 会反映各种**压缩 / 正则化**（如 early stopping、噪声注入、模型剪枝等）带来的信息缩减；
> - 比起 PAC‑Bayes，互信息界不需要显式指定先验 $P$，而是直接用“算法输出携带了多少关于训练集的信息”来刻画泛化难度。

---

## 第 11 章　端到端误差与样本复杂度

本章把第 9 章的 Hankel 估计误差
$$
\Delta:=\|\widehat H-H\|_2
$$
与第 6 章的“真白化坐标”结合，给出从 $\Delta$ 到整层点态误差
$$
\sup_{|x|=L}|\widehat p(x)-p(x)|
$$
的上界；在额外的非负/次随机结构下，长度依赖可以压到 $O(L)$。

### 11.1　从 $|\widehat H-H|_2$ 到字母算子误差与点态误差

**统一设定.**

- 长度‑$L$ Hankel 主矩阵 $H=H_p(P,S)\in\mathbb R^{m\times n}$，秩
  $$
  r=\mathrm{rank}(H),\quad
  \sigma_1(H)\ge\cdots\ge \sigma_r(H)>0,\quad
  \gamma:=\sigma_r(H).
  $$

- 估计矩阵 $\widehat H$ 及误差
  $$
  \Delta:=\|\widehat H-H\|_2.
  $$

- 对每个字母 $\sigma\in\Sigma$，列掩膜子矩阵
  $$
  H_\sigma=H\Pi_\sigma,\qquad
  \widehat H_\sigma=\widehat H\Pi_\sigma,
  $$
  其中 ${\Pi_\sigma}$ 是互斥且完备的列掩膜（见第 6 章），且掩膜不增性给出
  $$
  \|X\Pi_\sigma\|_2\le\|X\|_2.
  $$

#### 11.1.1　真白化坐标与字母块误差

由第 6.8 节：存在“真白化”算子 $W_L\in\mathbb R^{r\times m}$、$W_R\in\mathbb R^{n\times r}$，使得
$$
W_L H W_R = I_r,\qquad
\|W_L\|_2\,\|W_R\|_2 \le \frac{1}{\gamma}.
$$
在该坐标下定义
$$
B_\sigma:=W_L H_\sigma W_R,\qquad
\widehat B_\sigma:=W_L \widehat H_\sigma W_R.
$$

> 这些坐标只用于分析；算法本身并不需要显式求出 $W_L,W_R$。

##### 定理 11.1（字母块的谱范误差）

对任意 $\sigma\in\Sigma$，
$$
\boxed{
\ \ \|\widehat B_\sigma-B_\sigma\|_2\ \le\ \frac{\Delta}{\gamma}\ .
}
$$
于是
$$
\varepsilon_B:=\max_{\sigma}\|\widehat B_\sigma-B_\sigma\|_2\ \le\ \frac{\Delta}{\gamma}.
$$
**证明略.**
$$
\widehat B_\sigma-B_\sigma=W_L(\widehat H_\sigma-H_\sigma)W_R,
$$
谱范数次乘性与掩膜不增性给出
$$
\|\widehat B_\sigma-B_\sigma\|_2
\le\|W_L\|_2\,\|W_R\|_2\,\|\widehat H_\sigma-H_\sigma\|_2
\le\frac{1}{\gamma}\Delta.
$$
□

##### 定理 11.2（点态误差传播）

令
$$
\kappa_B:=\max_{\sigma\in\Sigma}\{\|B_\sigma\|_2,\ \|\widehat B_\sigma\|_2\}.
$$
在真白化坐标下，存在边界向量 $\alpha,\beta\in\mathbb R^r$，使
$$
p(x)=\alpha^\top B_{x_1}\cdots B_{x_L}\beta,\qquad
\widehat p(x)=\alpha^\top \widehat B_{x_1}\cdots \widehat B_{x_L}\beta.
$$
则对任意 $x=x_{1:L}\in\Sigma^L$，
$$
\boxed{
\ |\widehat p(x)-p(x)|\ \le\ 
\|\alpha\|_2\,\|\beta\|_2\;\varepsilon_B\;L\,\kappa_B^{L-1}\ .
}
$$
特别地，用定理 11.1 得
$$
\boxed{
\ |\widehat p(x)-p(x)|\ \le\ 
C_2\,\frac{\Delta}{\gamma}\,L\,\kappa_B^{L-1},\qquad
C_2:=\|\alpha\|_2\,\|\beta\|_2.
}
$$
**证明略.**（望远镜展开）
$$
\prod_{t=1}^L \widehat B_{x_t}-\prod_{t=1}^L B_{x_t}
=\sum_{s=1}^L\Big(\prod_{t=s+1}^L \widehat B_{x_t}\Big)
(\widehat B_{x_s}-B_{x_s})
\Big(\prod_{t=1}^{s-1} B_{x_t}\Big).
$$
每一项谱范数
$$
\le \kappa_B^{L-s}\,\varepsilon_B\,\kappa_B^{s-1}
=\varepsilon_B\,\kappa_B^{L-1},
$$
求和得
$$
\Big\|\prod_t \widehat B_{x_t}-\prod_t B_{x_t}\Big\|_2
\le L\,\varepsilon_B\,\kappa_B^{L-1}.
$$
再用
$$
|\widehat p(x)-p(x)|
=|\alpha^\top(\cdots)\beta|
\le\|\alpha\|_2\,\|\beta\|_2\;\|\cdots\|_2
$$
即可。□

##### 推论 11.3（一般情形下的端到端高概率界）

第 9.1 节矩阵 Bernstein 不等式给出：存在常数 $c_1,c_2>0$，对任意 $\delta\in(0,1)$，以概率至少 $1-\delta$,
$$
\Delta
\ \le\ 
c_1\sqrt{\frac{\mu\,\log((m+n)/\delta)}{N}}
+
c_2\frac{\log((m+n)/\delta)}{N},
$$
其中 $\mu\in[0,1]$ 为 Hankel 的行/列相干度。

代入定理 11.2，有常数 $C>0$ 使得以概率至少 $1-\delta$,
$$
\boxed{
\ \sup_{|x|=L}|\widehat p(x)-p(x)|\ \le\ 
C\,\frac{L\,\kappa_B^{L-1}}{\gamma}
\left(
\sqrt{\frac{\mu\,\log((m+n)/\delta)}{N}}
+\frac{\log((m+n)/\delta)}{N}
\right).
}
$$
这里 $C$ 吸收了 $|\alpha|_2|\beta|_2$ 以及常数 $c_1,c_2$。

### 11.2　在非负/次随机设定下得到 $O(L)$ 界

现在加入一个结构性假设，使长度放大从一般的 $L\kappa_B^{L-1}$ 降为 $O(L)$。

##### 假设 11.4（可收缩锥）

在真白化坐标下，存在某个诱导矩阵范数 $|\cdot|_\bullet$（例如 1 范数或 $\infty$ 范数），使得：

1. ${B_\sigma}$ 与 ${\widehat B_\sigma}$ 的元素均非负；
2. $\sum_\sigma B_\sigma$ 在该范数意义下行/列次随机（见 8.2 节）。

由第 8.3 节可知，此时
$$
\max_\sigma\|B_\sigma\|_\bullet\le 1,\quad
\max_\sigma\|\widehat B_\sigma\|_\bullet\le 1,
$$
且任意前缀乘积在 $|\cdot|_\bullet$ 下均不扩张：
$$
\Big\|\prod_t B_{x_t}\Big\|_\bullet\le 1,\quad
\Big\|\prod_t \widehat B_{x_t}\Big\|_\bullet\le 1.
$$
有限维换范数给出存在常数 $C_{\rm dim}>0$（只依赖维度 $r$），使得
$$
\|M\|_2\le C_{\rm dim}\|M\|_\bullet\quad\text{对所有 }M\in\mathbb R^{r\times r}.
$$

##### 定理 11.4（可收缩锥下的长度线性界）

在假设 11.4 下，存在常数 $C>0$，对任意 $\delta\in(0,1)$，one‑shot 采样下以概率至少 $1-\delta$ 有
$$
\boxed{
\ \sup_{|x|=L}|\widehat p(x)-p(x)|\ \le\ 
\frac{C\,L}{\gamma}
\left(
\sqrt{\frac{\mu\,\log((m+n)/\delta)}{N}}
+\frac{\log((m+n)/\delta)}{N}
\right).
}
$$
**证明略.**
 在 $|\cdot|*\bullet$ 下重做望远镜展开：
 每一项两侧乘积范数 $\le1$，中间差异 $|\widehat B*{x_s}-B_{x_s}|*\bullet\le C*{\rm dim}\varepsilon_B$，故
$$
\Big\|\prod_t \widehat B_{x_t}-\prod_t B_{x_t}\Big\|_\bullet
\le L\,C_{\rm dim}\varepsilon_B.
$$
换回谱范数再乘上 $|\alpha|_2|\beta|_2$，并用 $\varepsilon_B\le\Delta/\gamma$ 与 Bernstein 的 $\Delta$ 上界，即得所述不等式；常数统一吸收到 $C$ 中。□

##### 命题 11.5（给定精度的样本量反解）

给定目标点态误差 $\varepsilon>0$ 与置信度 $1-\delta$，在可收缩锥假设下，存在常数 $C'>0$ 使得只要
$$
\boxed{
\ N\ \ge\ C'\cdot
\max\left\{
\frac{L^2\,\mu}{\gamma^2}\cdot\frac{\log((m+n)/\delta)}{\varepsilon^2},
\ \ 
\frac{L}{\gamma}\cdot\frac{\log((m+n)/\delta)}{\varepsilon}
\right\},
}
$$
就有
$$
\Pr\Big[\sup_{|x|=L}|\widehat p(x)-p(x)|\le \varepsilon\Big]\ \ge\ 1-\delta.
$$
**推导略.**
 从定理 11.4：
$$
\frac{C L}{\gamma}
\left(
\sqrt{\frac{\mu\log}{N}}
+\frac{\log}{N}
\right)
\le \varepsilon.
$$
充分条件是把两项分别压到 $\varepsilon/2$：
$$
\frac{C L}{\gamma}\sqrt{\frac{\mu\log}{N}}\ \le\ \frac{\varepsilon}{2},
\qquad
\frac{C L}{\gamma}\frac{\log}{N}\ \le\ \frac{\varepsilon}{2},
$$
解得
$$
N\ \ge\ \frac{4C^2L^2\mu}{\gamma^2\varepsilon^2}\log,\qquad
N\ \ge\ \frac{2CL}{\gamma\varepsilon}\log.
$$
用一个共同常数 $C'$ 吸收数值系数即得。□

##### 备注 11.6（滑窗采样与有效样本量）

若采样不是 one‑shot，而是第 9.2 节的滑窗设定，在满足相应混合/鞅条件时：

- 间隔抽窗（定理 9.5）给出一个**有效窗口数** $N_{\rm eff}=N K_s$（或带混合因子 $\eta(s)$）；
- 鞅 Freedman 版本（定理 9.6）则给出形如 $N_{\rm eff}=N K/\eta$ 的有效样本量。

在这些情形下，只需在本章所有结论中把
$$
N\ \text{替换为}\ N_{\rm eff},
$$
并把相干度 $\mu$ 换成相应的“有效方差尺度”，就得到同样形式的端到端界。长度 $L$ 和谱间隙 $\gamma$ 的依赖保持不变，采样复杂度则从 $1/\sqrt{N}$ 换成 $1/\sqrt{N_{\rm eff}}$ 级。

## 11.3　信息论下界（minimax 量级）与可达性 

本节给出两类**严格可证**的下界，用以与上界对照其量级。以下常数与对数因子均省略不影响主阶。

##### 定理 11.7（Frobenius 风险的 minimax 下界；核范/有效秩族）

考虑 one‑shot 采样与模型族

$$
\mathcal H(r,\tau_F,\mu)
=\Big\{H\in\mathbb R^{m\times n}:\ \|H\|_F\le \tau_F,\ r_{\rm eff}(H)\le r,\ 
\max\{\max_u\sum_v H(u,v),\ \max_v\sum_u H(u,v)\}\le \mu\Big\}.
$$

则存在绝对常数 $c>0$，对任意估计量 $\widehat H$ 与样本量 $N$,

$$
\boxed{\quad
\inf_{\widehat H}\ \sup_{H\in\mathcal H(r,\tau_F,\mu)}
\mathbb E\|\,\widehat H-H\,\|_F
\ \ge\
c\cdot \min\!\Big\{\tau_F,\ \sqrt{\tfrac{\mu}{N}}\Big\}.
\quad}
$$

**证明要点（两点/多点法）**：在 $\|H\|_F\le\tau_F$ 球内、选取总质量 $\Theta(\mu)$ 的小支撑，构造幅度为 $\delta$ 的成组扰动族 $\{H_\theta\}$ 使得单次 KL 满足 $\mathrm{KL}(H_\theta\|H_{\theta'})\lesssim \delta^2/\mu$。令 $\delta\asymp \sqrt{\mu/N}$ 保证 $N$ 次采样的 KL 有界，Fano/Le Cam 即给出 $\Omega(\sqrt{\mu/N})$ 的 Frobenius 分离度。与 $\tau_F$ 取最小得到结论。

> **备注**：该下界**不依赖 $m,n$** 且对 $r_{\rm eff}\le r$ 的任何子类（因此也含低秩族）都成立；若进一步施加“均匀杠杆/有界势能分布”等**额外结构**，可得到含 $r$ 的更细下界，但为避免条件不足造成的不严谨，这里给出**普适且稳健**的形式。

##### 定理 11.8（端到端 TV 的 minimax 下界；白化‑恒等与非负锥内）

在**白化‑恒等校准**坐标与**非负锥**内：$\{B_\sigma\}_{\sigma\in\Sigma}\ge0$ 且 $\sum_\sigma B_\sigma=I$（逐元素）。令 $p,q$ 为由 $(\alpha,\{B_\sigma\},\beta)$ 生成的长度‑$L$ 分布。则对任意 $\varepsilon\in(0,\varepsilon_0)$ 存在常数 $c>0$ 使：

1. **非扩张或临界（$\kappa_B\le 1$）**：对任意估计器 $\widehat p$，当

$$
N\ \le\ c\,\frac{1}{\varepsilon^2}
$$

必存在一对 $p,q$ 使

$$
\mathbb E\big[\mathrm{TV}(\widehat p,p)\big]\ \vee\ \mathbb E\big[\mathrm{TV}(\widehat p,q)\big]\ \ge\ c\,\varepsilon .
$$

2. **严格收缩（$\kappa_B<1$）**：结论同上，阈值同阶 $N=\Omega(1/\varepsilon^2)$。

3. **一般扩张（$\kappa_B>1$）**：仍有**普适下界** $N=\Omega(1/\varepsilon^2)$。

**证明要点（两点法 + Pinsker）**：取秩‑1 对角构造（例如二元字母的轻微偏置）即可在该锥内得到一对 $p_\pm$。其**单样本** KL 随长度加和为 $\Theta(\delta^2 L)$（$\delta$ 为微小偏置），而 **Pinsker** 给出

$$
\mathrm{TV}(p_+,p_-)\ \le\ \sqrt{\tfrac12\,\mathrm{KL}(p_+\|p_-)}\ =\ O(\delta\sqrt{L}).
$$

令 $\delta\asymp \varepsilon/\sqrt{L}$ 得 $\mathrm{TV}(p_+,p_-)\asymp \varepsilon$、单样本 KL $\asymp \varepsilon^2$。Le Cam 因而给出 **$N=\Omega(1/\varepsilon^2)$** 的不可区分门槛，且与 $L$**无关**。

##### 结论 11.9（对照与启示）

* **非扩张/收缩情形**：端到端 **TV** 的**正确下界**为 $\Omega(1/\varepsilon^2)$，**不随 $L$ 增长**。与我们的上界（在可收缩锥内误差传播为 $O(L)$，从而样本量 $\tilde O(L^2/\varepsilon^2)$）相比，存在一个多项式级的长度差距。这表明上界在 $L$ 上**保守**，缩小该差距有赖于更细的混合/谱结构或更锋利的分析。

* **扩张情形**：仍有普适 $\Omega(1/\varepsilon^2)$ 下界；要得到包含 $L$ 或 $G_L(\kappa_B)$ 的更强下界，必须**额外**排除会使 KL 随长度线性累积的放大方向（强谱约束）。在未加此类约束时，不应主张强于 $\Omega(1/\varepsilon^2)$ 的长度依赖下界。

---



# ==Part Ⅳ　拓展与统一视角==

## 第12章　从纯态到混态与 POVM

本章把 Part I–V 的纯态/计算基测量框架扩展到**混态 + 一般 POVM**，以及**量子通道（CP 映射）**驱动的序列模型；并讨论量子访问（QAE/阴影）对样本复杂度的影响。

### 12.1　密度矩阵情形的 Hankel 扩张

**设定（混态 + POVM）.**
给定初态 $\rho_0\in\mathbb C^{d^T\times d^T}$（$\rho_0\succeq0,\ \mathrm{Tr}\rho_0=1$），在计算基/或一般 POVM ${M_x\succeq0}_{x\in\Sigma^L}$ 下的生成分布
$$
p(x)=\mathrm{Tr}(M_x\,\rho_0),\qquad \sum_x M_x=I .
$$

当 $M_x=|x\rangle\langle x|$ 时退化为 Born 机的 one‑shot 测量。

**MPDO（矩阵乘积密度算符）.**
若 $\rho_0$ admit MPDO 表达，存在“键维” $\chi_\rho$ 使

$$
\rho_0=\!\!\sum_{\{a_t\}}\!\! \mathrm{Tr}\!\Big[W^{[1]}_{a_1}\cdots W^{[T]}_{a_T}\Big]\,
|a_1\cdots a_T\rangle\langle a_1\cdots a_T| .
$$

（在 Liouville/向量化表述时，$\mathrm{vec}(\rho_0)$ 亦对应一条沿链的 TN，跨割维度为 $\chi_\rho$。）

**定理 12.1（混态/POVM 的 Hankel 秩上界，修订）.**
设 $\rho_0$ 的向量化张量网络跨割虚拟维为 $\chi_\rho$；设 POVM ${M_x}$ 由一条**测量张量网络**张成，其跨割虚拟维为 $\chi_M$（逐位点**可分**测量，如计算基投影，满足 $\chi_M=1$）。则对任意长度 $L$、切分点与集合 $P,S$，长度‑$L$ 的概率‑Hankel 满足
$$
H_p(u,v)=\ell_{\rm mix}(u)^\top r_{\rm mix}(v),\qquad
\mathrm{rank}\,H_p(P,S)\ \le\ \chi_\rho\,\chi_M .
$$

特别地，在**逐位点可分 POVM** 下 $\chi_M=1$，故 $\mathrm{rank},H_p(P,S)\le \chi_\rho$。在**纯态‑MPS** 情形，$\chi_\rho\le D^2$，因而 $\mathrm{rank},H_p(P,S)\le D^2\chi_M$；当测量可分时回到 $\le D^2$（与 Part II 一致）。

*Proof sketch.* 在 Liouville 表示中
$p(x)=\mathrm{vec}(I)^\top,\mathcal M_x,\mathrm{vec}(\rho_0)$，其中 $\mathcal M_x$ 为由测量张量网络诱导的线性超算子。将 $\mathrm{vec}(\rho_0)$ 与 $\mathcal M_x$ 各自写成沿链的 TN，$x=uv$ 的拼接仅在切分处通过它们的虚拟边连接。跨割有效空间维至多为 $\chi_\rho\chi_M$，故 $H_p$ 可写成该维度的双线性分解，秩上界随之得到。

**备注 12.2（截断与有效秩）.**
若对上述两条网络分别逐割截断到 $\chi_{\rho,{\rm eff}}$、$\chi_{M,{\rm eff}}$，则仍有$\mathrm{rank}_\varepsilon(H_p)\le \chi_{\rho,{\rm eff}}\chi_{M,{\rm eff}}$，且$|H_p-\tilde H_p|_2$ 继续满足 Part II 的**主界/备用界**（常数由两侧转移算子的范数控制）。在可分测量下 $\chi_{M,{\rm eff}}=1$，简化为 $\le \chi_{\rho,{\rm eff}}$。

### 12.2　CP 映射/量子 WFA 与转移算子收缩性

**量子仪器（instrument）与序列模型.**
设每个字母 $\sigma\in\Sigma$ 对应一个**完全正（CP）**且**迹非增**的超算子 $\mathcal M_\sigma$。定义
$$
\mathcal E:=\sum_{\sigma\in\Sigma} \mathcal M_\sigma
$$

为**CPTP** 通道（总效应保持迹）。长度 $L$ 字串的概率

$$
p(x_1\cdots x_L)=\mathrm{Tr}\big(\mathcal M_{x_L}\circ\cdots\circ \mathcal M_{x_1}(\rho_0)\big).
$$

（这是“量子隐马尔可夫/量子自动机”的标准生成式。）

**Liouville（向量化）表示.**
对每个 $\mathcal M_\sigma$ 取 Kraus $\{K_{\sigma,k}\}$，其矩阵表示

$$
B_\sigma=\sum_k K_{\sigma,k}\otimes \overline{K_{\sigma,k}}\in\mathbb C^{d^2\times d^2},\quad 
T:=\sum_\sigma B_\sigma.
$$

则

$$
p(x)=i^\top B_{x_1}\cdots B_{x_L}\, f,\qquad
i^\top=\mathrm{vec}(I)^\top,\quad f=\mathrm{vec}(\rho_0),
$$

（或选择 Heisenberg 图像把 $i,f$ 互换；两者仅是转置/相似变换差异）。

**定理 12.3（量子 WFA 与 Hankel 秩）.**
上述表示是一个**线性加权自动机**（WFA），其最小维度 $\le d^2$。因此无限 Hankel 的秩 $\le d^2$；若进一步通过 MPDO/隐变量降维（$\chi<d^2$），则 $\mathrm{rank}(H_p)\le\chi$。

*Proof sketch.* $p(\cdot)$ 为有理级数，Hankel 秩等于最小表示维（Part I–III 已述）。

**收缩性与混合.**

* **CPTP**（薛定谔图像）对**迹距离**是 1‑收缩：$\|\mathcal E(X)-\mathcal E(Y)\|_1\le\|X-Y\|_1$。
* **CPU**（海森堡对偶）对算子范数 $\|\cdot\|_\infty$ 亦是 1‑收缩。
* 若 $\mathcal E$ **原始/primitive**（量子 Perron–Frobenius：存在唯一满秩不动点、外围谱仅有简单 1），则对某常数 $C$ 与 $\lambda_\star<1$：

$$
\|\mathcal E^t(X)-\mathrm{Tr}(X)\rho_\star\|_1\ \le\ C\,\lambda_\star^t\,\|X\|_1 .
$$

**命题 12.4（长度依赖与谱半径）.**
在 Liouville 表示下，$\rho(T)=1$。若 $\mathcal E$ primitive，则
$$
\|T^t-\Pi\|_2\ \le\ C'\,\lambda_\star^t,
$$

其中 $\Pi$ 为到不动点的秩‑1 投影（左右特征向量外积）。

### 12.3　量子访问（QAE/阴影）对样本复杂度的影响

**QAE（量子幅度估计）.**
若能对**事件指示**实现受控反射并执行 QAE，则在**单次试验**内用 $K$ 轮相位估计可将该事件概率估计的 MSE 从常数级降为 $O(1/K^2)$，因而在固定独立试验次数 $N$ 下，总体**根均方误差**获得 **$1/K$** 的乘性改进（达到同等精度的总资源量由经典的 $O(1/\varepsilon^2)$ 降至 $O(1/\varepsilon)$ 级）。需注意这**仅降低方差**，**不改变**单次增量的幅度上界。

**定理 12.5（QAE‑增强的 Hankel 集中）.**
在第 9 章的 one‑shot 设定中，令 $N$ 为独立试验数（窗口/串），每次试验内部使用 $K$ 轮 QAE 得到**无偏或低偏**的矩阵增量。则以概率至少 $1-\delta$，
$$
\boxed{\ 
\|\widehat H-H\|_2\ \le\ 
C_1\,\frac{1}{K}\sqrt{\frac{\mu\,\log((m+n)/\delta)}{N}}
\ +\ 
C_2\,\frac{\log((m+n)/\delta)}{N}
\ +\ b_K\ .
}
$$

其中首项体现相对经典矩阵 Bernstein 的 **$1/K$** 方差改进；第二项源于单次增量的幅度界，**不随 $K$** 缩放；$b_K$ 为（可选的）偏差项：若构造为无偏估计则 $b_K=0$，常见 QAE 变体经合适后处理可达 $b_K=O(1/K)$。若改为“逐条目独立 QAE”再拼成矩阵，可得保守界
$\|\widehat H-H\|_2\lesssim \frac{\sqrt{mn}}{K}\sqrt{\log(mn/\delta)}$。

*Proof sketch.* QAE 把条件方差缩至原来的 $1/K^2$，而增量取值范围不变；代入矩阵 Bernstein（或 Freedman）得第一项按 $1/K$ 缩放、第二项保持不变，并附加偏差 $b_K$。

**量子阴影（classical shadows）.**
当需同时估计多项 $\{\mathrm{Tr}(O_j\rho)\}$ 时，误差由 **shadow norm** 控制；若 $O_j$ 为对角投影等“友好”可观测量，该常数较小，可将**多条目同时估计**的总复杂度压到 $\tilde O(\log(mn)/\varepsilon^2)$ 级，与 QAE 形成互补。

**备注 12.6（可用性）.**
QAE 需要“可控反射 + 相位估计”的硬件能力，并常需中位数‑均值/随机相位等后处理以实现无偏/低偏与稳健尾界；阴影需要**随机测量基**与线性重建。本文主体结论不依赖这些访问，它们仅作为**可选加速器**。

---

## 第13章　无限长度与平稳极限

本章讨论 $L\to\infty$ 时的极限行为：转移算子谱隙、混合时间、滑窗极限与极限 Hankel 的结构。

### 13.1　传递算子、谱隙与混合时间

**设定.** 继续采用量子仪器/CP 模型，Liouville 表示 $B_\sigma$、总转移 $T=\sum_\sigma B_\sigma$，以及初始向量 $f=\mathrm{vec}(\rho_0)$、左向量 $i^\top=\mathrm{vec}(I)^\top$。

**定义 13.1（谱隙与外围谱）.** 令
$$
\lambda_1=1,\quad 
\lambda_2=\max\{|\lambda|:\ \lambda\in\mathrm{spec}(T),\ \lambda\neq 1\},\quad 
\mathrm{gap}:=1-\lambda_2\ (>0\ \text{若 }\mathcal E\text{ primitive}).
$$

**定理 13.2（原始通道的多项式‑指数混合）.**
若 $\mathcal E$ primitive，则存在秩‑1 投影 $\Pi=f_\star g_\star^\top$（$T f_\star=f_\star,\ g_\star^\top T=g_\star^\top$）与常数 $C>0$、整数 $\nu\ge1$（由 $T$ 的 Jordan 结构决定）使
$$
\boxed{\ \ \|T^t-\Pi\|_2\ \le\ C\,t^{\nu-1}\,\lambda_2^{\,t}\qquad (t=1,2,\dots)\ .\ }
$$

若进一步 $T$ 在某等价内积下可对角化（例如满足可逆对称/详细平衡），则可取 $\nu=1$，从而得到纯指数界 $\|T^t-\Pi\|_2\le C\,\lambda_2^{\,t}$。

混合时间（使残差 $\le \varepsilon$）满足

$$
t_{\rm mix}(\varepsilon)\ \le\ \frac{ \log(C/\varepsilon)\ +\ (\nu-1)\log\!\big(1/\mathrm{gap}\big)\ +\ O(\log\log(C/\varepsilon)) }{\mathrm{gap}},
$$

而在可对角化/可逆对称情形则简化为

$$
t_{\rm mix}(\varepsilon)\ \le\ \frac{\log(C/\varepsilon)}{\mathrm{gap}}.
$$

*Proof sketch.* 量子 Perron–Frobenius 与 primitive 假设给出唯一简单本征值 $1$ 及 $\Pi$；Schur/Jordan 形将非主谱贡献界为多项式×指数 $t^{\nu-1}\lambda_2^{t}$。若 $T$ 可对角化（如满足详细平衡），则无 Jordan 放大，故 $\nu=1$。

**含义.** 长度增大时，$T^t$ 逼近秩‑1 投影 $\Pi$，长窗口的桥接/边缘化统计趋于秩‑1 结构；一般情形存在可控的多项式前因子，而在可对角化（可逆对称）设定下收敛为纯指数。

### 13.2　滑窗极限与理性级数

**无限有理级数.**
对任意有限词 $w\in\Sigma^\ast$，定义
$$
f(w)=i^\top B_w f\quad (B_w=B_{w_1}\cdots B_{w_{|w|}}).
$$

$\{f(w)\}$ 是一个**理性级数**（finite linear representation），其**无限 Hankel** $H_\infty(u,v)=f(uv)$ 的秩等于最小表示维度（≤ $d^2$ 或 MPDO 维 $\chi$）。

**Z‑变换/生成函数.** 令按长度分级的生成函数

$$
F(z):=\sum_{L\ge0}\ \sum_{w\in\Sigma^L} f(w)\, z^L 
= i^\top \Big(I - z\,T\Big)^{-1} f ,
$$

在 $|z|<1/\rho(T)=1$ 内解析。更细的分解可写成
$F(z)=\sum_\sigma i^\top (I-zT)^{-1} B_\sigma f\cdot z + \cdots$。

**滑窗极限（固定窗口、长序列）.**
当观察来自**平稳过程**（见下节）且只关心固定窗口长度 $L$ 时，经验 Hankel 的极限一致于由最小表示生成的 $H_p^{(L)}$（强大数定律/鞅极限定理）。因此对于足够大的数据量，**固定 $L$** 的学习问题稳定在有限维表示之内。

### 13.3　稳态分布与极限 Hankel

**稳态与投影.**
设 $\mathcal E$ primitive，令 $f_\star$ 为右不动向量（$\mathrm{vec}(\rho_\star)$），$g_\star$ 为左不动向量（$\mathrm{vec}(I)$ 的重标定）。则
$$
\lim_{t\to\infty} T^t=\Pi=f_\star g_\star^\top .
$$

**定理 16.3（桥接/边缘化 Hankel 的秩‑1 极限）.**
固定 $t_\star$ 与集合 $P\subseteq\Sigma^{t_\star}$、$S\subseteq\Sigma^{\ell}$（$\ell$ 固定）。令中段长度为 $k\ge0$，定义**桥接/边缘化**的概率‑Hankel

$$
H_p^{(t_\star,k)}(u,v):=\sum_{\substack{w\in\Sigma^k}}p(uwv)
= i^\top B_u\,T^{k}\,B_v f ,
$$

于是

$$
H_p^{(t_\star,k)}(P,S)=O_P\,T^{k}\,C_S
\ \xrightarrow[k\to\infty]{}\ 
O_P\,\Pi\,C_S
=\big(O_P f_\star\big)\big(g_\star^\top C_S\big),
$$

因此极限矩阵的秩 $\le 1$，收敛速率为 $\tilde O(\lambda_2^{k})$。等价地，若固定两端长度 $t_\star,\ell$ 而令总长 $L\to\infty$，取 $k=L-t_\star-\ell$ 得同样结论。

*Proof sketch.* 由 16.2 的 $T^{k}\to\Pi$，代入 $H_p^{(t_\star,k)}=O_PT^{k}C_S$ 即得。

**含义.** 在**强混合**情形，**对中段做边缘化**（或固定两端、仅拉长中段）时，桥接 Hankel 退化为近秩‑1（信息耗散至稳态），解释了“窗口过长→劣条件”的经验现象，并动机了**短窗口/多切分**与**主动选集**。
**注：** 若按原始定义对每个具体后缀 $v$ 单独建列而**不**对中段求和，矩阵一般**不会**随 $L$ 自发塌缩为秩‑1。 

---

## 第14章　其他观测与相位可达性

概率‑Hankel 只反映测量分布 $p(x)=|\psi(x)|^2$。为改善**可辨识性**与**条件数**，本章讨论三条“轻量观测增强”路线：

1. 在不改变主体硬件的前提下，通过局域相位门或双份干涉获得**相位相关的线性信息**；
2. 通过**交叉矩（cross‑moment）**引入额外的 Hankel 型矩阵；
3. 将 Hankel 嵌入视作**核特征**或张量网络边界，实现与核/ TN 软件栈的接口与模型选择。

本章的所有结论都是在前文线性表示
$$
p(x)=i^\top B_x f,\qquad B_x:=B_{x_1}\cdots B_{x_L}
$$
已经存在的前提下的**额外选项**；不改变 Part I–V 的主算法及其理论。

### 14.1　轻量干涉/对比实验的相位视角

**基本思路.**
 在测量前对**少数几个位置**施加可控的小门，或者对**两份同态**做轻量干涉，从而得到与振幅 $\psi(x)$ 有关的附加统计量，再配合概率‑Hankel 共同约束模型。

#### 14.1.1 局域相位抖动（phase contrast）

在某一位置 $t$ 加一个小相位门（例如单比特 $R_z(\phi)=e^{-i\phi Z/2}$ 或等价局域相位），再进行同样的测量。记此时长度‑$L$ 字串 $x$ 的概率为 $p_\phi(x)$。

对任意固定的前缀/后缀 $u,v$（满足 $|u|+|v|=L$），定义
$$
\Delta_{t}(u,v)
:=\frac{d}{d\phi}\,p_\phi(uv)\Big|_{\phi=0}.
$$
在标准量子力学中，$\Delta_t(u,v)$ 可以写成某个**局域算符的期望值**的虚部，因此是关于振幅的**线性信息**，而不仅仅是 $|\psi|^2$。在 MPS / Liouville 表示下，这一量可写成
$$
\Delta_t(u,v)
=\tilde\ell_t(u)^\top\, A_t\,\tilde r_t(v),
$$
其中 $\tilde\ell_t,\tilde r_t$ 是在位置 $t$ 切分后得到的前/后缀嵌入，$A_t$ 是一个由局域生成元确定的固定矩阵（与样本无关）。我们无需给出 $A_t$ 的显式形式，只用到：

- 它仍然是“**前缀向量 × 矩阵 × 后缀向量**”的双线性结构；
- 和概率‑Hankel $H_p(u,v)=\ell_p(u)^\top r_p(v)$ 共享相同或可扩展的嵌入空间。

对若干 $t$ 和若干 $(u,v)$ 估计 $\Delta_t(u,v)$，可以把这些导数值视为一组新的“**对比矩阵**”，与 $H_p$ 共同加入谱学习。

> 直观地，$H_p$ 控制了 $|\psi|^2$，$\Delta_t$ 提供了关于相位差的线性约束，二者合用可显著减少等价变换下的自由度。

#### 14.1.2 双份干涉（swap / beam‑splitter）

若可同时制备两份相同状态 $|\psi\rangle$，可以对它们做简单干涉（例如 SWAP‑test 或受控相位 + 测量），以得到**前缀/后缀嵌入的内积信息**。

典型地，利用 SWAP‑test 可得到
$$
\mathbb E[\text{测量结果}]=|\langle\phi|\psi\rangle|^2,
$$
因此只要能把“前缀态 $\ell(u)$” 和 “前缀态 $\ell(u')$”嵌入为两份输入，就能估计
$$
|\langle\ell(u),\ell(u')\rangle|^2,
$$
类似地对后缀嵌入 $r(v)$ 亦然。把这些内积条目堆成 Gram 矩阵
$$
G_P(u,u')\approx \langle\ell(u),\ell(u')\rangle,\qquad
G_S(v,v')\approx \langle r(v),r(v')\rangle,
$$
可直接增强第 6 章中可观测 Gram 的有界性，从而改善谱学习的条件数。

**命题 14.1（观测增强与 Gram 改善）.**

设原始概率‑Hankel 在选定的前缀/后缀集合 $P,S$ 上可分解为
$$
H_p(P,S)=O_P\,C_S,
$$
其中 $O_P\in\mathbb C^{|P|\times d}$、$C_S\in\mathbb C^{d\times |S|}$。

若通过局域相位抖动或双份干涉得到的额外观测，可以写成同一右嵌入 $C_S$ 下的一族矩阵
$$
H^{(k)}_{\rm extra}(P,S)=O_P^{(k)}\,C_S,\qquad k=1,\dots,K,
$$
则将它们按行级联
$$
H_{\rm joint}(P,S):=
\begin{bmatrix}
H_p \\ H^{(1)}_{\rm extra} \\ \vdots \\ H^{(K)}_{\rm extra}
\end{bmatrix}
=
\underbrace{
\begin{bmatrix}
O_P \\ O_P^{(1)} \\ \vdots \\ O_P^{(K)}
\end{bmatrix}}_{\mathcal O_{\rm joint}}
C_S,
$$
有
$$
\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint}
=O_P^\top O_P+\sum_{k}O_P^{(k)\top}O_P^{(k)}\ \succeq\ O_P^\top O_P.
$$
因此其最小特征值不减：
$$
\lambda_{\min}(\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint})
\ \ge\
\lambda_{\min}(O_P^\top O_P),
$$
在第 6 章限制‑Gram 假设下，意味着**可实现 Hankel 的最小奇异值下界不减，并在 $O_P^{(k)}$ 真正带来新方向时严格增大**。由此，谱学习得到的恢复误差常数可以得到系统性改善。

*备注.*
 在具体线路里，只需在少数位置施加相位门或者做少量 SWAP‑test / 受控干涉，就可以构造上面形式的若干 $H^{(k)}_{\rm extra}$，避免大规模修改硬件。

### 14.2　交叉矩（cross‑moment）与扩展可识别性

这一节考虑一种更“统计”的增强：在概率‑Hankel 之外，加入带权的**交叉矩**。

#### 14.2.1 交叉 Hankel 的定义与线性表示

取一个辅助观测函数 $g:\Sigma^L\to\mathbb R$，例如：

- 简单的符号/奇偶性函数；
- 由第二份样本或 classical shadow 重建得到的线性函数；
- 或其他可由某线性表示计算的统计量。

定义长度‑$L$ 的交叉 Hankel：
$$
H_\times(u,v)
:=\mathbb E_{x\sim p}\big[\mathbf 1\{x=uv\}\cdot g(x)\big],
\qquad |u|+|v|=L.
$$
若 $g$ 本身也 admit 一组线性表示
$$
g(x)=i_g^\top B_x f_g,
$$
（这里 $B_x$ 与 $p$ 共享同一组转移 $B_\sigma$，只是左右向量 $i_g,f_g$ 不同），则
$$
H_\times(u,v)
= p(uv)\,g(uv)
= (i^\top B_u B_v f)\,(i_g^\top B_u B_v f_g).
$$
上述乘积本身也是一个有理级数，可以表示为更高维的线性表示。例如定义扩展矩阵
$$
\widetilde B_\sigma:=B_\sigma\otimes B_\sigma,\quad
\widetilde i:=i\otimes i_g,\quad
\widetilde f:=f\otimes f_g,
$$
则有
$$
H_\times(u,v)
=\widetilde i^\top\,\widetilde B_u\,\widetilde B_v\,\widetilde f
=\phi_\times(u)^\top\,\psi_\times(v),
$$
其中
$$
\phi_\times(u):=\widetilde i^\top\widetilde B_u,\quad
\psi_\times(v):=\widetilde B_v \widetilde f.
$$
也就是说：**交叉 Hankel 仍然是“前缀向量 × 后缀向量”的双线性结构**，只是嵌入空间变成了 Kronecker 扩张的高维空间。

在很多自然构造下，还可以选择 $g$ 使得右嵌入和 $p$ 共享同一 $C_S$（例如 $g$ 只改变前缀侧的线性函数）。以下命题就聚焦在这种“右侧兼容”的情形上，便于与前文 Gram 分析对接。

#### 14.2.2 联合估计与条件数改善

**命题 14.2（交叉矩引入的联合 Hankel）.**

假设存在矩阵 $O_\times\in\mathbb C^{|P|\times d}$，使得在选定的前缀/后缀集合 $P,S$ 上，交叉 Hankel 可写成
$$
H_\times(P,S)=O_\times\,C_S,
$$
其中 $C_S$ 与 $H_p(P,S)=O_P C_S$ 的右因子相同（这一点可通过对 $g$ 的设计保证，例如让 $g$ 只引入新的前缀侧线性结构）。

定义联合矩阵
$$
H_{\rm joint}(P,S)
:=
\begin{bmatrix}
H_p \\ H_\times
\end{bmatrix}
=
\underbrace{\begin{bmatrix}
O_P \\ O_\times
\end{bmatrix}}_{\mathcal O_{\rm joint}}
C_S.
$$
则
$$
\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint}
=O_P^\top O_P + O_\times^\top O_\times\ \succeq\ O_P^\top O_P,
$$
因此
$$
\lambda_{\min}(\mathcal O_{\rm joint}^\top\mathcal O_{\rm joint})
\ \ge\ 
\lambda_{\min}(O_P^\top O_P).
$$
在第 6 章的统一框架下，这意味着：

- 联合使用 $H_p$ 和 $H_\times$ 至少不会降低限制‑Gram 的最小特征值；
- 若 $O_\times$ 真正提供了新的独立方向，则最小特征值**严格增大**；
- 相应地，用联合 Hankel 做谱学习时，$\sigma_{\min}$ 的理论下界更好，恢复误差常数更小。

*实现建议.*
 在实践中：

- 若已有测量数据/阴影数据，可令 $g(x)$ 为其线性函数，从而“免费”得到交叉矩；
- 若测量预算有限，可选取简单的符号/哈希函数 $g$，以很小附加代价增加一块 Hankel 结构。

### 14.3　与张量网络/核方法的接口

最后，讨论如何把前文的 Hankel / 线性表示视作**特征映射**或**张量网络边界**，方便与核方法 / MPS 软件栈结合。

#### 14.3.1 核化视角（feature map）

在最小线性表示维为 $D$ 的情形下，我们可以把“Hankel 嵌入”显式写成特征：
$$
\phi_P(u):=\ell_p(u)^\top\in\mathbb C^{1\times D},\qquad
\phi_S(v):=r_p(v)\in\mathbb C^{D\times 1},
$$
于是
$$
H_p(u,v)=\ell_p(u)^\top r_p(v)=\langle\phi_P(u),\phi_S(v)\rangle.
$$
由此得到**字符串核**：
$$
k_P(u,u'):=\phi_P(u)\phi_P(u')^\top,\qquad
k_S(v,v'):=\phi_S(v)^\top\phi_S(v').
$$
这两类核可以直接用于：

- 核回归/分类：把前缀/后缀当作输入，Hankel 作为核矩阵；
- 低秩核学习：在核矩阵近低秩时，用 Nyström / 随机特征近似。

当表示维 $D$ 自身不大或 Hankel 有明显低秩结构时，**显式 WFA / SVD** 通常更高效；当 $D$ 很大但数据自然稀疏或局部结构强时，用核方法 + 选集更灵活。

#### 14.3.2 张量网络接口

从张量网络视角看，前缀/后缀嵌入 $O_P,C_S$ 正是 TN 的“边界张量”：

- 把 $O_P$ 看成多个前缀边界张量堆叠，$C_S$ 看成多个后缀边界张量堆叠；
- 选集设计（例如最大化 $\log\det(I+\lambda^{-1}O_P^\top O_P)$）等价于**最大化边界 Gram 的体积**，保证选到的信息最丰富的一组边界条件；
- 在 MPS/MPDO 软件中，可直接用 TEBD/DMRG 中的“正交中心移动 + 截断”来实现前文第 II 部分的截断与误差控制。

**命题 14.3（表示选择与有效秩）.**

设在某个固定窗口丈量下，真 Hankel $H\in\mathbb R^{m\times n}$ 满足：

- Frobenius 范数有界：$\|H\|_F\le\tau_F$；
- 有效秩（例如 $r_{\rm eff}:=\|H\|_F^2/\|H\|_2^2$）远小于 $\min\{m,n\}$。

在第 10 章给出的核范/有效秩风险界下：

1. 任何要达到给定精度的学习方法，其**有效维度**至少是 $\Omega(r_{\rm eff})$ 量级（无论它实现为显式低秩参数还是 Nyström 特征数）；
2. 显式低秩参数化（如 WFA / SVD 截断到秩 $\tilde r\approx r_{\rm eff}$）用 $O(r_{\rm eff})$ 个参数即可达到与核范正则同阶的泛化界；
3. 因此，在 $r_{\rm eff}\ll \min\{m,n\}$ 的 regime 下，**显式低秩模型在统计和计算上都不劣于纯核方法，且参数更少、更易解释**；
    而在“$D$ 很大但 Hankel 本身并不明显低秩、或者只在局部块上低秩”的场景，核化 + 选集往往更灵活。

这为“选用显式 WFA / 低秩 Hankel 还是核方法”提供了一个简单准则：**看 Hankel 的有效秩**。有效秩小 → 倾向于显式低秩；有效秩大、结构偏局部 → 倾向于核化 + 选集 / TN 技术。

