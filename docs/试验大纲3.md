## 实验 3：门噪声与长度放大

（验证定理 5.5 & 8.1 的几何放大 vs 线性放大）

### 0. 理论目标回顾

**定理 5.5 / 8.1 的核心：**

- 一般情形（没结构约束）：
  $$
  \|H_p^{(L)}-\widetilde H_p^{(L)}\|_2
  \;\lesssim\;
  C_{P,S}\,\kappa_p^{\,L-1}\sum_{t=1}^L \epsilon_p(t)
  $$
  — 随长度 $L$ 可能呈**几何/指数放大**。

- 在存在某个**可收缩范数**（如非负次随机锥下的 $\|\cdot\|_1/\|\cdot\|_\infty$）时：
  $$
  \|H_p^{(L)}-\widetilde H_p^{(L)}\|_2
  \;\lesssim\;
  C^{(\bullet)}_{P,S}\,\Big(\sum_{t=1}^L \epsilon_p^{(\bullet)}(t)\Big)\,G_{1:L}(\kappa^{(\bullet)})
  $$
  若 $\kappa^{(\bullet)}\le1$，则 $G_{1:L}\le L$，**长度依赖降为 $O(L)$**。

**实验目标：**

1. 从“干净” MPS 出发，对每一层门加小噪声，看看
    $\|H_p^{(L)}-\widetilde H_p^{(L)}\|_2$ 如何随 $L$ 增长：是否呈现近似几何（接近指数）增长趋势。
2. 构造一个“可收缩锥近似模型”（对 WFA 转移 $\{B_\sigma\}$ 做投影/重标定，使其处于非负次随机锥内），在这个模型中再加同样的噪声，看看误差随 $L$ 是否**更接近线性**。

------

## 一、实验设置（总体结构）

### 1. 参数选择

- 字母表：$\Sigma = \{0,1\}$，即 $d=2$。

- 键维：选一个中等值 $D \in \{3,4\}$（保证 $D^2$ 不太大，WFA 维度 manageable）。

- 长度：$L\in\{5,10,15,20\}$，用来观察随长度增长的趋势。

- 噪声尺度 $\varepsilon$：例如
  $$
  \varepsilon \in \{10^{-3},\,3\times10^{-3},\,10^{-2}\}
  $$

- 对每个组合 $(L,\varepsilon)$，重复实验 $N_{\text{trial}}\approx 20$ 次，取平均和误差棒（标准差/标准误差）。

### 2. Ground truth MPS（干净模型）

生成一组**左规范**的 MPS 作为真实模型 $\psi$ / $p(x)$：

1. 对每个 site $t=1,\dots,L_{\max}$（这里 $L_{\max}=20$），在 $\Sigma$ 上生成随机复矩阵
   $$
   A_t(\sigma)\in\mathbb C^{D\times D},\quad\sigma\in\{0,1\}
   $$

2. 对每个 $t$，做一次 left-canonical 规范化：
   $$
   M_t := \sum_{\sigma} A_t(\sigma)A_t(\sigma)^\dagger
   $$

   $$
   A_t(\sigma) \leftarrow M_t^{-1/2}A_t(\sigma)
   $$

   这样大致满足 $\sum_\sigma A_t(\sigma)A_t(\sigma)^\dagger\approx I$。

3. 取边界向量 $\alpha,\beta\in\mathbb C^D$ 随机生成并归一化：
   $$
   \|\alpha\|_2=\|\beta\|_2 = 1.
   $$

4. 对给定长度 $L$，只取前 $L$ 个 site 的 $\{A_t(\sigma)\}_{t=1}^L$ 和同一组 $(\alpha,\beta)$ 来定义干净 MPS。

> 注：你可以根据算力选择“每个 L 独立采样一套 MPS”或者“统一采样一套长度 20 MPS，截取前 L 阶段”。

------

## 二、注入门噪声（原始 QCBM 模型）

### 1. 噪声形式

对每个层 $t$ 和符号 $\sigma$：

- 采样一个随机扰动矩阵：
  $$
  G_{t,\sigma} \sim \text{复高斯矩阵}\in\mathbb C^{D\times D}
  $$

- 计算其谱范数（最大奇异值）$\|G_{t,\sigma}\|_2$，定义
  $$
  \Delta A_{t}(\sigma) := \varepsilon \,\frac{G_{t,\sigma}}{\|G_{t,\sigma}\|_2},
  \quad\Rightarrow\quad
  \|\Delta A_{t}(\sigma)\|_2 = \varepsilon.
  $$

- 设噪声后 gate：
  $$
  \widetilde A_t(\sigma)=A_t(\sigma)+\Delta A_t(\sigma).
  $$

这样每一层的每个 gate 的扰动谱范数都约为 $\varepsilon$，和理论里的 $\varepsilon_t$ 对应。

**注意：**

- 不再强制规范化噪声后的 $\widetilde A_t$，故 $\kappa_p$ 可能 >1，更容易看到指数放大。
- 这对应定理 5.5 中的一般扰动情形。

### 2. 噪声后的概率分布与 Hankel

对每个长度 $L$：

1. 对所有 $x\in\Sigma^L$（如有算力顾虑，可抽样）：

   - 干净模型：
     $$
     \psi(x) = \alpha^\top\Big(\prod_{t=1}^L A_t(x_t)\Big)\beta,\quad
     p(x)=|\psi(x)|^2
     $$

   - 噪声模型：
     $$
     \widetilde\psi(x)=\alpha^\top\Big(\prod_{t=1}^L \widetilde A_t(x_t)\Big)\beta,\quad
     \widetilde p(x)=|\widetilde\psi(x)|^2
     $$

2. 固定切分点 $t_\*=\lfloor L/2\rfloor$，选取前缀/后缀集合 $P,S$ 来构造 Hankel：

   - **为降低计算负担**，建议不枚举所有 $2^{t_*}$ 个前缀、$2^{L-t_*}$ 个后缀，而是：
     - 若 $2^{t_*}\le M$（例如 $M=256$），就取全部；
     - 若 $2^{t_*}>M$，随机采样 $M$ 个前缀；
     - 对后缀集合 $S$ 同理。
   - 这样 Hankel 维度最多 $M\times M$（例如 256×256），SVD/谱范数计算非常轻松。

3. 构造：
   $$
   H_p^{(L)}(u,v) = p(uv),\quad \widetilde H_p^{(L)}(u,v)=\widetilde p(uv).
   $$

------

## 三、误差度量（无结构约束）

对每个 $L,\varepsilon$ 和每次 trial：

- 计算：
  $$
  E_{\text{raw}}(L,\varepsilon)
  := \big\|H_p^{(L)}-\widetilde H_p^{(L)}\big\|_2.
  $$

- 可选：也记录 Frobenius 范数 $\|\,\cdot\,\|_F$，看两者 scaling 是否一致。

对每个 $(L,\varepsilon)$，在 $N_{\text{trial}}$ 个样本上取：

- 平均误差 $\overline E_{\text{raw}}(L,\varepsilon)$，
- 标准差 / 标准误差 用作误差棒。

**预期：**

- 若 $\kappa_p>1$，则 $\overline E_{\text{raw}}(L,\varepsilon)$ 随 $L$ 呈**超线性甚至近似指数**增长；在半对数坐标上（log 误差 vs L）会接近一条直线。

------

## 四、可收缩锥近似：构造行次随机 WFA 模型

接下来是一整套“投影到可收缩锥”的流程。这里我们不再要求它精确代表物理 QCBM，而是作为“结构化近似模型”，看看噪声传播是否更温和（线性）。

### 1. 从 MPS 得到 WFA 转移矩阵 $B_{t,\sigma}$

对每个层 $t$ 和符号 $\sigma$：
$$
B_{t,\sigma} = A_t(\sigma)\otimes\overline{A_t(\sigma)}\ \in\ \mathbb C^{D^2\times D^2}.
$$
（时间依赖的 WFA：每层使用 $\{B_{t,\sigma}\}$）

### 2. 映射到非负矩阵

为了进入“非负行次随机锥” $\mathcal K_{\text{row}}$，先做 elementwise 绝对值：
$$
B_{t,\sigma}^{(+)}(i,j) := |B_{t,\sigma}(i,j)| \ge 0.
$$
这一步丢掉了相位，但保留了“大小结构”，作为近似。

### 3. 行次随机重标定（投影到 $\mathcal K_{\text{row}}$）

我们希望 $\{B_{t,\sigma}^{\text{proj}}\}$ 满足：

- 非负：$B_{t,\sigma}^{\text{proj}}\ge0$；

- 行次随机锥条件：
  $$
  \sum_\sigma B_{t,\sigma}^{\text{proj}}\mathbf 1\ \le\ \mathbf1.
  $$

一个简单可行的投影方式：

对每个层 $t$ 的每一行 $i$：

1. 计算该行在所有符号上的总和：
   $$
   r_{t,i} := \sum_{\sigma}\sum_j B_{t,\sigma}^{(+)}(i,j)
   $$

2. 定义缩放因子：
   $$
   s_{t,i} :=
   \begin{cases}
   1, & r_{t,i}\le 1, \\
   1/r_{t,i}, & r_{t,i}>1.
   \end{cases}
   $$

3. 设置投影结果：
   $$
   B_{t,\sigma}^{\text{proj}}(i,j) := s_{t,i}\,B_{t,\sigma}^{(+)}(i,j).
   $$

这样对任意 $i$ 有：
$$
\sum_\sigma\sum_j B_{t,\sigma}^{\text{proj}}(i,j)
= s_{t,i} r_{t,i}\le 1,
$$
因此 $\{B_{t,\sigma}^{\text{proj}}\}\in\mathcal K_{\text{row}}$。

> 注意：
>
> - 这是一个相当粗糙但实现简单的投影；
> - 更精细的投影（例如最小化 $\sum_\sigma\|B_{t,\sigma}^{\text{proj}}-B_{t,\sigma}^{(+)}\|_F^2$ 的凸优化）也可以，但这套简单规则足以演示“可收缩性”的效果。

### 4. 噪声后的投影：$\{\widetilde B_{t,\sigma}^{\text{proj}}\}$

对噪声后的 gate $\widetilde A_t(\sigma)$ 同样构造：

1. $ \widetilde B_{t,\sigma} = \widetilde A_t(\sigma)\otimes \overline{\widetilde A_t(\sigma)}$
2. 元素级绝对值：$\widetilde B_{t,\sigma}^{(+)} = |\widetilde B_{t,\sigma}|$
3. 对每一层的行按前面的规则缩放，得到 $\widetilde B_{t,\sigma}^{\text{proj}}\in\mathcal K_{\text{row}}$。

------

## 五、在可收缩锥模型中定义“概率”和 Hankel

现在我们有了一对 WFA 模型（干净投影 / 噪声投影）：

- 干净：$\{B_{t,\sigma}^{\text{proj}}\}$
- 噪声：$\{\widetilde B_{t,\sigma}^{\text{proj}}\}$

需要构造“输出标量”来定义长度 $L$ 上的序列值（可理解为 surrogate 概率）。

### 1. 选择 WFA 的边界向量 $i,f$

为了和非负锥结构吻合，可以简单选取非负向量，比如：

- 初始向量 $i := e_1$（标准基向量），维度 $D^2$；
- 终止向量 $f := \mathbf 1 / D^2$（全 1 向量归一化）。

这样对任意非负 WFA，输出：
$$
q(x_{1:L}) = i^\top \Big(\prod_{t=1}^L B_{t,x_t}^{\text{proj}}\Big) f \ge 0.
$$
对噪声模型用同样的 $i,f$ 定义 $\widetilde q(x)$。

### 2. 归一化成“伪概率”（可选）

如需对齐“概率 Hankel”的语义，可以做归一化：
$$
p_{\text{proj}}(x) = \frac{q(x)}{\sum_{x'} q(x')},\qquad
\widetilde p_{\text{proj}}(x) = \frac{\widetilde q(x)}{\sum_{x'} \widetilde q(x')}.
$$
即使不归一化，误差的 **相对长度依赖** 也不会改变，但归一化后更便于与原模型的 $p(x)$ 比较。

### 3. 构造 Hankel 矩阵

对每个 $L$，用与上文同样的前缀/后缀集合 $P,S$：

- 干净投影模型：
  $$
  H_{p,\text{proj}}^{(L)}(u,v) = p_{\text{proj}}(uv)
  $$

- 噪声投影模型：
  $$
  \widetilde H_{p,\text{proj}}^{(L)}(u,v) = \widetilde p_{\text{proj}}(uv)
  $$

------

## 六、误差度量（可收缩锥模型）

对每个 $L,\varepsilon$ 与每次 trial：
$$
E_{\text{proj}}(L,\varepsilon)
:= \big\|H_{p,\text{proj}}^{(L)} - \widetilde H_{p,\text{proj}}^{(L)}\big\|_2.
$$
同样在 trials 上取平均 $\overline E_{\text{proj}}(L,\varepsilon)$ 和误差棒。

**理论期待：**

- 由于 $\{B_{t,\sigma}^{\text{proj}}\}\in\mathcal K_{\text{row}}$，在 $\|\cdot\|_\infty$ 范数下是非扩张的：
   每一步乘积的行和 ≤1 ⇒ $G_L(\kappa^{(\infty)})\le L$。

- 转回谱范数最多引入一个固定维度常数 $C$，因此整体长度依赖应该接近线性：
  $$
  E_{\text{proj}}(L,\varepsilon)\ \approx\ \text{const}(\varepsilon)\times L.
  $$

------

## 七、对比与可视化

### 1. 主图：误差 vs 长度（原始 vs 投影）

对每个噪声尺度 $\varepsilon$，画两条曲线：

- x 轴：长度 $L\in\{5,10,15,20\}$
- y 轴：
  - 原始 QCBM 模型的平均误差：$\overline E_{\text{raw}}(L,\varepsilon)$
  - 投影后可收缩模型的平均误差：$\overline E_{\text{proj}}(L,\varepsilon)$

有两种画法：

1. **线性坐标（y vs L）**
   - 原始模型：曲线明显弯向上（凸），增长比线性快；
   - 投影模型：曲线接近一条直线。
2. **半 log 坐标（$\log y$ vs L）**
   - 原始模型：接近一条斜率 > 0 的直线 ⇒ 对应指数 / 几何增长；
   - 投影模型：更接近“弯下来的曲线”，对应线性或低次多项式增长，在 log 轴上表现为 sub-exponential。

### 2. 拟合斜率（定量化）

可以对每组数据做一个简单拟合：

- 对原始模型拟合：
  $$
  \log \overline E_{\text{raw}}(L,\varepsilon) \approx a_{\text{raw}} + b_{\text{raw}} L
  $$
  如果 $b_{\text{raw}}$ 明显 >0，则表明存在几何放大（$\kappa_p>1$）。

- 对投影模型拟合：
  $$
  \overline E_{\text{proj}}(L,\varepsilon) \approx c_{\text{proj}} + d_{\text{proj}} L
  $$
  若 $d_{\text{proj}}$ 稳定且拟合较好，说明线性放大是合理模型。

可以在论文里直接给一句话定量描述，例如：

> For $\varepsilon=10^{-2}$, the slope $b_{\text{raw}}\approx 0.12$ (indicating an effective expansion factor $\kappa\approx e^{0.12}\approx 1.13$), while the projected model exhibits a near-linear dependency with slope $d_{\text{proj}}\approx 0.03$.

------

## 八、注意事项与变体

1. **序列枚举 vs 抽样：**
   - 若 L=20 时枚举所有 $2^{20}$ 个字符串成本太高，可以只枚举构造 $H_p(P,S)$ 所需要的那些 $uv$（大小 ≤$M^2$）；
   - 对于 $M=256$，每个 L 的字符串数最多 $256^2=65536$，对 D=3/4 来说非常安全。
2. **多基准 MPS：**
   - 你可以固定一组基准 MPS，在不同 trial 中仅重采噪声；
   - 也可以每个 trial 都重新采样 MPS（更接近“典型行为”），二者差别不大。
3. **其它锥（列次随机）：**
   - 若使用 $\mathcal K_{\text{col}}$（列非负，列和 ≤1），则用 $\|\cdot\|_1$ 作为可收缩范数；
   - 实现时只需把“行和”换成“列和”缩放即可。
4. **和理论的对齐表述（写在论文里的方式）**

可以在正文中这样总结这组实验：

> Starting from left-canonical MPS with bond dimension $D$, we inject small perturbations to each local tensor $A_t(\sigma)$ and examine how the Hankel error $\|H_p^{(L)}-\widetilde H_p^{(L)}\|_2$ scales with the sequence length $L$. In the “raw” QCBM parameterization, we observe a clear super-linear (often close to exponential) growth with $L$, in line with the geometric amplification factor predicted by Theorem 5.5.
>  In contrast, when we project the associated WFA transition matrices $B_{t,\sigma}=A_t(\sigma)\otimes\overline{A_t(\sigma)}$ onto a nonnegative row-substochastic cone and recompute the induced Hankel matrices, the error growth becomes almost linear in $L$. This matches the contractive-norm analysis in Theorem 8.1(B) and Theorem 8.4, where the length dependence is reduced from $G_L(\kappa)$ to $O(L)$.