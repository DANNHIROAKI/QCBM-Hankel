# 实验 6：多视角 Hankel 的好处

> 对应理论：第 8.3 章（多视角 Hankel 联合分析） + 第 11 章（端到端误差与 $1/\gamma$ 缩放）。
>  实现参考脚本：`exp6_multi_view.py`（但本大纲对联合经验 Hankel 的部分做了关键升级）。

------

## 6.0 理论目标与待验证假设

### 6.0.1 背景与符号

- 对每个视角 $k$，存在 Hankel 分解
  $$
  H^{(k)} = O^{(k)} C^{(k)},\qquad \mathrm{rank}(H^{(k)}) = r.
  $$

- 多视角联合：
  $$
  \mathcal O_{\rm joint}=
  \begin{bmatrix}
  O^{(1)}\\\vdots\\O^{(K)}
  \end{bmatrix},\quad
  \mathcal C_{\rm joint}=
  \begin{bmatrix}
  C^{(1)}&\cdots&C^{(K)}
  \end{bmatrix},\quad
  H_{\rm joint}=\mathcal O_{\rm joint}\mathcal C_{\rm joint}.
  $$

- 定理 8.7（谱下界）说明：
  $$
  \sigma_r(H_{\rm joint})
  \ \ge\
  \sqrt{
    \Big(\sum_k \lambda_{\min}(O^{(k)\top}O^{(k)})\Big)
    \Big(\sum_k \lambda_{\min}(C^{(k)}C^{(k)\top})\Big)
  }.
  $$

- 第 11 章表明，端到端点态误差大致为：
  $$
  \text{error} \;\propto\; \frac{\Delta}{\gamma},\quad 
  \gamma = \sigma_r(H),
  $$
  其中 $\Delta$ 是 Hankel 估计误差、$\gamma$ 是最小非零奇异值。

### 6.0.2 实验要检验的两条主 Hypothesis

**H6‑A（谱层面，多视角抬高最小奇异值）**

- 对同一 ground truth 模型，
  $$
  H^{(k)} \ (k=1,\dots,K),\quad H_{\rm joint}
  $$
  的最小奇异值满足
  $$
  \gamma^{(k)} := \sigma_r(H^{(k)}),\qquad
  \gamma_{\rm joint} := \sigma_r(H_{\rm joint}),
  $$
  且数值上
  $$
  \gamma_{\rm joint} \gg \max_k \gamma^{(k)}.
  $$

- 同时，$\gamma_{\rm joint}$ 应该**数值上不小于**定理 8.7 的 Gram 下界：
  $$
  \gamma_{\rm joint}
  \;\gtrsim\;
  \sqrt{
    \Big(\sum_k \lambda_{\min}(O^{(k)\top}O^{(k)})\Big)
    \Big(\sum_k \lambda_{\min}(C^{(k)}C^{(k)\top})\Big)
  }.
  $$

------

**H6‑B（学习层面，多视角提高稳定性且误差随 $1/\gamma$ 缩放）**

在有限样本谱学习中，比较：

- 单视角谱学习（选一个代表视角，比如“中间切分”）；
- 多视角联合白化 + 多视角预测；

我们希望看到：

1. 在同一样本数 $N$ 下，多视角的点态误差（max / TV）**平均更小**；

2. 多视角误差在不同 trial 间的**标准差更小**（鲁棒性更好）；

3. 把误差乘上对应的 $\gamma$ 后：
   $$
   \overline E_{\rm single}(N)\cdot\gamma_{\rm single},
   \qquad
   \overline E_{\rm multi}(N)\cdot\gamma_{\rm joint}
   $$
   的曲线更接近，支持“误差主要由 $1/\gamma$ 控制”的理论。

------

## 6.1 实验总体设置

### 6.1.1 Ground truth 模型家族

- 字母表：$\Sigma = \{0,1\}$，即二元序列。

- 序列长度 $L$：取若干个值做参数扫描，例如：
  $$
  L \in \{6,8,10\}.
  $$

- 键维 $D$：选择中等规模，确保 Hankel 秩不会太低，例如：
  $$
  D \in \{2,3,4\}.
  $$

- ground truth 生成方式（与现有脚本一致）：exp6_multi_view

  1. 对每个位置 $t\in\{1,\dots,L\}$ 和每个符号 $\sigma\in\Sigma$ 生成随机复矩阵 $A_t(\sigma)\in\mathbb C^{D\times D}$；

  2. 做 left‑canonical 规范化：
     $$
     M_t = \sum_{\sigma} A_t(\sigma)A_t(\sigma)^\dagger,\quad
     A_t(\sigma)\leftarrow M_t^{-1/2}A_t(\sigma),
     $$
     其中 $M_t^{-1/2}$ 用 Newton–Schulz 迭代近似；

  3. 随机归一化边界向量 $\alpha,\beta\in\mathbb C^D$；

  4. 枚举所有 $x\in\Sigma^L$，用 MPS 精确计算振幅与概率
     $$
     p(x)=|\psi(x)|^2,
     $$
     并归一化形成真分布表 $p_{\rm true}(x)$。

- 为了统计稳定性，每个 $(L,D)$ 组合跑若干个独立模型，例如：
  $$
  \text{num\_models\_per\_setting} = 5.
  $$

### 6.1.2 多视角切分与前缀/后缀集合

对每个固定的 $L$，选择一组切分点 $\{t_{*,k}\}_{k=1}^K$：

- 典型配置：
  $$
  K\in\{2,3,4\},\quad
  t_{*,k}\in\{2,\dots,L-2\},
  $$
  例如：

  - $L=6$ 时：$t_{*,1}=2,t_{*,2}=3,t_{*,3}=4$（与现有脚本一致）；exp6_multi_view
  - $L=10$ 时：$t_{*,1}=3,t_{*,2}=5,t_{*,3}=7$ 等。

对每个视角 $k$：

- 前缀/后缀全集：
  $$
  P^{(k)}_{\text{full}} = \Sigma^{t_{*,k}},\quad
  S^{(k)}_{\text{full}} = \Sigma^{L-t_{*,k}}.
  $$

- 若全集过大，则**随机下采样**到指定上限（例如 128），但要记住：

  - 使用一个固定的随机种子保证可复现；
  - 得到有序列表 `P^{(k)}`, `S^{(k)}`，并在后续所有地方**严格使用同样的顺序**，
     不允许 `set+sort` 之类打乱顺序（防止 Hankel 行/列索引错位）。试验大纲6

### 6.1.3 样本规模与 trial 设定

- 样本规模 $N$：建议用 log 级别扫描，例如：
  $$
  N\in\{500,2000,5000,20000\}.
  $$

- 对每个 $(L,D,K,N)$ 配置，重复 $R$ 次独立采样 trial，例如：
  $$
  R = 20.
  $$

每个 trial 都重新采样数据，但共用同一个 ground truth MPS，这样可以分离“模型难度”和“采样噪声”的影响。

------

## 6.2 实验 6A：真 Hankel 的谱结构验证（H6‑A）

目标：在**无采样噪声**情况下，验证多视角联合 Hankel 的谱性质确实符合定理 8.7。

### 6.2.1 单视角真 Hankel 与 SVD 分解

对每个 ground truth 模型、每个视角 $k$：

1. 利用真分布 $p_{\rm true}$ 构造 Hankel：
   $$
   H^{(k)}(u,v) = p_{\rm true}(uv),\quad u\in P^{(k)}, v\in S^{(k)}.
   $$

2. 对 $H^{(k)}$ 做 rank‑$r$ SVD（$r\le D^2$）：
   $$
   H^{(k)} = U^{(k)}\Sigma^{(k)}V^{(k)\top}.
   $$

3. 取：
   $$
   O^{(k)} = U^{(k)}\Sigma^{(k)1/2},\quad
   C^{(k)} = \Sigma^{(k)1/2}V^{(k)\top},
   $$
   则 $H^{(k)} = O^{(k)}C^{(k)}$ 是一组合法的 rank‑$r$ 分解。

4. 记录单视角最小奇异值：
   $$
   \gamma^{(k)} := \sigma_r(H^{(k)}) = \Sigma^{(k)}_{rr}.
   $$

### 6.2.2 联合 Hankel 与 Gram 下界

1. 构造联合可观测/可控制矩阵：
   $$
   \mathcal O_{\rm joint}=
   \begin{bmatrix}
   O^{(1)}\\\vdots\\O^{(K)}
   \end{bmatrix},\quad
   \mathcal C_{\rm joint}=
   \begin{bmatrix}
   C^{(1)}&\cdots&C^{(K)}
   \end{bmatrix}.
   $$

2. 联合 Hankel：
   $$
   H_{\rm joint} = \mathcal O_{\rm joint}\mathcal C_{\rm joint}.
   $$

3. 对 $H_{\rm joint}$ 做 rank‑$r$ SVD，记录：
   $$
   \gamma_{\rm joint} := \sigma_r(H_{\rm joint}).
   $$

4. Gram 下界（数值 sanity check）：

   - 每个视角的 Gram：
     $$
     G_O^{(k)} = O^{(k)\top}O^{(k)},\quad
     G_C^{(k)} = C^{(k)}C^{(k)\top};
     $$

   - 定义：
     $$
     \Lambda_O = \sum_k \lambda_{\min}(G_O^{(k)}),\quad
     \Lambda_C = \sum_k \lambda_{\min}(G_C^{(k)}).
     $$

   - Gram 下界：
     $$
     \gamma_{\rm Gram} :=
     \sqrt{\Lambda_O\Lambda_C}.
     $$

   - 验证数值上是否满足：
     $$
     \gamma_{\rm joint} \ge \gamma_{\rm Gram},\quad
     \gamma_{\rm joint} \ge \max_k \gamma^{(k)}.
     $$

### 6.2.3 统计与可视化

- 对每个 $(L,D,K)$ 配置，在多个 ground truth 模型上统计：
  - 单视角 $\gamma^{(k)}$ 的均值/中位数与分布；
  - 联合 $\gamma_{\rm joint}$ 的均值/中位数；
  - $\gamma_{\rm joint} / \max_k \gamma^{(k)}$ 的提升倍数；
  - $\gamma_{\rm joint}$ 与 $\gamma_{\rm Gram}$ 的差距。
- 建议图：
  1. **柱状图 / 箱线图**：各视角的 $\gamma^{(k)}$ 与 $\gamma_{\rm joint}$ 对比；
  2. **散点图**：横轴 $\gamma_{\rm Gram}$，纵轴 $\gamma_{\rm joint}$，看是否集中在对角线之上；
  3. **提升倍数 vs K**：显示随着视角数 K 增加，$\gamma_{\rm joint}$ 的提升如何变化。

------

## 6.3 实验 6B：多视角联合谱学习的稳定性（H6‑B）

这里重点是**在有限样本下**，比较单视角 vs 多视角谱学习的端到端误差与方差，并分析误差与 $\gamma$ 之间的缩放关系。

### 6.3.1 trial 流程与样本生成

对每个 ground truth 模型、每个样本规模 $N$、每个 trial（共 $R$ 次）：

1. 从真分布 $p_{\rm true}$ 中 iid 采样 $N$ 条长度为 $L$ 的序列；
2. 这些样本同时用于所有视角（避免不同视角使用不同数据集）。

### 6.3.2 单视角谱学习 Baseline

选一个代表视角 $k_* $（例如中间切分 $t_{*,2}$）作为 baseline：

1. 用切分点 $t_{*,k_*}$ 把每个样本 $x$ 拆成 $u,v$，只对 $(u,v)\in P^{(k_*)}\times S^{(k_*)}$ 计数，得到经验 Hankel：
   $$
   \widehat H^{(k_*)}(u,v)
   =\frac1N\sum_{i=1}^N \mathbf 1\{u^{(i)}=u,v^{(i)}=v\}.
   $$

2. 对 $\widehat H^{(k_*)}$ 做 rank‑$r$ SVD：
   $$
   \widehat H^{(k_*)} \approx \widehat U^{(k_*)}\widehat\Sigma^{(k_*)}\widehat V^{(k_*)\top},
   $$
   记录经验最小奇异值 $\widehat\gamma^{(k_*)}_{\rm emp} = \sigma_r(\widehat H^{(k_*)})$。

3. 构造单视角嵌入：
   $$
   \phi^{(k_*)}(u)=\widehat\Sigma^{(k_*)1/2}\widehat U^{(k_*)\top}e_u,\quad
   \psi^{(k_*)}(v)=\widehat\Sigma^{(k_*)1/2}\widehat V^{(k_*)\top}e_v.
   $$

4. 对任意 $x=uv$，定义预测：
   $$
   \widehat p_{\rm single}(uv)
   :=\phi^{(k_*)}(u)^\top\psi^{(k_*)}(v),
   $$
   再对所有 $x$ 上的预测做非负截断 + 归一化，得到合法分布 $\widehat p_{\rm single}$。

5. 误差度量：
   $$
   E_{\rm single} = \max_x|\widehat p_{\rm single}(x)-p_{\rm true}(x)|,\quad
   \mathrm{TV}_{\rm single} = \tfrac12\sum_x|\widehat p_{\rm single}(x)-p_{\rm true}(x)|.
   $$

### 6.3.3 多视角联合经验 Hankel（关键补强）

为了和理论中的 $H_{\rm joint}$ 一一对应，我们用**联合频率**构造经验联合 Hankel，而不是通过“先单视角 SVD 再堆 O/C”。试验大纲6

1. **全局前缀/后缀集合：**
   $$
   P_{\rm all} := \bigcup_{k=1}^K P^{(k)},\quad
   S_{\rm all} := \bigcup_{k=1}^K S^{(k)}.
   $$
   实现：建立两个有序列表 `P_all_list`, `S_all_list`，顺序固定且在整个实验过程中不变。

2. **联合频数统计：**

   对每个样本 $x^{(i)}$、每个视角 $k$：

   - 按 $t_{*,k}$ 切分 $x^{(i)}=u_k^{(i)}v_k^{(i)}$；
   - 若 $u_k^{(i)}\in P_{\rm all}$ 且 $v_k^{(i)}\in S_{\rm all}$，则更新对应条目。

   定义联合经验 Hankel：
   $$
   \widehat H_{\rm all}(u,v)
   = \frac{1}{N K} \sum_{i=1}^N \sum_{k=1}^K
   \mathbf 1\{u_k^{(i)}=u,\ v_k^{(i)}=v\}.
   $$
   它估计的就是以 $P_{\rm all},S_{\rm all}$ 为索引的联合 Hankel $H_{\rm joint}$ 的对应条目（模一个常数因子）。

3. **联合 SVD 与联合嵌入：**

   - 对 $\widehat H_{\rm all}$ 做 rank‑$r$ SVD：
     $$
     \widehat H_{\rm all} \approx U_r^{\rm all}\Sigma_r^{\rm all}V_r^{\rm all\top},
     $$
     记录联合经验最小奇异值：
     $$
     \widehat\gamma_{\rm joint}^{\rm emp} = \sigma_r(\widehat H_{\rm all}).
     $$

   - 联合嵌入：
     $$
     \phi_{\rm joint}(u)=\Sigma_r^{\rm all\,1/2}U_r^{\rm all\top}e_u,\quad
     \psi_{\rm joint}(v)=\Sigma_r^{\rm all\,1/2}V_r^{\rm all\top}e_v,
     $$
     其中 $u\in P_{\rm all},v\in S_{\rm all}$。

### 6.3.4 多视角预测与误差

对任意测试串 $x\in\Sigma^L$，执行：

1. 对所有视角 $k$，用各自切分点 $t_{*,k}$ 得到 $x=u_k v_k$；

2. 若 $u_k\in P_{\rm all}$ 且 $v_k\in S_{\rm all}$，则计算该视角的预测：
   $$
   \widehat p^{(k)}_{\rm joint}(x) :=
   \phi_{\rm joint}(u_k)^\top\psi_{\rm joint}(v_k).
   $$

3. 对所有有有效嵌入的视角求平均：
   $$
   \widehat p_{\rm multi}(x)
   := 
   \begin{cases}
   \frac1{|\mathcal K_x|}\sum_{k\in\mathcal K_x}\widehat p^{(k)}_{\rm joint}(x), & \mathcal K_x\neq\emptyset,\\[4pt]
   0, & \text{否则},
   \end{cases}
   $$
   其中 $\mathcal K_x$ 为有定义的视角集合。

4. 对 $\widehat p_{\rm multi}$ 做截断为非负并归一化，得到合法分布。

5. 多视角误差：
   $$
   E_{\rm multi} = \max_x|\widehat p_{\rm multi}(x)-p_{\rm true}(x)|,\quad
   \mathrm{TV}_{\rm multi} = \tfrac12\sum_x|\widehat p_{\rm multi}(x)-p_{\rm true}(x)|.
   $$

### 6.3.5 误差与 $1/\gamma$ 缩放分析

对每个 $(L,D,K,N)$ 配置，利用 $R$ 个 trial 的结果统计：

- 单视角：
  $$
  \overline E_{\rm single}(N),
  \quad
  \overline{\mathrm{TV}}_{\rm single}(N),
  \quad
  \mathrm{Std}[E_{\rm single}(N)],\dots
  $$

- 多视角：
  $$
  \overline E_{\rm multi}(N),
  \quad
  \overline{\mathrm{TV}}_{\rm multi}(N),
  \quad
  \mathrm{Std}[E_{\rm multi}(N)],\dots
  $$

- 缩放后的误差：
  $$
  \tilde E_{\rm single}(N) := \overline E_{\rm single}(N)\cdot\gamma^{(k_*)},
  \quad
  \tilde E_{\rm multi}(N) := \overline E_{\rm multi}(N)\cdot\gamma_{\rm joint}.
  $$

理论预期：$\tilde E_{\rm single}(N)$ 与 $\tilde E_{\rm multi}(N)$ 的数量级比较接近，说明误差主要由 $\Delta/\gamma$ 的比值控制，而 $\gamma_{\rm joint}$ 的变大就是多视角提高稳定性的主要来源。

------

## 6.4 超参数扫描与结果呈现

### 6.4.1 推荐的超参数网格

为了在不爆炸计算量的前提下捕捉主要趋势，可以采用如下网格：

- 长度：$L\in\{6,8,10\}$；
- 键维：$D\in\{2,3,4\}$；
- 视角数：$K\in\{2,3,4\}$，切分点均匀分布在 $[2,L-2]$；
- 样本数：$N\in\{500,2000,5000,20000\}$；
- 每个 $(L,D)$ 下 ground truth 模型数：5；
- 每个 $(L,D,K,N)$ 下 trial 数：$R=20$。

对于计算成本较高的配置（比如 $L=10,D=4$），可以适当减少 trial 或限制 $K$ 的取值。

### 6.4.2 建议图像

1. **图 6(a)：真 Hankel 的最小奇异值**
   - x 轴：视角 $k$ 以及 “joint”；
   - y 轴：$\gamma^{(k)}$ 与 $\gamma_{\rm joint}$ 的中位数（附误差条）；
   - 同图加上 Gram 下界 $\gamma_{\rm Gram}$，展示 $\gamma_{\rm joint}$ 始终在下界之上。
2. **图 6(b)：误差 vs 样本数**
   - x 轴：$\log N$；
   - y 轴：$\overline E$ 或 $\overline{\mathrm{TV}}$；
   - 曲线 1：单视角 baseline；曲线 2：多视角；
   - 用误差棒表示 trial 间标准差，多视角的棒应更短。
3. **图 6(c)：缩放误差 vs 样本数（验证 $1/\gamma$）**
   - x 轴：$\log N$；
   - y 轴：$\tilde E_{\rm single}(N)$、$\tilde E_{\rm multi}(N)$；
   - 若两条曲线接近平行甚至接近重合，则说明“误差主要通过 $1/\gamma$ 缩放”的理论是可信的。
4. **图 6(d)：多视角数量 K 的收益**
   - 固定 $L,D,N$，横轴为 K，纵轴为：
     - $\gamma_{\rm joint}/\max_k \gamma^{(k)}$；
     - $\overline E_{\rm single}/\overline E_{\rm multi}$ 的相对提升；
   - 展现 K 从 1 到 2,3,4 时的收益是否逐渐递减（典型 “多视角收益到一定数量会趋于饱和” 的现象）。

------

## 6.5 实现细节与坑点提醒

1. **索引一致性是重中之重**
   - 前缀/后缀集合 `P^{(k)},S^{(k)},P_all_list,S_all_list` 的顺序一旦确定，所有构造 Hankel / 嵌入 / 预测的地方都必须使用同一顺序；
   - 不要在中途对这些列表做排序或重新构造映射，否则很容易出现 Hankel 行/列错位的问题（之前脚本里已经踩到过这个坑）。试验大纲6
2. **数值稳定性**
   - SVD 可通过 Gram 矩阵 + 幂迭代实现，但要注意对奇异值很小的方向加入阈值截断；
   - 预测阶段，对 $\widehat p$ 做非负截断 + 归一化是必要的，否则小的负值会影响 TV 计算。
3. **运行成本**
   - 对于较长的 L 和较大的 D，不必枚举全部 $2^L$ 串做评估，可以随机抽取一个足够大的测试集（例如 10^4 个）来估计误差；
   - Hankel 的规模受 $P,S$ cap 控制，`max_prefixes,max_suffixes` 尽量控制在 128–256 以内，防止矩阵 SVD 成本过高。